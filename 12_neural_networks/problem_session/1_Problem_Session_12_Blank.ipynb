{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64f29b2f",
   "metadata": {},
   "source": [
    "# Problem Session 12\n",
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b50b5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95274a04",
   "metadata": {},
   "source": [
    "### Carseats Regression Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e02443",
   "metadata": {},
   "source": [
    "First run the following code to clean the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf89aec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = pd.read_csv(\"../../Data/car_sales.csv\")\n",
    "cars.dropna(inplace = True)\n",
    "\n",
    "def clean_column(text):\n",
    "    return float(text.split()[0])\n",
    "\n",
    "## Cleaning the mileage, engine and max_power columns\n",
    "cars['mileage'] = cars['mileage'].apply(clean_column)\n",
    "cars['engine'] = cars['engine'].apply(clean_column)\n",
    "cars['max_power'] = cars['max_power'].apply(clean_column)\n",
    "\n",
    "## creating the age column\n",
    "cars['age'] = 2020 - cars['year']\n",
    "\n",
    "## performing the log transform on selling_price and km_driven\n",
    "cars['log_sell'] = np.log10(cars['selling_price'])\n",
    "cars['log_km'] = np.log10(cars['km_driven'])\n",
    "\n",
    "## making one-hot encoded variables for transmission, dealer and owner\n",
    "cars['automatic'] = 1\n",
    "cars.loc[cars.transmission=='Manual', 'automatic'] = 0\n",
    "\n",
    "cars[['first_owner', 'second_owner', 'third_owner']] = pd.get_dummies(cars['owner'])[['First Owner', \n",
    "                                                                                      'Second Owner',\n",
    "                                                                                      'Third Owner']]\n",
    "\n",
    "cars['dealer'] = 1\n",
    "cars.loc[cars.seller_type == 'Individual', 'dealer'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8334b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7815e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_train, cars_test = train_test_split(cars.copy(),\n",
    "                                            test_size=.2,\n",
    "                                            shuffle=True,\n",
    "                                            random_state=440)\n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb7454c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remind yourself about what the data looks like.\n",
    "\n",
    "features = ['max_power', 'age', 'engine', 'log_km', 'seats', 'dealer', 'automatic', 'mileage']\n",
    "            \n",
    "target = ['log_sell']\n",
    "\n",
    "cars_train[features + target].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e04e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert everything to numpy arrays\n",
    "\n",
    "X_train = cars_train[features].values\n",
    "y_train = cars_train[target].values\n",
    "X_test = cars_test[features].values\n",
    "y_test = cars_test[target].values\n",
    "X_tt, X_val, y_tt, y_val = train_test_split(X_train, y_train, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe14148",
   "metadata": {},
   "source": [
    "Train a vanilla linear regression model on `(X_tt, y_tt)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebeb2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce56a176",
   "metadata": {},
   "source": [
    "Now try to train a feed forward neural network which has better validation MSE.\n",
    "\n",
    "Some things to consider:\n",
    "* How will you address normalization of the input data, if at all?\n",
    "* How many intermediate layers will you use?  What dimensions will they be?\n",
    "* What activation functions should you use in the hidden layer?\n",
    "* What final activation function should you use, if any?\n",
    "* What loss function should you use?\n",
    "* What are some other hyperparameters you could play with?\n",
    "\n",
    "If you are not able to beat linear regression after playing for 20 minutes you should move on.  If you successfully train a neural network and observe the loss going down: count this as a victory!\n",
    "\n",
    "We will use [early stopping callback](https://keras.io/api/callbacks/early_stopping/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d47170c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mine took about 4 seconds to run.\n",
    "\n",
    "model = \n",
    "\n",
    "callback = keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "\n",
    "model.compile(optimizer = , loss = )\n",
    "\n",
    "history = model.fit(X_tt, y_tt, epochs = , validation_data = (X_val, y_val), batch_size = , callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e303cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25351c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_squared_error(y_val, model.predict(X_val)))\n",
    "print(mean_squared_error(y_val, lr.predict(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b96a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively use model.evaluate\n",
    "model.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fd8470",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting the training and validation loss\n",
    "plt.figure(figsize = (8,6))\n",
    "epochs = len(history.history['val_loss'])\n",
    "plt.scatter(range(1, epochs + 1),history.history['loss'], label = \"Training Loss\")\n",
    "plt.scatter(range(1, epochs + 1),history.history['val_loss'], label = \"Validation Loss\")\n",
    "\n",
    "plt.xlabel(\"Epoch\", fontsize=12)\n",
    "plt.ylabel(\"Loss Function Value\", fontsize=12)\n",
    "\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a92ccf4",
   "metadata": {},
   "source": [
    "Once you are satisfied, check to see if the test MSE of the neural network model still beats linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a76ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.evaluate(X_test, y_test))\n",
    "print(mean_squared_error(y_test, lr.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa13b5d9",
   "metadata": {},
   "source": [
    "### Forest Cover Classification Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcc7041",
   "metadata": {},
   "source": [
    "In this problem we will build a feed forward neural network to classify forest cover type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ae70a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7bec0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell took about 7 minutes to run for me!\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "covertype = fetch_ucirepo(id=31) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = covertype.data.features \n",
    "y = covertype.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(covertype.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(covertype.variables) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93745d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state = 216)\n",
    "X_tt, X_val, y_tt, y_val = train_test_split(X_train,y_train, test_size=0.2, random_state = 216)\n",
    "X_tt.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01214f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making everything into numpy arrays\n",
    "X_train = X_train.values\n",
    "X_tt = X_tt.values\n",
    "X_val = X_val.values\n",
    "X_test = X_test.values\n",
    "\n",
    "# Adjusting class labels to go from 0 to 6 instead of 1 to 7.  Keras expects this.\n",
    "y_train = y_train.values.reshape(-1) - 1\n",
    "y_tt = y_tt.values.reshape(-1) - 1\n",
    "y_val = y_val.values.reshape(-1) - 1\n",
    "y_test = y_test.values.reshape(-1) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cacf6bb",
   "metadata": {},
   "source": [
    "Neural Networks are not a good choice for tabular data like this:  something like XGBoost is much better.  A \"default settings\" random forest classifier gets around 95% accuracy for this problem.\n",
    "\n",
    "The first dense feed forward NN I wrote down got 78% validation accuracy.  Can you beat that?\n",
    "\n",
    "Some things to consider:\n",
    "* Since this is a multiclass classification problem you want to use 'softmax' as your final activation function.\n",
    "    * Discussion question:  why do we need a final activation function?  Why not use 'sigmoid'?\n",
    "* Since your class labels are encoded as the integers $0,1,2,3,4,5,6$, you want to use  ['sparse_categorical_crossentropy'](https://www.tensorflow.org/api_docs/python/tf/keras/losses/sparse_categorical_crossentropy) as your loss and ['sparse_categorical_accuracy'](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/sparse_categorical_accuracy) as your metric when you compile the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df984470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mine took about 5 minutes to run.\n",
    "\n",
    "clf = \n",
    "\n",
    "callback = keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
    "\n",
    "clf.compile(optimizer = , loss = \"sparse_categorical_crossentropy\", metrics = 'sparse_categorical_accuracy')\n",
    "\n",
    "history = clf.fit(X_tt, y_tt, epochs = , validation_data = (X_val, y_val), batch_size = , callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e61748f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.evaluate(X_val, y_val.reshape(-1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675e18f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.evaluate(X_test, y_test.reshape(-1) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

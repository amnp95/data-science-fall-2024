{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcf6f50b",
   "metadata": {},
   "source": [
    "# Problem Session 7\n",
    "## Forecasting The Bachelorette and Pumpkin Spice II\n",
    "\n",
    "In the second of two time series based problem sessions you build upon your work in `Problem Session 6`. In particular you will look to build the best forecast you can for the Bachelorette IMDB ratings. Afterwards you will be introduced to seasonal ARIMA models with the pumpkin spice Google trends data.\n",
    "\n",
    "The problems in this notebook will cover the content covered in our `Time Series Forecasting` lectures including:\n",
    "- `Averaging and Smoothing`,\n",
    "- `Stationarity and Autocorrelation` and\n",
    "- `ARIMA`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4cf50e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from seaborn import set_style\n",
    "from datetime import datetime\n",
    "\n",
    "set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bba8849",
   "metadata": {},
   "source": [
    "#### 1. The Bachelorette\n",
    "\n",
    "##### a.\n",
    "\n",
    "- Reload the Bachelorette IMDB data stored in `the_bachelorette.csv` in the `data` folder. \n",
    "- Look at the first five rows.\n",
    "- Then make a train test split setting aside the last three episodes as a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7447489",
   "metadata": {},
   "outputs": [],
   "source": [
    "tv = pd.read_csv(\"../../data/the_bachelorette.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54347f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>episode_number</th>\n",
       "      <th>title</th>\n",
       "      <th>season</th>\n",
       "      <th>season_episode_number</th>\n",
       "      <th>imdb_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Episode #1.1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.201235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Episode #1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6.201235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Episode #1.3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5.301235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Episode #1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5.801235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Episode #1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5.801235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   episode_number         title  season  season_episode_number  imdb_rating\n",
       "0               1  Episode #1.1       1                      1     6.201235\n",
       "1               2  Episode #1.2       1                      2     6.201235\n",
       "2               3  Episode #1.3       1                      3     5.301235\n",
       "3               4  Episode #1.4       1                      4     5.801235\n",
       "4               5  Episode #1.5       1                      5     5.801235"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72f04d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_train = tv.iloc[:-3].copy()\n",
    "tv_test = tv.drop(tv_train.index).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8721870c",
   "metadata": {},
   "source": [
    "##### b.\n",
    "\n",
    "Here is a refresher on the columns of this data.\n",
    "\n",
    "- `episode_number` is the number of the episode with respect to the entire series run,\n",
    "- `title` is the title of the episode,\n",
    "- `season` is the number of the season in which the episode aired,\n",
    "- `season_episode_number` is the number of the episode with respect to the season in which it aired,\n",
    "- `imdb_rating` is the average rating of the episode among IMDB's users."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2b0e41",
   "metadata": {},
   "source": [
    "##### c.\n",
    "\n",
    "The first model you will fit is a moving average model. In this problem you will be tuning the moving average window size, $q$, to find the value that minimizes the average cross-validation root mean squared error (RMSE).\n",
    "\n",
    "Fill in the missing chunks of code to perform hyperparameter tuning for $q$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43554c0b",
   "metadata": {},
   "source": [
    "##### Sample Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03bf8168",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22271dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = TimeSeriesSplit(10, test_size=3)\n",
    "\n",
    "start = 2\n",
    "end = 31\n",
    "ma_rmses = np.zeros((10, len(range(start, end))))\n",
    "\n",
    "\n",
    "i = 0\n",
    "for train_index, test_index in cv.split(tv_train):\n",
    "    tv_tt = tv_train.iloc[train_index]\n",
    "    tv_ho = tv_train.iloc[test_index]\n",
    "    \n",
    "    j = 0\n",
    "    for q in range(start, end):\n",
    "        pred = tv_tt.imdb_rating[-q:].mean() * np.ones(len(tv_ho))\n",
    "        \n",
    "        ma_rmses[i,j] = np.sqrt(mean_squared_error(tv_ho.imdb_rating.values, pred))\n",
    "        j = j + 1\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2c628f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "plt.scatter(range(start,end), np.mean(ma_rmses, axis=0))\n",
    "\n",
    "plt.xlabel(\"Window Size\", fontsize=12)\n",
    "plt.ylabel(\"Average CV RMSE\", fontsize=12)\n",
    "\n",
    "plt.xticks(range(start, end, 3), fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f2d9b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The window size that minimized the avg. cv rmse was q = 13. It had a mean cv rmse of 0.46\n"
     ]
    }
   ],
   "source": [
    "print(\"The window size that minimized the avg. cv rmse\",\n",
    "      \"was q =\", \n",
    "      range(start,end)[np.argmin(np.mean(ma_rmses, axis=0))],\n",
    "      \"\\b.\",\n",
    "      \"It had a mean cv rmse of\", \n",
    "      np.round(np.min(np.mean(ma_rmses, axis=0)), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513947e5",
   "metadata": {},
   "source": [
    "##### d.\n",
    "\n",
    "The second model you will try is an exponential smoothing model.\n",
    "\n",
    "Because these data exhibit a trend but not seasonality we will fit a double exponential smoothing model. For this we will want to find the best $\\alpha$ (The smoothing on the time series) and $\\beta$ (the smoothing on the trend component).\n",
    "\n",
    "Fill in the missing code chunks below to perform a grid search for the values of $\\alpha$ and $\\beta$ that minimize the average CV RMSE. (Note that a grid search is what we call it when you perform hyperparameter tuning with a grid of possible hyperparameter values)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47375f5",
   "metadata": {},
   "source": [
    "##### Sample Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1431430d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.holtwinters import Holt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc8761d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha = 0.0 beta = 0.0\n",
      "alpha = 0.0 beta = 0.01\n",
      "alpha = 0.0 beta = 0.02\n",
      "alpha = 0.0 beta = 0.03\n",
      "alpha = 0.0 beta = 0.04\n",
      "alpha = 0.0 beta = 0.05\n",
      "alpha = 0.0 beta = 0.06\n",
      "alpha = 0.0 beta = 0.07\n",
      "alpha = 0.0 beta = 0.08\n",
      "alpha = 0.0 beta = 0.09\n",
      "alpha = 0.0 beta = 0.1\n",
      "alpha = 0.0 beta = 0.11\n",
      "alpha = 0.0 beta = 0.12\n",
      "alpha = 0.0 beta = 0.13\n",
      "alpha = 0.0 beta = 0.14\n",
      "alpha = 0.0 beta = 0.15\n",
      "alpha = 0.0 beta = 0.16\n",
      "alpha = 0.0 beta = 0.17\n",
      "alpha = 0.0 beta = 0.18\n",
      "alpha = 0.0 beta = 0.19\n",
      "alpha = 0.01 beta = 0.0\n",
      "alpha = 0.01 beta = 0.01\n",
      "alpha = 0.01 beta = 0.02\n",
      "alpha = 0.01 beta = 0.03\n",
      "alpha = 0.01 beta = 0.04\n",
      "alpha = 0.01 beta = 0.05\n",
      "alpha = 0.01 beta = 0.06\n",
      "alpha = 0.01 beta = 0.07\n",
      "alpha = 0.01 beta = 0.08\n",
      "alpha = 0.01 beta = 0.09\n",
      "alpha = 0.01 beta = 0.1\n",
      "alpha = 0.01 beta = 0.11\n",
      "alpha = 0.01 beta = 0.12\n",
      "alpha = 0.01 beta = 0.13\n",
      "alpha = 0.01 beta = 0.14\n",
      "alpha = 0.01 beta = 0.15\n",
      "alpha = 0.01 beta = 0.16\n",
      "alpha = 0.01 beta = 0.17\n",
      "alpha = 0.01 beta = 0.18\n",
      "alpha = 0.01 beta = 0.19\n",
      "alpha = 0.02 beta = 0.0\n",
      "alpha = 0.02 beta = 0.01\n",
      "alpha = 0.02 beta = 0.02\n",
      "alpha = 0.02 beta = 0.03\n",
      "alpha = 0.02 beta = 0.04\n",
      "alpha = 0.02 beta = 0.05\n",
      "alpha = 0.02 beta = 0.06\n",
      "alpha = 0.02 beta = 0.07\n",
      "alpha = 0.02 beta = 0.08\n",
      "alpha = 0.02 beta = 0.09\n",
      "alpha = 0.02 beta = 0.1\n",
      "alpha = 0.02 beta = 0.11\n",
      "alpha = 0.02 beta = 0.12\n",
      "alpha = 0.02 beta = 0.13\n",
      "alpha = 0.02 beta = 0.14\n",
      "alpha = 0.02 beta = 0.15\n",
      "alpha = 0.02 beta = 0.16\n",
      "alpha = 0.02 beta = 0.17\n",
      "alpha = 0.02 beta = 0.18\n",
      "alpha = 0.02 beta = 0.19\n",
      "alpha = 0.03 beta = 0.0\n",
      "alpha = 0.03 beta = 0.01\n",
      "alpha = 0.03 beta = 0.02\n",
      "alpha = 0.03 beta = 0.03\n",
      "alpha = 0.03 beta = 0.04\n",
      "alpha = 0.03 beta = 0.05\n",
      "alpha = 0.03 beta = 0.06\n",
      "alpha = 0.03 beta = 0.07\n",
      "alpha = 0.03 beta = 0.08\n",
      "alpha = 0.03 beta = 0.09\n",
      "alpha = 0.03 beta = 0.1\n",
      "alpha = 0.03 beta = 0.11\n",
      "alpha = 0.03 beta = 0.12\n",
      "alpha = 0.03 beta = 0.13\n",
      "alpha = 0.03 beta = 0.14\n",
      "alpha = 0.03 beta = 0.15\n",
      "alpha = 0.03 beta = 0.16\n",
      "alpha = 0.03 beta = 0.17\n",
      "alpha = 0.03 beta = 0.18\n",
      "alpha = 0.03 beta = 0.19\n",
      "alpha = 0.04 beta = 0.0\n",
      "alpha = 0.04 beta = 0.01\n",
      "alpha = 0.04 beta = 0.02\n",
      "alpha = 0.04 beta = 0.03\n",
      "alpha = 0.04 beta = 0.04\n",
      "alpha = 0.04 beta = 0.05\n",
      "alpha = 0.04 beta = 0.06\n",
      "alpha = 0.04 beta = 0.07\n",
      "alpha = 0.04 beta = 0.08\n",
      "alpha = 0.04 beta = 0.09\n",
      "alpha = 0.04 beta = 0.1\n",
      "alpha = 0.04 beta = 0.11\n",
      "alpha = 0.04 beta = 0.12\n",
      "alpha = 0.04 beta = 0.13\n",
      "alpha = 0.04 beta = 0.14\n",
      "alpha = 0.04 beta = 0.15\n",
      "alpha = 0.04 beta = 0.16\n",
      "alpha = 0.04 beta = 0.17\n",
      "alpha = 0.04 beta = 0.18\n",
      "alpha = 0.04 beta = 0.19\n",
      "alpha = 0.05 beta = 0.0\n",
      "alpha = 0.05 beta = 0.01\n",
      "alpha = 0.05 beta = 0.02\n",
      "alpha = 0.05 beta = 0.03\n",
      "alpha = 0.05 beta = 0.04\n",
      "alpha = 0.05 beta = 0.05\n",
      "alpha = 0.05 beta = 0.06\n",
      "alpha = 0.05 beta = 0.07\n",
      "alpha = 0.05 beta = 0.08\n",
      "alpha = 0.05 beta = 0.09\n",
      "alpha = 0.05 beta = 0.1\n",
      "alpha = 0.05 beta = 0.11\n",
      "alpha = 0.05 beta = 0.12\n",
      "alpha = 0.05 beta = 0.13\n",
      "alpha = 0.05 beta = 0.14\n",
      "alpha = 0.05 beta = 0.15\n",
      "alpha = 0.05 beta = 0.16\n",
      "alpha = 0.05 beta = 0.17\n",
      "alpha = 0.05 beta = 0.18\n",
      "alpha = 0.05 beta = 0.19\n",
      "alpha = 0.06 beta = 0.0\n",
      "alpha = 0.06 beta = 0.01\n",
      "alpha = 0.06 beta = 0.02\n",
      "alpha = 0.06 beta = 0.03\n",
      "alpha = 0.06 beta = 0.04\n",
      "alpha = 0.06 beta = 0.05\n",
      "alpha = 0.06 beta = 0.06\n",
      "alpha = 0.06 beta = 0.07\n",
      "alpha = 0.06 beta = 0.08\n",
      "alpha = 0.06 beta = 0.09\n",
      "alpha = 0.06 beta = 0.1\n",
      "alpha = 0.06 beta = 0.11\n",
      "alpha = 0.06 beta = 0.12\n",
      "alpha = 0.06 beta = 0.13\n",
      "alpha = 0.06 beta = 0.14\n",
      "alpha = 0.06 beta = 0.15\n",
      "alpha = 0.06 beta = 0.16\n",
      "alpha = 0.06 beta = 0.17\n",
      "alpha = 0.06 beta = 0.18\n",
      "alpha = 0.06 beta = 0.19\n",
      "alpha = 0.07 beta = 0.0\n",
      "alpha = 0.07 beta = 0.01\n",
      "alpha = 0.07 beta = 0.02\n",
      "alpha = 0.07 beta = 0.03\n",
      "alpha = 0.07 beta = 0.04\n",
      "alpha = 0.07 beta = 0.05\n",
      "alpha = 0.07 beta = 0.06\n",
      "alpha = 0.07 beta = 0.07\n",
      "alpha = 0.07 beta = 0.08\n",
      "alpha = 0.07 beta = 0.09\n",
      "alpha = 0.07 beta = 0.1\n",
      "alpha = 0.07 beta = 0.11\n",
      "alpha = 0.07 beta = 0.12\n",
      "alpha = 0.07 beta = 0.13\n",
      "alpha = 0.07 beta = 0.14\n",
      "alpha = 0.07 beta = 0.15\n",
      "alpha = 0.07 beta = 0.16\n",
      "alpha = 0.07 beta = 0.17\n",
      "alpha = 0.07 beta = 0.18\n",
      "alpha = 0.07 beta = 0.19\n",
      "alpha = 0.08 beta = 0.0\n",
      "alpha = 0.08 beta = 0.01\n",
      "alpha = 0.08 beta = 0.02\n",
      "alpha = 0.08 beta = 0.03\n",
      "alpha = 0.08 beta = 0.04\n",
      "alpha = 0.08 beta = 0.05\n",
      "alpha = 0.08 beta = 0.06\n",
      "alpha = 0.08 beta = 0.07\n",
      "alpha = 0.08 beta = 0.08\n",
      "alpha = 0.08 beta = 0.09\n",
      "alpha = 0.08 beta = 0.1\n",
      "alpha = 0.08 beta = 0.11\n",
      "alpha = 0.08 beta = 0.12\n",
      "alpha = 0.08 beta = 0.13\n",
      "alpha = 0.08 beta = 0.14\n",
      "alpha = 0.08 beta = 0.15\n",
      "alpha = 0.08 beta = 0.16\n",
      "alpha = 0.08 beta = 0.17\n",
      "alpha = 0.08 beta = 0.18\n",
      "alpha = 0.08 beta = 0.19\n",
      "alpha = 0.09 beta = 0.0\n",
      "alpha = 0.09 beta = 0.01\n",
      "alpha = 0.09 beta = 0.02\n",
      "alpha = 0.09 beta = 0.03\n",
      "alpha = 0.09 beta = 0.04\n",
      "alpha = 0.09 beta = 0.05\n",
      "alpha = 0.09 beta = 0.06\n",
      "alpha = 0.09 beta = 0.07\n",
      "alpha = 0.09 beta = 0.08\n",
      "alpha = 0.09 beta = 0.09\n",
      "alpha = 0.09 beta = 0.1\n",
      "alpha = 0.09 beta = 0.11\n",
      "alpha = 0.09 beta = 0.12\n",
      "alpha = 0.09 beta = 0.13\n",
      "alpha = 0.09 beta = 0.14\n",
      "alpha = 0.09 beta = 0.15\n",
      "alpha = 0.09 beta = 0.16\n",
      "alpha = 0.09 beta = 0.17\n",
      "alpha = 0.09 beta = 0.18\n",
      "alpha = 0.09 beta = 0.19\n",
      "alpha = 0.1 beta = 0.0\n",
      "alpha = 0.1 beta = 0.01\n",
      "alpha = 0.1 beta = 0.02\n",
      "alpha = 0.1 beta = 0.03\n",
      "alpha = 0.1 beta = 0.04\n",
      "alpha = 0.1 beta = 0.05\n",
      "alpha = 0.1 beta = 0.06\n",
      "alpha = 0.1 beta = 0.07\n",
      "alpha = 0.1 beta = 0.08\n",
      "alpha = 0.1 beta = 0.09\n",
      "alpha = 0.1 beta = 0.1\n",
      "alpha = 0.1 beta = 0.11\n",
      "alpha = 0.1 beta = 0.12\n",
      "alpha = 0.1 beta = 0.13\n",
      "alpha = 0.1 beta = 0.14\n",
      "alpha = 0.1 beta = 0.15\n",
      "alpha = 0.1 beta = 0.16\n",
      "alpha = 0.1 beta = 0.17\n",
      "alpha = 0.1 beta = 0.18\n",
      "alpha = 0.1 beta = 0.19\n",
      "alpha = 0.11 beta = 0.0\n",
      "alpha = 0.11 beta = 0.01\n",
      "alpha = 0.11 beta = 0.02\n",
      "alpha = 0.11 beta = 0.03\n",
      "alpha = 0.11 beta = 0.04\n",
      "alpha = 0.11 beta = 0.05\n",
      "alpha = 0.11 beta = 0.06\n",
      "alpha = 0.11 beta = 0.07\n",
      "alpha = 0.11 beta = 0.08\n",
      "alpha = 0.11 beta = 0.09\n",
      "alpha = 0.11 beta = 0.1\n",
      "alpha = 0.11 beta = 0.11\n",
      "alpha = 0.11 beta = 0.12\n",
      "alpha = 0.11 beta = 0.13\n",
      "alpha = 0.11 beta = 0.14\n",
      "alpha = 0.11 beta = 0.15\n",
      "alpha = 0.11 beta = 0.16\n",
      "alpha = 0.11 beta = 0.17\n",
      "alpha = 0.11 beta = 0.18\n",
      "alpha = 0.11 beta = 0.19\n",
      "alpha = 0.12 beta = 0.0\n",
      "alpha = 0.12 beta = 0.01\n",
      "alpha = 0.12 beta = 0.02\n",
      "alpha = 0.12 beta = 0.03\n",
      "alpha = 0.12 beta = 0.04\n",
      "alpha = 0.12 beta = 0.05\n",
      "alpha = 0.12 beta = 0.06\n",
      "alpha = 0.12 beta = 0.07\n",
      "alpha = 0.12 beta = 0.08\n",
      "alpha = 0.12 beta = 0.09\n",
      "alpha = 0.12 beta = 0.1\n",
      "alpha = 0.12 beta = 0.11\n",
      "alpha = 0.12 beta = 0.12\n",
      "alpha = 0.12 beta = 0.13\n",
      "alpha = 0.12 beta = 0.14\n",
      "alpha = 0.12 beta = 0.15\n",
      "alpha = 0.12 beta = 0.16\n",
      "alpha = 0.12 beta = 0.17\n",
      "alpha = 0.12 beta = 0.18\n",
      "alpha = 0.12 beta = 0.19\n",
      "alpha = 0.13 beta = 0.0\n",
      "alpha = 0.13 beta = 0.01\n",
      "alpha = 0.13 beta = 0.02\n",
      "alpha = 0.13 beta = 0.03\n",
      "alpha = 0.13 beta = 0.04\n",
      "alpha = 0.13 beta = 0.05\n",
      "alpha = 0.13 beta = 0.06\n",
      "alpha = 0.13 beta = 0.07\n",
      "alpha = 0.13 beta = 0.08\n",
      "alpha = 0.13 beta = 0.09\n",
      "alpha = 0.13 beta = 0.1\n",
      "alpha = 0.13 beta = 0.11\n",
      "alpha = 0.13 beta = 0.12\n",
      "alpha = 0.13 beta = 0.13\n",
      "alpha = 0.13 beta = 0.14\n",
      "alpha = 0.13 beta = 0.15\n",
      "alpha = 0.13 beta = 0.16\n",
      "alpha = 0.13 beta = 0.17\n",
      "alpha = 0.13 beta = 0.18\n",
      "alpha = 0.13 beta = 0.19\n",
      "alpha = 0.14 beta = 0.0\n",
      "alpha = 0.14 beta = 0.01\n",
      "alpha = 0.14 beta = 0.02\n",
      "alpha = 0.14 beta = 0.03\n",
      "alpha = 0.14 beta = 0.04\n",
      "alpha = 0.14 beta = 0.05\n",
      "alpha = 0.14 beta = 0.06\n",
      "alpha = 0.14 beta = 0.07\n",
      "alpha = 0.14 beta = 0.08\n",
      "alpha = 0.14 beta = 0.09\n",
      "alpha = 0.14 beta = 0.1\n",
      "alpha = 0.14 beta = 0.11\n",
      "alpha = 0.14 beta = 0.12\n",
      "alpha = 0.14 beta = 0.13\n",
      "alpha = 0.14 beta = 0.14\n",
      "alpha = 0.14 beta = 0.15\n",
      "alpha = 0.14 beta = 0.16\n",
      "alpha = 0.14 beta = 0.17\n",
      "alpha = 0.14 beta = 0.18\n",
      "alpha = 0.14 beta = 0.19\n",
      "alpha = 0.15 beta = 0.0\n",
      "alpha = 0.15 beta = 0.01\n",
      "alpha = 0.15 beta = 0.02\n",
      "alpha = 0.15 beta = 0.03\n",
      "alpha = 0.15 beta = 0.04\n",
      "alpha = 0.15 beta = 0.05\n",
      "alpha = 0.15 beta = 0.06\n",
      "alpha = 0.15 beta = 0.07\n",
      "alpha = 0.15 beta = 0.08\n",
      "alpha = 0.15 beta = 0.09\n",
      "alpha = 0.15 beta = 0.1\n",
      "alpha = 0.15 beta = 0.11\n",
      "alpha = 0.15 beta = 0.12\n",
      "alpha = 0.15 beta = 0.13\n",
      "alpha = 0.15 beta = 0.14\n",
      "alpha = 0.15 beta = 0.15\n",
      "alpha = 0.15 beta = 0.16\n",
      "alpha = 0.15 beta = 0.17\n",
      "alpha = 0.15 beta = 0.18\n",
      "alpha = 0.15 beta = 0.19\n",
      "alpha = 0.16 beta = 0.0\n",
      "alpha = 0.16 beta = 0.01\n",
      "alpha = 0.16 beta = 0.02\n",
      "alpha = 0.16 beta = 0.03\n",
      "alpha = 0.16 beta = 0.04\n",
      "alpha = 0.16 beta = 0.05\n",
      "alpha = 0.16 beta = 0.06\n",
      "alpha = 0.16 beta = 0.07\n",
      "alpha = 0.16 beta = 0.08\n",
      "alpha = 0.16 beta = 0.09\n",
      "alpha = 0.16 beta = 0.1\n",
      "alpha = 0.16 beta = 0.11\n",
      "alpha = 0.16 beta = 0.12\n",
      "alpha = 0.16 beta = 0.13\n",
      "alpha = 0.16 beta = 0.14\n",
      "alpha = 0.16 beta = 0.15\n",
      "alpha = 0.16 beta = 0.16\n",
      "alpha = 0.16 beta = 0.17\n",
      "alpha = 0.16 beta = 0.18\n",
      "alpha = 0.16 beta = 0.19\n",
      "alpha = 0.17 beta = 0.0\n",
      "alpha = 0.17 beta = 0.01\n",
      "alpha = 0.17 beta = 0.02\n",
      "alpha = 0.17 beta = 0.03\n",
      "alpha = 0.17 beta = 0.04\n",
      "alpha = 0.17 beta = 0.05\n",
      "alpha = 0.17 beta = 0.06\n",
      "alpha = 0.17 beta = 0.07\n",
      "alpha = 0.17 beta = 0.08\n",
      "alpha = 0.17 beta = 0.09\n",
      "alpha = 0.17 beta = 0.1\n",
      "alpha = 0.17 beta = 0.11\n",
      "alpha = 0.17 beta = 0.12\n",
      "alpha = 0.17 beta = 0.13\n",
      "alpha = 0.17 beta = 0.14\n",
      "alpha = 0.17 beta = 0.15\n",
      "alpha = 0.17 beta = 0.16\n",
      "alpha = 0.17 beta = 0.17\n",
      "alpha = 0.17 beta = 0.18\n",
      "alpha = 0.17 beta = 0.19\n",
      "alpha = 0.18 beta = 0.0\n",
      "alpha = 0.18 beta = 0.01\n",
      "alpha = 0.18 beta = 0.02\n",
      "alpha = 0.18 beta = 0.03\n",
      "alpha = 0.18 beta = 0.04\n",
      "alpha = 0.18 beta = 0.05\n",
      "alpha = 0.18 beta = 0.06\n",
      "alpha = 0.18 beta = 0.07\n",
      "alpha = 0.18 beta = 0.08\n",
      "alpha = 0.18 beta = 0.09\n",
      "alpha = 0.18 beta = 0.1\n",
      "alpha = 0.18 beta = 0.11\n",
      "alpha = 0.18 beta = 0.12\n",
      "alpha = 0.18 beta = 0.13\n",
      "alpha = 0.18 beta = 0.14\n",
      "alpha = 0.18 beta = 0.15\n",
      "alpha = 0.18 beta = 0.16\n",
      "alpha = 0.18 beta = 0.17\n",
      "alpha = 0.18 beta = 0.18\n",
      "alpha = 0.18 beta = 0.19\n",
      "alpha = 0.19 beta = 0.0\n",
      "alpha = 0.19 beta = 0.01\n",
      "alpha = 0.19 beta = 0.02\n",
      "alpha = 0.19 beta = 0.03\n",
      "alpha = 0.19 beta = 0.04\n",
      "alpha = 0.19 beta = 0.05\n",
      "alpha = 0.19 beta = 0.06\n",
      "alpha = 0.19 beta = 0.07\n",
      "alpha = 0.19 beta = 0.08\n",
      "alpha = 0.19 beta = 0.09\n",
      "alpha = 0.19 beta = 0.1\n",
      "alpha = 0.19 beta = 0.11\n",
      "alpha = 0.19 beta = 0.12\n",
      "alpha = 0.19 beta = 0.13\n",
      "alpha = 0.19 beta = 0.14\n",
      "alpha = 0.19 beta = 0.15\n",
      "alpha = 0.19 beta = 0.16\n",
      "alpha = 0.19 beta = 0.17\n",
      "alpha = 0.19 beta = 0.18\n",
      "alpha = 0.19 beta = 0.19\n",
      "alpha = 0.0 beta = 0.0\n",
      "alpha = 0.0 beta = 0.01\n",
      "alpha = 0.0 beta = 0.02\n",
      "alpha = 0.0 beta = 0.03\n",
      "alpha = 0.0 beta = 0.04\n",
      "alpha = 0.0 beta = 0.05\n",
      "alpha = 0.0 beta = 0.06\n",
      "alpha = 0.0 beta = 0.07\n",
      "alpha = 0.0 beta = 0.08\n",
      "alpha = 0.0 beta = 0.09\n",
      "alpha = 0.0 beta = 0.1\n",
      "alpha = 0.0 beta = 0.11\n",
      "alpha = 0.0 beta = 0.12\n",
      "alpha = 0.0 beta = 0.13\n",
      "alpha = 0.0 beta = 0.14\n",
      "alpha = 0.0 beta = 0.15\n",
      "alpha = 0.0 beta = 0.16\n",
      "alpha = 0.0 beta = 0.17\n",
      "alpha = 0.0 beta = 0.18\n",
      "alpha = 0.0 beta = 0.19\n",
      "alpha = 0.01 beta = 0.0\n",
      "alpha = 0.01 beta = 0.01\n",
      "alpha = 0.01 beta = 0.02\n",
      "alpha = 0.01 beta = 0.03\n",
      "alpha = 0.01 beta = 0.04\n",
      "alpha = 0.01 beta = 0.05\n",
      "alpha = 0.01 beta = 0.06\n",
      "alpha = 0.01 beta = 0.07\n",
      "alpha = 0.01 beta = 0.08\n",
      "alpha = 0.01 beta = 0.09\n",
      "alpha = 0.01 beta = 0.1\n",
      "alpha = 0.01 beta = 0.11\n",
      "alpha = 0.01 beta = 0.12\n",
      "alpha = 0.01 beta = 0.13\n",
      "alpha = 0.01 beta = 0.14\n",
      "alpha = 0.01 beta = 0.15\n",
      "alpha = 0.01 beta = 0.16\n",
      "alpha = 0.01 beta = 0.17\n",
      "alpha = 0.01 beta = 0.18\n",
      "alpha = 0.01 beta = 0.19\n",
      "alpha = 0.02 beta = 0.0\n",
      "alpha = 0.02 beta = 0.01\n",
      "alpha = 0.02 beta = 0.02\n",
      "alpha = 0.02 beta = 0.03\n",
      "alpha = 0.02 beta = 0.04\n",
      "alpha = 0.02 beta = 0.05\n",
      "alpha = 0.02 beta = 0.06\n",
      "alpha = 0.02 beta = 0.07\n",
      "alpha = 0.02 beta = 0.08\n",
      "alpha = 0.02 beta = 0.09\n",
      "alpha = 0.02 beta = 0.1\n",
      "alpha = 0.02 beta = 0.11\n",
      "alpha = 0.02 beta = 0.12\n",
      "alpha = 0.02 beta = 0.13\n",
      "alpha = 0.02 beta = 0.14\n",
      "alpha = 0.02 beta = 0.15\n",
      "alpha = 0.02 beta = 0.16\n",
      "alpha = 0.02 beta = 0.17\n",
      "alpha = 0.02 beta = 0.18\n",
      "alpha = 0.02 beta = 0.19\n",
      "alpha = 0.03 beta = 0.0\n",
      "alpha = 0.03 beta = 0.01\n",
      "alpha = 0.03 beta = 0.02\n",
      "alpha = 0.03 beta = 0.03\n",
      "alpha = 0.03 beta = 0.04\n",
      "alpha = 0.03 beta = 0.05\n",
      "alpha = 0.03 beta = 0.06\n",
      "alpha = 0.03 beta = 0.07\n",
      "alpha = 0.03 beta = 0.08\n",
      "alpha = 0.03 beta = 0.09\n",
      "alpha = 0.03 beta = 0.1\n",
      "alpha = 0.03 beta = 0.11\n",
      "alpha = 0.03 beta = 0.12\n",
      "alpha = 0.03 beta = 0.13\n",
      "alpha = 0.03 beta = 0.14\n",
      "alpha = 0.03 beta = 0.15\n",
      "alpha = 0.03 beta = 0.16\n",
      "alpha = 0.03 beta = 0.17\n",
      "alpha = 0.03 beta = 0.18\n",
      "alpha = 0.03 beta = 0.19\n",
      "alpha = 0.04 beta = 0.0\n",
      "alpha = 0.04 beta = 0.01\n",
      "alpha = 0.04 beta = 0.02\n",
      "alpha = 0.04 beta = 0.03\n",
      "alpha = 0.04 beta = 0.04\n",
      "alpha = 0.04 beta = 0.05\n",
      "alpha = 0.04 beta = 0.06\n",
      "alpha = 0.04 beta = 0.07\n",
      "alpha = 0.04 beta = 0.08\n",
      "alpha = 0.04 beta = 0.09\n",
      "alpha = 0.04 beta = 0.1\n",
      "alpha = 0.04 beta = 0.11\n",
      "alpha = 0.04 beta = 0.12\n",
      "alpha = 0.04 beta = 0.13\n",
      "alpha = 0.04 beta = 0.14\n",
      "alpha = 0.04 beta = 0.15\n",
      "alpha = 0.04 beta = 0.16\n",
      "alpha = 0.04 beta = 0.17\n",
      "alpha = 0.04 beta = 0.18\n",
      "alpha = 0.04 beta = 0.19\n",
      "alpha = 0.05 beta = 0.0\n",
      "alpha = 0.05 beta = 0.01\n",
      "alpha = 0.05 beta = 0.02\n",
      "alpha = 0.05 beta = 0.03\n",
      "alpha = 0.05 beta = 0.04\n",
      "alpha = 0.05 beta = 0.05\n",
      "alpha = 0.05 beta = 0.06\n",
      "alpha = 0.05 beta = 0.07\n",
      "alpha = 0.05 beta = 0.08\n",
      "alpha = 0.05 beta = 0.09\n",
      "alpha = 0.05 beta = 0.1\n",
      "alpha = 0.05 beta = 0.11\n",
      "alpha = 0.05 beta = 0.12\n",
      "alpha = 0.05 beta = 0.13\n",
      "alpha = 0.05 beta = 0.14\n",
      "alpha = 0.05 beta = 0.15\n",
      "alpha = 0.05 beta = 0.16\n",
      "alpha = 0.05 beta = 0.17\n",
      "alpha = 0.05 beta = 0.18\n",
      "alpha = 0.05 beta = 0.19\n",
      "alpha = 0.06 beta = 0.0\n",
      "alpha = 0.06 beta = 0.01\n",
      "alpha = 0.06 beta = 0.02\n",
      "alpha = 0.06 beta = 0.03\n",
      "alpha = 0.06 beta = 0.04\n",
      "alpha = 0.06 beta = 0.05\n",
      "alpha = 0.06 beta = 0.06\n",
      "alpha = 0.06 beta = 0.07\n",
      "alpha = 0.06 beta = 0.08\n",
      "alpha = 0.06 beta = 0.09\n",
      "alpha = 0.06 beta = 0.1\n",
      "alpha = 0.06 beta = 0.11\n",
      "alpha = 0.06 beta = 0.12\n",
      "alpha = 0.06 beta = 0.13\n",
      "alpha = 0.06 beta = 0.14\n",
      "alpha = 0.06 beta = 0.15\n",
      "alpha = 0.06 beta = 0.16\n",
      "alpha = 0.06 beta = 0.17\n",
      "alpha = 0.06 beta = 0.18\n",
      "alpha = 0.06 beta = 0.19\n",
      "alpha = 0.07 beta = 0.0\n",
      "alpha = 0.07 beta = 0.01\n",
      "alpha = 0.07 beta = 0.02\n",
      "alpha = 0.07 beta = 0.03\n",
      "alpha = 0.07 beta = 0.04\n",
      "alpha = 0.07 beta = 0.05\n",
      "alpha = 0.07 beta = 0.06\n",
      "alpha = 0.07 beta = 0.07\n",
      "alpha = 0.07 beta = 0.08\n",
      "alpha = 0.07 beta = 0.09\n",
      "alpha = 0.07 beta = 0.1\n",
      "alpha = 0.07 beta = 0.11\n",
      "alpha = 0.07 beta = 0.12\n",
      "alpha = 0.07 beta = 0.13\n",
      "alpha = 0.07 beta = 0.14\n",
      "alpha = 0.07 beta = 0.15\n",
      "alpha = 0.07 beta = 0.16\n",
      "alpha = 0.07 beta = 0.17\n",
      "alpha = 0.07 beta = 0.18\n",
      "alpha = 0.07 beta = 0.19\n",
      "alpha = 0.08 beta = 0.0\n",
      "alpha = 0.08 beta = 0.01\n",
      "alpha = 0.08 beta = 0.02\n",
      "alpha = 0.08 beta = 0.03\n",
      "alpha = 0.08 beta = 0.04\n",
      "alpha = 0.08 beta = 0.05\n",
      "alpha = 0.08 beta = 0.06\n",
      "alpha = 0.08 beta = 0.07\n",
      "alpha = 0.08 beta = 0.08\n",
      "alpha = 0.08 beta = 0.09\n",
      "alpha = 0.08 beta = 0.1\n",
      "alpha = 0.08 beta = 0.11\n",
      "alpha = 0.08 beta = 0.12\n",
      "alpha = 0.08 beta = 0.13\n",
      "alpha = 0.08 beta = 0.14\n",
      "alpha = 0.08 beta = 0.15\n",
      "alpha = 0.08 beta = 0.16\n",
      "alpha = 0.08 beta = 0.17\n",
      "alpha = 0.08 beta = 0.18\n",
      "alpha = 0.08 beta = 0.19\n",
      "alpha = 0.09 beta = 0.0\n",
      "alpha = 0.09 beta = 0.01\n",
      "alpha = 0.09 beta = 0.02\n",
      "alpha = 0.09 beta = 0.03\n",
      "alpha = 0.09 beta = 0.04\n",
      "alpha = 0.09 beta = 0.05\n",
      "alpha = 0.09 beta = 0.06\n",
      "alpha = 0.09 beta = 0.07\n",
      "alpha = 0.09 beta = 0.08\n",
      "alpha = 0.09 beta = 0.09\n",
      "alpha = 0.09 beta = 0.1\n",
      "alpha = 0.09 beta = 0.11\n",
      "alpha = 0.09 beta = 0.12\n",
      "alpha = 0.09 beta = 0.13\n",
      "alpha = 0.09 beta = 0.14\n",
      "alpha = 0.09 beta = 0.15\n",
      "alpha = 0.09 beta = 0.16\n",
      "alpha = 0.09 beta = 0.17\n",
      "alpha = 0.09 beta = 0.18\n",
      "alpha = 0.09 beta = 0.19\n",
      "alpha = 0.1 beta = 0.0\n",
      "alpha = 0.1 beta = 0.01\n",
      "alpha = 0.1 beta = 0.02\n",
      "alpha = 0.1 beta = 0.03\n",
      "alpha = 0.1 beta = 0.04\n",
      "alpha = 0.1 beta = 0.05\n",
      "alpha = 0.1 beta = 0.06\n",
      "alpha = 0.1 beta = 0.07\n",
      "alpha = 0.1 beta = 0.08\n",
      "alpha = 0.1 beta = 0.09\n",
      "alpha = 0.1 beta = 0.1\n",
      "alpha = 0.1 beta = 0.11\n",
      "alpha = 0.1 beta = 0.12\n",
      "alpha = 0.1 beta = 0.13\n",
      "alpha = 0.1 beta = 0.14\n",
      "alpha = 0.1 beta = 0.15\n",
      "alpha = 0.1 beta = 0.16\n",
      "alpha = 0.1 beta = 0.17\n",
      "alpha = 0.1 beta = 0.18\n",
      "alpha = 0.1 beta = 0.19\n",
      "alpha = 0.11 beta = 0.0\n",
      "alpha = 0.11 beta = 0.01\n",
      "alpha = 0.11 beta = 0.02\n",
      "alpha = 0.11 beta = 0.03\n",
      "alpha = 0.11 beta = 0.04\n",
      "alpha = 0.11 beta = 0.05\n",
      "alpha = 0.11 beta = 0.06\n",
      "alpha = 0.11 beta = 0.07\n",
      "alpha = 0.11 beta = 0.08\n",
      "alpha = 0.11 beta = 0.09\n",
      "alpha = 0.11 beta = 0.1\n",
      "alpha = 0.11 beta = 0.11\n",
      "alpha = 0.11 beta = 0.12\n",
      "alpha = 0.11 beta = 0.13\n",
      "alpha = 0.11 beta = 0.14\n",
      "alpha = 0.11 beta = 0.15\n",
      "alpha = 0.11 beta = 0.16\n",
      "alpha = 0.11 beta = 0.17\n",
      "alpha = 0.11 beta = 0.18\n",
      "alpha = 0.11 beta = 0.19\n",
      "alpha = 0.12 beta = 0.0\n",
      "alpha = 0.12 beta = 0.01\n",
      "alpha = 0.12 beta = 0.02\n",
      "alpha = 0.12 beta = 0.03\n",
      "alpha = 0.12 beta = 0.04\n",
      "alpha = 0.12 beta = 0.05\n",
      "alpha = 0.12 beta = 0.06\n",
      "alpha = 0.12 beta = 0.07\n",
      "alpha = 0.12 beta = 0.08\n",
      "alpha = 0.12 beta = 0.09\n",
      "alpha = 0.12 beta = 0.1\n",
      "alpha = 0.12 beta = 0.11\n",
      "alpha = 0.12 beta = 0.12\n",
      "alpha = 0.12 beta = 0.13\n",
      "alpha = 0.12 beta = 0.14\n",
      "alpha = 0.12 beta = 0.15\n",
      "alpha = 0.12 beta = 0.16\n",
      "alpha = 0.12 beta = 0.17\n",
      "alpha = 0.12 beta = 0.18\n",
      "alpha = 0.12 beta = 0.19\n",
      "alpha = 0.13 beta = 0.0\n",
      "alpha = 0.13 beta = 0.01\n",
      "alpha = 0.13 beta = 0.02\n",
      "alpha = 0.13 beta = 0.03\n",
      "alpha = 0.13 beta = 0.04\n",
      "alpha = 0.13 beta = 0.05\n",
      "alpha = 0.13 beta = 0.06\n",
      "alpha = 0.13 beta = 0.07\n",
      "alpha = 0.13 beta = 0.08\n",
      "alpha = 0.13 beta = 0.09\n",
      "alpha = 0.13 beta = 0.1\n",
      "alpha = 0.13 beta = 0.11\n",
      "alpha = 0.13 beta = 0.12\n",
      "alpha = 0.13 beta = 0.13\n",
      "alpha = 0.13 beta = 0.14\n",
      "alpha = 0.13 beta = 0.15\n",
      "alpha = 0.13 beta = 0.16\n",
      "alpha = 0.13 beta = 0.17\n",
      "alpha = 0.13 beta = 0.18\n",
      "alpha = 0.13 beta = 0.19\n",
      "alpha = 0.14 beta = 0.0\n",
      "alpha = 0.14 beta = 0.01\n",
      "alpha = 0.14 beta = 0.02\n",
      "alpha = 0.14 beta = 0.03\n",
      "alpha = 0.14 beta = 0.04\n",
      "alpha = 0.14 beta = 0.05\n",
      "alpha = 0.14 beta = 0.06\n",
      "alpha = 0.14 beta = 0.07\n",
      "alpha = 0.14 beta = 0.08\n",
      "alpha = 0.14 beta = 0.09\n",
      "alpha = 0.14 beta = 0.1\n",
      "alpha = 0.14 beta = 0.11\n",
      "alpha = 0.14 beta = 0.12\n",
      "alpha = 0.14 beta = 0.13\n",
      "alpha = 0.14 beta = 0.14\n",
      "alpha = 0.14 beta = 0.15\n",
      "alpha = 0.14 beta = 0.16\n",
      "alpha = 0.14 beta = 0.17\n",
      "alpha = 0.14 beta = 0.18\n",
      "alpha = 0.14 beta = 0.19\n",
      "alpha = 0.15 beta = 0.0\n",
      "alpha = 0.15 beta = 0.01\n",
      "alpha = 0.15 beta = 0.02\n",
      "alpha = 0.15 beta = 0.03\n",
      "alpha = 0.15 beta = 0.04\n",
      "alpha = 0.15 beta = 0.05\n",
      "alpha = 0.15 beta = 0.06\n",
      "alpha = 0.15 beta = 0.07\n",
      "alpha = 0.15 beta = 0.08\n",
      "alpha = 0.15 beta = 0.09\n",
      "alpha = 0.15 beta = 0.1\n",
      "alpha = 0.15 beta = 0.11\n",
      "alpha = 0.15 beta = 0.12\n",
      "alpha = 0.15 beta = 0.13\n",
      "alpha = 0.15 beta = 0.14\n",
      "alpha = 0.15 beta = 0.15\n",
      "alpha = 0.15 beta = 0.16\n",
      "alpha = 0.15 beta = 0.17\n",
      "alpha = 0.15 beta = 0.18\n",
      "alpha = 0.15 beta = 0.19\n",
      "alpha = 0.16 beta = 0.0\n",
      "alpha = 0.16 beta = 0.01\n",
      "alpha = 0.16 beta = 0.02\n",
      "alpha = 0.16 beta = 0.03\n",
      "alpha = 0.16 beta = 0.04\n",
      "alpha = 0.16 beta = 0.05\n",
      "alpha = 0.16 beta = 0.06\n",
      "alpha = 0.16 beta = 0.07\n",
      "alpha = 0.16 beta = 0.08\n",
      "alpha = 0.16 beta = 0.09\n",
      "alpha = 0.16 beta = 0.1\n",
      "alpha = 0.16 beta = 0.11\n",
      "alpha = 0.16 beta = 0.12\n",
      "alpha = 0.16 beta = 0.13\n",
      "alpha = 0.16 beta = 0.14\n",
      "alpha = 0.16 beta = 0.15\n",
      "alpha = 0.16 beta = 0.16\n",
      "alpha = 0.16 beta = 0.17\n",
      "alpha = 0.16 beta = 0.18\n",
      "alpha = 0.16 beta = 0.19\n",
      "alpha = 0.17 beta = 0.0\n",
      "alpha = 0.17 beta = 0.01\n",
      "alpha = 0.17 beta = 0.02\n",
      "alpha = 0.17 beta = 0.03\n",
      "alpha = 0.17 beta = 0.04\n",
      "alpha = 0.17 beta = 0.05\n",
      "alpha = 0.17 beta = 0.06\n",
      "alpha = 0.17 beta = 0.07\n",
      "alpha = 0.17 beta = 0.08\n",
      "alpha = 0.17 beta = 0.09\n",
      "alpha = 0.17 beta = 0.1\n",
      "alpha = 0.17 beta = 0.11\n",
      "alpha = 0.17 beta = 0.12\n",
      "alpha = 0.17 beta = 0.13\n",
      "alpha = 0.17 beta = 0.14\n",
      "alpha = 0.17 beta = 0.15\n",
      "alpha = 0.17 beta = 0.16\n",
      "alpha = 0.17 beta = 0.17\n",
      "alpha = 0.17 beta = 0.18\n",
      "alpha = 0.17 beta = 0.19\n",
      "alpha = 0.18 beta = 0.0\n",
      "alpha = 0.18 beta = 0.01\n",
      "alpha = 0.18 beta = 0.02\n",
      "alpha = 0.18 beta = 0.03\n",
      "alpha = 0.18 beta = 0.04\n",
      "alpha = 0.18 beta = 0.05\n",
      "alpha = 0.18 beta = 0.06\n",
      "alpha = 0.18 beta = 0.07\n",
      "alpha = 0.18 beta = 0.08\n",
      "alpha = 0.18 beta = 0.09\n",
      "alpha = 0.18 beta = 0.1\n",
      "alpha = 0.18 beta = 0.11\n",
      "alpha = 0.18 beta = 0.12\n",
      "alpha = 0.18 beta = 0.13\n",
      "alpha = 0.18 beta = 0.14\n",
      "alpha = 0.18 beta = 0.15\n",
      "alpha = 0.18 beta = 0.16\n",
      "alpha = 0.18 beta = 0.17\n",
      "alpha = 0.18 beta = 0.18\n",
      "alpha = 0.18 beta = 0.19\n",
      "alpha = 0.19 beta = 0.0\n",
      "alpha = 0.19 beta = 0.01\n",
      "alpha = 0.19 beta = 0.02\n",
      "alpha = 0.19 beta = 0.03\n",
      "alpha = 0.19 beta = 0.04\n",
      "alpha = 0.19 beta = 0.05\n",
      "alpha = 0.19 beta = 0.06\n",
      "alpha = 0.19 beta = 0.07\n",
      "alpha = 0.19 beta = 0.08\n",
      "alpha = 0.19 beta = 0.09\n",
      "alpha = 0.19 beta = 0.1\n",
      "alpha = 0.19 beta = 0.11\n",
      "alpha = 0.19 beta = 0.12\n",
      "alpha = 0.19 beta = 0.13\n",
      "alpha = 0.19 beta = 0.14\n",
      "alpha = 0.19 beta = 0.15\n",
      "alpha = 0.19 beta = 0.16\n",
      "alpha = 0.19 beta = 0.17\n",
      "alpha = 0.19 beta = 0.18\n",
      "alpha = 0.19 beta = 0.19\n",
      "alpha = 0.0 beta = 0.0\n",
      "alpha = 0.0 beta = 0.01\n",
      "alpha = 0.0 beta = 0.02\n",
      "alpha = 0.0 beta = 0.03\n",
      "alpha = 0.0 beta = 0.04\n",
      "alpha = 0.0 beta = 0.05\n",
      "alpha = 0.0 beta = 0.06\n",
      "alpha = 0.0 beta = 0.07\n",
      "alpha = 0.0 beta = 0.08\n",
      "alpha = 0.0 beta = 0.09\n",
      "alpha = 0.0 beta = 0.1\n",
      "alpha = 0.0 beta = 0.11\n",
      "alpha = 0.0 beta = 0.12\n",
      "alpha = 0.0 beta = 0.13\n",
      "alpha = 0.0 beta = 0.14\n",
      "alpha = 0.0 beta = 0.15\n",
      "alpha = 0.0 beta = 0.16\n",
      "alpha = 0.0 beta = 0.17\n",
      "alpha = 0.0 beta = 0.18\n",
      "alpha = 0.0 beta = 0.19\n",
      "alpha = 0.01 beta = 0.0\n",
      "alpha = 0.01 beta = 0.01\n",
      "alpha = 0.01 beta = 0.02\n",
      "alpha = 0.01 beta = 0.03\n",
      "alpha = 0.01 beta = 0.04\n",
      "alpha = 0.01 beta = 0.05\n",
      "alpha = 0.01 beta = 0.06\n",
      "alpha = 0.01 beta = 0.07\n",
      "alpha = 0.01 beta = 0.08\n",
      "alpha = 0.01 beta = 0.09\n",
      "alpha = 0.01 beta = 0.1\n",
      "alpha = 0.01 beta = 0.11\n",
      "alpha = 0.01 beta = 0.12\n",
      "alpha = 0.01 beta = 0.13\n",
      "alpha = 0.01 beta = 0.14\n",
      "alpha = 0.01 beta = 0.15\n",
      "alpha = 0.01 beta = 0.16\n",
      "alpha = 0.01 beta = 0.17\n",
      "alpha = 0.01 beta = 0.18\n",
      "alpha = 0.01 beta = 0.19\n",
      "alpha = 0.02 beta = 0.0\n",
      "alpha = 0.02 beta = 0.01\n",
      "alpha = 0.02 beta = 0.02\n",
      "alpha = 0.02 beta = 0.03\n",
      "alpha = 0.02 beta = 0.04\n",
      "alpha = 0.02 beta = 0.05\n",
      "alpha = 0.02 beta = 0.06\n",
      "alpha = 0.02 beta = 0.07\n",
      "alpha = 0.02 beta = 0.08\n",
      "alpha = 0.02 beta = 0.09\n",
      "alpha = 0.02 beta = 0.1\n",
      "alpha = 0.02 beta = 0.11\n",
      "alpha = 0.02 beta = 0.12\n",
      "alpha = 0.02 beta = 0.13\n",
      "alpha = 0.02 beta = 0.14\n",
      "alpha = 0.02 beta = 0.15\n",
      "alpha = 0.02 beta = 0.16\n",
      "alpha = 0.02 beta = 0.17\n",
      "alpha = 0.02 beta = 0.18\n",
      "alpha = 0.02 beta = 0.19\n",
      "alpha = 0.03 beta = 0.0\n",
      "alpha = 0.03 beta = 0.01\n",
      "alpha = 0.03 beta = 0.02\n",
      "alpha = 0.03 beta = 0.03\n",
      "alpha = 0.03 beta = 0.04\n",
      "alpha = 0.03 beta = 0.05\n",
      "alpha = 0.03 beta = 0.06\n",
      "alpha = 0.03 beta = 0.07\n",
      "alpha = 0.03 beta = 0.08\n",
      "alpha = 0.03 beta = 0.09\n",
      "alpha = 0.03 beta = 0.1\n",
      "alpha = 0.03 beta = 0.11\n",
      "alpha = 0.03 beta = 0.12\n",
      "alpha = 0.03 beta = 0.13\n",
      "alpha = 0.03 beta = 0.14\n",
      "alpha = 0.03 beta = 0.15\n",
      "alpha = 0.03 beta = 0.16\n",
      "alpha = 0.03 beta = 0.17\n",
      "alpha = 0.03 beta = 0.18\n",
      "alpha = 0.03 beta = 0.19\n",
      "alpha = 0.04 beta = 0.0\n",
      "alpha = 0.04 beta = 0.01\n",
      "alpha = 0.04 beta = 0.02\n",
      "alpha = 0.04 beta = 0.03\n",
      "alpha = 0.04 beta = 0.04\n",
      "alpha = 0.04 beta = 0.05\n",
      "alpha = 0.04 beta = 0.06\n",
      "alpha = 0.04 beta = 0.07\n",
      "alpha = 0.04 beta = 0.08\n",
      "alpha = 0.04 beta = 0.09\n",
      "alpha = 0.04 beta = 0.1\n",
      "alpha = 0.04 beta = 0.11\n",
      "alpha = 0.04 beta = 0.12\n",
      "alpha = 0.04 beta = 0.13\n",
      "alpha = 0.04 beta = 0.14\n",
      "alpha = 0.04 beta = 0.15\n",
      "alpha = 0.04 beta = 0.16\n",
      "alpha = 0.04 beta = 0.17\n",
      "alpha = 0.04 beta = 0.18\n",
      "alpha = 0.04 beta = 0.19\n",
      "alpha = 0.05 beta = 0.0\n",
      "alpha = 0.05 beta = 0.01\n",
      "alpha = 0.05 beta = 0.02\n",
      "alpha = 0.05 beta = 0.03\n",
      "alpha = 0.05 beta = 0.04\n",
      "alpha = 0.05 beta = 0.05\n",
      "alpha = 0.05 beta = 0.06\n",
      "alpha = 0.05 beta = 0.07\n",
      "alpha = 0.05 beta = 0.08\n",
      "alpha = 0.05 beta = 0.09\n",
      "alpha = 0.05 beta = 0.1\n",
      "alpha = 0.05 beta = 0.11\n",
      "alpha = 0.05 beta = 0.12\n",
      "alpha = 0.05 beta = 0.13\n",
      "alpha = 0.05 beta = 0.14\n",
      "alpha = 0.05 beta = 0.15\n",
      "alpha = 0.05 beta = 0.16\n",
      "alpha = 0.05 beta = 0.17\n",
      "alpha = 0.05 beta = 0.18\n",
      "alpha = 0.05 beta = 0.19\n",
      "alpha = 0.06 beta = 0.0\n",
      "alpha = 0.06 beta = 0.01\n",
      "alpha = 0.06 beta = 0.02\n",
      "alpha = 0.06 beta = 0.03\n",
      "alpha = 0.06 beta = 0.04\n",
      "alpha = 0.06 beta = 0.05\n",
      "alpha = 0.06 beta = 0.06\n",
      "alpha = 0.06 beta = 0.07\n",
      "alpha = 0.06 beta = 0.08\n",
      "alpha = 0.06 beta = 0.09\n",
      "alpha = 0.06 beta = 0.1\n",
      "alpha = 0.06 beta = 0.11\n",
      "alpha = 0.06 beta = 0.12\n",
      "alpha = 0.06 beta = 0.13\n",
      "alpha = 0.06 beta = 0.14\n",
      "alpha = 0.06 beta = 0.15\n",
      "alpha = 0.06 beta = 0.16\n",
      "alpha = 0.06 beta = 0.17\n",
      "alpha = 0.06 beta = 0.18\n",
      "alpha = 0.06 beta = 0.19\n",
      "alpha = 0.07 beta = 0.0\n",
      "alpha = 0.07 beta = 0.01\n",
      "alpha = 0.07 beta = 0.02\n",
      "alpha = 0.07 beta = 0.03\n",
      "alpha = 0.07 beta = 0.04\n",
      "alpha = 0.07 beta = 0.05\n",
      "alpha = 0.07 beta = 0.06\n",
      "alpha = 0.07 beta = 0.07\n",
      "alpha = 0.07 beta = 0.08\n",
      "alpha = 0.07 beta = 0.09\n",
      "alpha = 0.07 beta = 0.1\n",
      "alpha = 0.07 beta = 0.11\n",
      "alpha = 0.07 beta = 0.12\n",
      "alpha = 0.07 beta = 0.13\n",
      "alpha = 0.07 beta = 0.14\n",
      "alpha = 0.07 beta = 0.15\n",
      "alpha = 0.07 beta = 0.16\n",
      "alpha = 0.07 beta = 0.17\n",
      "alpha = 0.07 beta = 0.18\n",
      "alpha = 0.07 beta = 0.19\n",
      "alpha = 0.08 beta = 0.0\n",
      "alpha = 0.08 beta = 0.01\n",
      "alpha = 0.08 beta = 0.02\n",
      "alpha = 0.08 beta = 0.03\n",
      "alpha = 0.08 beta = 0.04\n",
      "alpha = 0.08 beta = 0.05\n",
      "alpha = 0.08 beta = 0.06\n",
      "alpha = 0.08 beta = 0.07\n",
      "alpha = 0.08 beta = 0.08\n",
      "alpha = 0.08 beta = 0.09\n",
      "alpha = 0.08 beta = 0.1\n",
      "alpha = 0.08 beta = 0.11\n",
      "alpha = 0.08 beta = 0.12\n",
      "alpha = 0.08 beta = 0.13\n",
      "alpha = 0.08 beta = 0.14\n",
      "alpha = 0.08 beta = 0.15\n",
      "alpha = 0.08 beta = 0.16\n",
      "alpha = 0.08 beta = 0.17\n",
      "alpha = 0.08 beta = 0.18\n",
      "alpha = 0.08 beta = 0.19\n",
      "alpha = 0.09 beta = 0.0\n",
      "alpha = 0.09 beta = 0.01\n",
      "alpha = 0.09 beta = 0.02\n",
      "alpha = 0.09 beta = 0.03\n",
      "alpha = 0.09 beta = 0.04\n",
      "alpha = 0.09 beta = 0.05\n",
      "alpha = 0.09 beta = 0.06\n",
      "alpha = 0.09 beta = 0.07\n",
      "alpha = 0.09 beta = 0.08\n",
      "alpha = 0.09 beta = 0.09\n",
      "alpha = 0.09 beta = 0.1\n",
      "alpha = 0.09 beta = 0.11\n",
      "alpha = 0.09 beta = 0.12\n",
      "alpha = 0.09 beta = 0.13\n",
      "alpha = 0.09 beta = 0.14\n",
      "alpha = 0.09 beta = 0.15\n",
      "alpha = 0.09 beta = 0.16\n",
      "alpha = 0.09 beta = 0.17\n",
      "alpha = 0.09 beta = 0.18\n",
      "alpha = 0.09 beta = 0.19\n",
      "alpha = 0.1 beta = 0.0\n",
      "alpha = 0.1 beta = 0.01\n",
      "alpha = 0.1 beta = 0.02\n",
      "alpha = 0.1 beta = 0.03\n",
      "alpha = 0.1 beta = 0.04\n",
      "alpha = 0.1 beta = 0.05\n",
      "alpha = 0.1 beta = 0.06\n",
      "alpha = 0.1 beta = 0.07\n",
      "alpha = 0.1 beta = 0.08\n",
      "alpha = 0.1 beta = 0.09\n",
      "alpha = 0.1 beta = 0.1\n",
      "alpha = 0.1 beta = 0.11\n",
      "alpha = 0.1 beta = 0.12\n",
      "alpha = 0.1 beta = 0.13\n",
      "alpha = 0.1 beta = 0.14\n",
      "alpha = 0.1 beta = 0.15\n",
      "alpha = 0.1 beta = 0.16\n",
      "alpha = 0.1 beta = 0.17\n",
      "alpha = 0.1 beta = 0.18\n",
      "alpha = 0.1 beta = 0.19\n",
      "alpha = 0.11 beta = 0.0\n",
      "alpha = 0.11 beta = 0.01\n",
      "alpha = 0.11 beta = 0.02\n",
      "alpha = 0.11 beta = 0.03\n",
      "alpha = 0.11 beta = 0.04\n",
      "alpha = 0.11 beta = 0.05\n",
      "alpha = 0.11 beta = 0.06\n",
      "alpha = 0.11 beta = 0.07\n",
      "alpha = 0.11 beta = 0.08\n",
      "alpha = 0.11 beta = 0.09\n",
      "alpha = 0.11 beta = 0.1\n",
      "alpha = 0.11 beta = 0.11\n",
      "alpha = 0.11 beta = 0.12\n",
      "alpha = 0.11 beta = 0.13\n",
      "alpha = 0.11 beta = 0.14\n",
      "alpha = 0.11 beta = 0.15\n",
      "alpha = 0.11 beta = 0.16\n",
      "alpha = 0.11 beta = 0.17\n",
      "alpha = 0.11 beta = 0.18\n",
      "alpha = 0.11 beta = 0.19\n",
      "alpha = 0.12 beta = 0.0\n",
      "alpha = 0.12 beta = 0.01\n",
      "alpha = 0.12 beta = 0.02\n",
      "alpha = 0.12 beta = 0.03\n",
      "alpha = 0.12 beta = 0.04\n",
      "alpha = 0.12 beta = 0.05\n",
      "alpha = 0.12 beta = 0.06\n",
      "alpha = 0.12 beta = 0.07\n",
      "alpha = 0.12 beta = 0.08\n",
      "alpha = 0.12 beta = 0.09\n",
      "alpha = 0.12 beta = 0.1\n",
      "alpha = 0.12 beta = 0.11\n",
      "alpha = 0.12 beta = 0.12\n",
      "alpha = 0.12 beta = 0.13\n",
      "alpha = 0.12 beta = 0.14\n",
      "alpha = 0.12 beta = 0.15\n",
      "alpha = 0.12 beta = 0.16\n",
      "alpha = 0.12 beta = 0.17\n",
      "alpha = 0.12 beta = 0.18\n",
      "alpha = 0.12 beta = 0.19\n",
      "alpha = 0.13 beta = 0.0\n",
      "alpha = 0.13 beta = 0.01\n",
      "alpha = 0.13 beta = 0.02\n",
      "alpha = 0.13 beta = 0.03\n",
      "alpha = 0.13 beta = 0.04\n",
      "alpha = 0.13 beta = 0.05\n",
      "alpha = 0.13 beta = 0.06\n",
      "alpha = 0.13 beta = 0.07\n",
      "alpha = 0.13 beta = 0.08\n",
      "alpha = 0.13 beta = 0.09\n",
      "alpha = 0.13 beta = 0.1\n",
      "alpha = 0.13 beta = 0.11\n",
      "alpha = 0.13 beta = 0.12\n",
      "alpha = 0.13 beta = 0.13\n",
      "alpha = 0.13 beta = 0.14\n",
      "alpha = 0.13 beta = 0.15\n",
      "alpha = 0.13 beta = 0.16\n",
      "alpha = 0.13 beta = 0.17\n",
      "alpha = 0.13 beta = 0.18\n",
      "alpha = 0.13 beta = 0.19\n",
      "alpha = 0.14 beta = 0.0\n",
      "alpha = 0.14 beta = 0.01\n",
      "alpha = 0.14 beta = 0.02\n",
      "alpha = 0.14 beta = 0.03\n",
      "alpha = 0.14 beta = 0.04\n",
      "alpha = 0.14 beta = 0.05\n",
      "alpha = 0.14 beta = 0.06\n",
      "alpha = 0.14 beta = 0.07\n",
      "alpha = 0.14 beta = 0.08\n",
      "alpha = 0.14 beta = 0.09\n",
      "alpha = 0.14 beta = 0.1\n",
      "alpha = 0.14 beta = 0.11\n",
      "alpha = 0.14 beta = 0.12\n",
      "alpha = 0.14 beta = 0.13\n",
      "alpha = 0.14 beta = 0.14\n",
      "alpha = 0.14 beta = 0.15\n",
      "alpha = 0.14 beta = 0.16\n",
      "alpha = 0.14 beta = 0.17\n",
      "alpha = 0.14 beta = 0.18\n",
      "alpha = 0.14 beta = 0.19\n",
      "alpha = 0.15 beta = 0.0\n",
      "alpha = 0.15 beta = 0.01\n",
      "alpha = 0.15 beta = 0.02\n",
      "alpha = 0.15 beta = 0.03\n",
      "alpha = 0.15 beta = 0.04\n",
      "alpha = 0.15 beta = 0.05\n",
      "alpha = 0.15 beta = 0.06\n",
      "alpha = 0.15 beta = 0.07\n",
      "alpha = 0.15 beta = 0.08\n",
      "alpha = 0.15 beta = 0.09\n",
      "alpha = 0.15 beta = 0.1\n",
      "alpha = 0.15 beta = 0.11\n",
      "alpha = 0.15 beta = 0.12\n",
      "alpha = 0.15 beta = 0.13\n",
      "alpha = 0.15 beta = 0.14\n",
      "alpha = 0.15 beta = 0.15\n",
      "alpha = 0.15 beta = 0.16\n",
      "alpha = 0.15 beta = 0.17\n",
      "alpha = 0.15 beta = 0.18\n",
      "alpha = 0.15 beta = 0.19\n",
      "alpha = 0.16 beta = 0.0\n",
      "alpha = 0.16 beta = 0.01\n",
      "alpha = 0.16 beta = 0.02\n",
      "alpha = 0.16 beta = 0.03\n",
      "alpha = 0.16 beta = 0.04\n",
      "alpha = 0.16 beta = 0.05\n",
      "alpha = 0.16 beta = 0.06\n",
      "alpha = 0.16 beta = 0.07\n",
      "alpha = 0.16 beta = 0.08\n",
      "alpha = 0.16 beta = 0.09\n",
      "alpha = 0.16 beta = 0.1\n",
      "alpha = 0.16 beta = 0.11\n",
      "alpha = 0.16 beta = 0.12\n",
      "alpha = 0.16 beta = 0.13\n",
      "alpha = 0.16 beta = 0.14\n",
      "alpha = 0.16 beta = 0.15\n",
      "alpha = 0.16 beta = 0.16\n",
      "alpha = 0.16 beta = 0.17\n",
      "alpha = 0.16 beta = 0.18\n",
      "alpha = 0.16 beta = 0.19\n",
      "alpha = 0.17 beta = 0.0\n",
      "alpha = 0.17 beta = 0.01\n",
      "alpha = 0.17 beta = 0.02\n",
      "alpha = 0.17 beta = 0.03\n",
      "alpha = 0.17 beta = 0.04\n",
      "alpha = 0.17 beta = 0.05\n",
      "alpha = 0.17 beta = 0.06\n",
      "alpha = 0.17 beta = 0.07\n",
      "alpha = 0.17 beta = 0.08\n",
      "alpha = 0.17 beta = 0.09\n",
      "alpha = 0.17 beta = 0.1\n",
      "alpha = 0.17 beta = 0.11\n",
      "alpha = 0.17 beta = 0.12\n",
      "alpha = 0.17 beta = 0.13\n",
      "alpha = 0.17 beta = 0.14\n",
      "alpha = 0.17 beta = 0.15\n",
      "alpha = 0.17 beta = 0.16\n",
      "alpha = 0.17 beta = 0.17\n",
      "alpha = 0.17 beta = 0.18\n",
      "alpha = 0.17 beta = 0.19\n",
      "alpha = 0.18 beta = 0.0\n",
      "alpha = 0.18 beta = 0.01\n",
      "alpha = 0.18 beta = 0.02\n",
      "alpha = 0.18 beta = 0.03\n",
      "alpha = 0.18 beta = 0.04\n",
      "alpha = 0.18 beta = 0.05\n",
      "alpha = 0.18 beta = 0.06\n",
      "alpha = 0.18 beta = 0.07\n",
      "alpha = 0.18 beta = 0.08\n",
      "alpha = 0.18 beta = 0.09\n",
      "alpha = 0.18 beta = 0.1\n",
      "alpha = 0.18 beta = 0.11\n",
      "alpha = 0.18 beta = 0.12\n",
      "alpha = 0.18 beta = 0.13\n",
      "alpha = 0.18 beta = 0.14\n",
      "alpha = 0.18 beta = 0.15\n",
      "alpha = 0.18 beta = 0.16\n",
      "alpha = 0.18 beta = 0.17\n",
      "alpha = 0.18 beta = 0.18\n",
      "alpha = 0.18 beta = 0.19\n",
      "alpha = 0.19 beta = 0.0\n",
      "alpha = 0.19 beta = 0.01\n",
      "alpha = 0.19 beta = 0.02\n",
      "alpha = 0.19 beta = 0.03\n",
      "alpha = 0.19 beta = 0.04\n",
      "alpha = 0.19 beta = 0.05\n",
      "alpha = 0.19 beta = 0.06\n",
      "alpha = 0.19 beta = 0.07\n",
      "alpha = 0.19 beta = 0.08\n",
      "alpha = 0.19 beta = 0.09\n",
      "alpha = 0.19 beta = 0.1\n",
      "alpha = 0.19 beta = 0.11\n",
      "alpha = 0.19 beta = 0.12\n",
      "alpha = 0.19 beta = 0.13\n",
      "alpha = 0.19 beta = 0.14\n",
      "alpha = 0.19 beta = 0.15\n",
      "alpha = 0.19 beta = 0.16\n",
      "alpha = 0.19 beta = 0.17\n",
      "alpha = 0.19 beta = 0.18\n",
      "alpha = 0.19 beta = 0.19\n",
      "alpha = 0.0 beta = 0.0\n",
      "alpha = 0.0 beta = 0.01\n",
      "alpha = 0.0 beta = 0.02\n",
      "alpha = 0.0 beta = 0.03\n",
      "alpha = 0.0 beta = 0.04\n",
      "alpha = 0.0 beta = 0.05\n",
      "alpha = 0.0 beta = 0.06\n",
      "alpha = 0.0 beta = 0.07\n",
      "alpha = 0.0 beta = 0.08\n",
      "alpha = 0.0 beta = 0.09\n",
      "alpha = 0.0 beta = 0.1\n",
      "alpha = 0.0 beta = 0.11\n",
      "alpha = 0.0 beta = 0.12\n",
      "alpha = 0.0 beta = 0.13\n",
      "alpha = 0.0 beta = 0.14\n",
      "alpha = 0.0 beta = 0.15\n",
      "alpha = 0.0 beta = 0.16\n",
      "alpha = 0.0 beta = 0.17\n",
      "alpha = 0.0 beta = 0.18\n",
      "alpha = 0.0 beta = 0.19\n",
      "alpha = 0.01 beta = 0.0\n",
      "alpha = 0.01 beta = 0.01\n",
      "alpha = 0.01 beta = 0.02\n",
      "alpha = 0.01 beta = 0.03\n",
      "alpha = 0.01 beta = 0.04\n",
      "alpha = 0.01 beta = 0.05\n",
      "alpha = 0.01 beta = 0.06\n",
      "alpha = 0.01 beta = 0.07\n",
      "alpha = 0.01 beta = 0.08\n",
      "alpha = 0.01 beta = 0.09\n",
      "alpha = 0.01 beta = 0.1\n",
      "alpha = 0.01 beta = 0.11\n",
      "alpha = 0.01 beta = 0.12\n",
      "alpha = 0.01 beta = 0.13\n",
      "alpha = 0.01 beta = 0.14\n",
      "alpha = 0.01 beta = 0.15\n",
      "alpha = 0.01 beta = 0.16\n",
      "alpha = 0.01 beta = 0.17\n",
      "alpha = 0.01 beta = 0.18\n",
      "alpha = 0.01 beta = 0.19\n",
      "alpha = 0.02 beta = 0.0\n",
      "alpha = 0.02 beta = 0.01\n",
      "alpha = 0.02 beta = 0.02\n",
      "alpha = 0.02 beta = 0.03\n",
      "alpha = 0.02 beta = 0.04\n",
      "alpha = 0.02 beta = 0.05\n",
      "alpha = 0.02 beta = 0.06\n",
      "alpha = 0.02 beta = 0.07\n",
      "alpha = 0.02 beta = 0.08\n",
      "alpha = 0.02 beta = 0.09\n",
      "alpha = 0.02 beta = 0.1\n",
      "alpha = 0.02 beta = 0.11\n",
      "alpha = 0.02 beta = 0.12\n",
      "alpha = 0.02 beta = 0.13\n",
      "alpha = 0.02 beta = 0.14\n",
      "alpha = 0.02 beta = 0.15\n",
      "alpha = 0.02 beta = 0.16\n",
      "alpha = 0.02 beta = 0.17\n",
      "alpha = 0.02 beta = 0.18\n",
      "alpha = 0.02 beta = 0.19\n",
      "alpha = 0.03 beta = 0.0\n",
      "alpha = 0.03 beta = 0.01\n",
      "alpha = 0.03 beta = 0.02\n",
      "alpha = 0.03 beta = 0.03\n",
      "alpha = 0.03 beta = 0.04\n",
      "alpha = 0.03 beta = 0.05\n",
      "alpha = 0.03 beta = 0.06\n",
      "alpha = 0.03 beta = 0.07\n",
      "alpha = 0.03 beta = 0.08\n",
      "alpha = 0.03 beta = 0.09\n",
      "alpha = 0.03 beta = 0.1\n",
      "alpha = 0.03 beta = 0.11\n",
      "alpha = 0.03 beta = 0.12\n",
      "alpha = 0.03 beta = 0.13\n",
      "alpha = 0.03 beta = 0.14\n",
      "alpha = 0.03 beta = 0.15\n",
      "alpha = 0.03 beta = 0.16\n",
      "alpha = 0.03 beta = 0.17\n",
      "alpha = 0.03 beta = 0.18\n",
      "alpha = 0.03 beta = 0.19\n",
      "alpha = 0.04 beta = 0.0\n",
      "alpha = 0.04 beta = 0.01\n",
      "alpha = 0.04 beta = 0.02\n",
      "alpha = 0.04 beta = 0.03\n",
      "alpha = 0.04 beta = 0.04\n",
      "alpha = 0.04 beta = 0.05\n",
      "alpha = 0.04 beta = 0.06\n",
      "alpha = 0.04 beta = 0.07\n",
      "alpha = 0.04 beta = 0.08\n",
      "alpha = 0.04 beta = 0.09\n",
      "alpha = 0.04 beta = 0.1\n",
      "alpha = 0.04 beta = 0.11\n",
      "alpha = 0.04 beta = 0.12\n",
      "alpha = 0.04 beta = 0.13\n",
      "alpha = 0.04 beta = 0.14\n",
      "alpha = 0.04 beta = 0.15\n",
      "alpha = 0.04 beta = 0.16\n",
      "alpha = 0.04 beta = 0.17\n",
      "alpha = 0.04 beta = 0.18\n",
      "alpha = 0.04 beta = 0.19\n",
      "alpha = 0.05 beta = 0.0\n",
      "alpha = 0.05 beta = 0.01\n",
      "alpha = 0.05 beta = 0.02\n",
      "alpha = 0.05 beta = 0.03\n",
      "alpha = 0.05 beta = 0.04\n",
      "alpha = 0.05 beta = 0.05\n",
      "alpha = 0.05 beta = 0.06\n",
      "alpha = 0.05 beta = 0.07\n",
      "alpha = 0.05 beta = 0.08\n",
      "alpha = 0.05 beta = 0.09\n",
      "alpha = 0.05 beta = 0.1\n",
      "alpha = 0.05 beta = 0.11\n",
      "alpha = 0.05 beta = 0.12\n",
      "alpha = 0.05 beta = 0.13\n",
      "alpha = 0.05 beta = 0.14\n",
      "alpha = 0.05 beta = 0.15\n",
      "alpha = 0.05 beta = 0.16\n",
      "alpha = 0.05 beta = 0.17\n",
      "alpha = 0.05 beta = 0.18\n",
      "alpha = 0.05 beta = 0.19\n",
      "alpha = 0.06 beta = 0.0\n",
      "alpha = 0.06 beta = 0.01\n",
      "alpha = 0.06 beta = 0.02\n",
      "alpha = 0.06 beta = 0.03\n",
      "alpha = 0.06 beta = 0.04\n",
      "alpha = 0.06 beta = 0.05\n",
      "alpha = 0.06 beta = 0.06\n",
      "alpha = 0.06 beta = 0.07\n",
      "alpha = 0.06 beta = 0.08\n",
      "alpha = 0.06 beta = 0.09\n",
      "alpha = 0.06 beta = 0.1\n",
      "alpha = 0.06 beta = 0.11\n",
      "alpha = 0.06 beta = 0.12\n",
      "alpha = 0.06 beta = 0.13\n",
      "alpha = 0.06 beta = 0.14\n",
      "alpha = 0.06 beta = 0.15\n",
      "alpha = 0.06 beta = 0.16\n",
      "alpha = 0.06 beta = 0.17\n",
      "alpha = 0.06 beta = 0.18\n",
      "alpha = 0.06 beta = 0.19\n",
      "alpha = 0.07 beta = 0.0\n",
      "alpha = 0.07 beta = 0.01\n",
      "alpha = 0.07 beta = 0.02\n",
      "alpha = 0.07 beta = 0.03\n",
      "alpha = 0.07 beta = 0.04\n",
      "alpha = 0.07 beta = 0.05\n",
      "alpha = 0.07 beta = 0.06\n",
      "alpha = 0.07 beta = 0.07\n",
      "alpha = 0.07 beta = 0.08\n",
      "alpha = 0.07 beta = 0.09\n",
      "alpha = 0.07 beta = 0.1\n",
      "alpha = 0.07 beta = 0.11\n",
      "alpha = 0.07 beta = 0.12\n",
      "alpha = 0.07 beta = 0.13\n",
      "alpha = 0.07 beta = 0.14\n",
      "alpha = 0.07 beta = 0.15\n",
      "alpha = 0.07 beta = 0.16\n",
      "alpha = 0.07 beta = 0.17\n",
      "alpha = 0.07 beta = 0.18\n",
      "alpha = 0.07 beta = 0.19\n",
      "alpha = 0.08 beta = 0.0\n",
      "alpha = 0.08 beta = 0.01\n",
      "alpha = 0.08 beta = 0.02\n",
      "alpha = 0.08 beta = 0.03\n",
      "alpha = 0.08 beta = 0.04\n",
      "alpha = 0.08 beta = 0.05\n",
      "alpha = 0.08 beta = 0.06\n",
      "alpha = 0.08 beta = 0.07\n",
      "alpha = 0.08 beta = 0.08\n",
      "alpha = 0.08 beta = 0.09\n",
      "alpha = 0.08 beta = 0.1\n",
      "alpha = 0.08 beta = 0.11\n",
      "alpha = 0.08 beta = 0.12\n",
      "alpha = 0.08 beta = 0.13\n",
      "alpha = 0.08 beta = 0.14\n",
      "alpha = 0.08 beta = 0.15\n",
      "alpha = 0.08 beta = 0.16\n",
      "alpha = 0.08 beta = 0.17\n",
      "alpha = 0.08 beta = 0.18\n",
      "alpha = 0.08 beta = 0.19\n",
      "alpha = 0.09 beta = 0.0\n",
      "alpha = 0.09 beta = 0.01\n",
      "alpha = 0.09 beta = 0.02\n",
      "alpha = 0.09 beta = 0.03\n",
      "alpha = 0.09 beta = 0.04\n",
      "alpha = 0.09 beta = 0.05\n",
      "alpha = 0.09 beta = 0.06\n",
      "alpha = 0.09 beta = 0.07\n",
      "alpha = 0.09 beta = 0.08\n",
      "alpha = 0.09 beta = 0.09\n",
      "alpha = 0.09 beta = 0.1\n",
      "alpha = 0.09 beta = 0.11\n",
      "alpha = 0.09 beta = 0.12\n",
      "alpha = 0.09 beta = 0.13\n",
      "alpha = 0.09 beta = 0.14\n",
      "alpha = 0.09 beta = 0.15\n",
      "alpha = 0.09 beta = 0.16\n",
      "alpha = 0.09 beta = 0.17\n",
      "alpha = 0.09 beta = 0.18\n",
      "alpha = 0.09 beta = 0.19\n",
      "alpha = 0.1 beta = 0.0\n",
      "alpha = 0.1 beta = 0.01\n",
      "alpha = 0.1 beta = 0.02\n",
      "alpha = 0.1 beta = 0.03\n",
      "alpha = 0.1 beta = 0.04\n",
      "alpha = 0.1 beta = 0.05\n",
      "alpha = 0.1 beta = 0.06\n",
      "alpha = 0.1 beta = 0.07\n",
      "alpha = 0.1 beta = 0.08\n",
      "alpha = 0.1 beta = 0.09\n",
      "alpha = 0.1 beta = 0.1\n",
      "alpha = 0.1 beta = 0.11\n",
      "alpha = 0.1 beta = 0.12\n",
      "alpha = 0.1 beta = 0.13\n",
      "alpha = 0.1 beta = 0.14\n",
      "alpha = 0.1 beta = 0.15\n",
      "alpha = 0.1 beta = 0.16\n",
      "alpha = 0.1 beta = 0.17\n",
      "alpha = 0.1 beta = 0.18\n",
      "alpha = 0.1 beta = 0.19\n",
      "alpha = 0.11 beta = 0.0\n",
      "alpha = 0.11 beta = 0.01\n",
      "alpha = 0.11 beta = 0.02\n",
      "alpha = 0.11 beta = 0.03\n",
      "alpha = 0.11 beta = 0.04\n",
      "alpha = 0.11 beta = 0.05\n",
      "alpha = 0.11 beta = 0.06\n",
      "alpha = 0.11 beta = 0.07\n",
      "alpha = 0.11 beta = 0.08\n",
      "alpha = 0.11 beta = 0.09\n",
      "alpha = 0.11 beta = 0.1\n",
      "alpha = 0.11 beta = 0.11\n",
      "alpha = 0.11 beta = 0.12\n",
      "alpha = 0.11 beta = 0.13\n",
      "alpha = 0.11 beta = 0.14\n",
      "alpha = 0.11 beta = 0.15\n",
      "alpha = 0.11 beta = 0.16\n",
      "alpha = 0.11 beta = 0.17\n",
      "alpha = 0.11 beta = 0.18\n",
      "alpha = 0.11 beta = 0.19\n",
      "alpha = 0.12 beta = 0.0\n",
      "alpha = 0.12 beta = 0.01\n",
      "alpha = 0.12 beta = 0.02\n",
      "alpha = 0.12 beta = 0.03\n",
      "alpha = 0.12 beta = 0.04\n",
      "alpha = 0.12 beta = 0.05\n",
      "alpha = 0.12 beta = 0.06\n",
      "alpha = 0.12 beta = 0.07\n",
      "alpha = 0.12 beta = 0.08\n",
      "alpha = 0.12 beta = 0.09\n",
      "alpha = 0.12 beta = 0.1\n",
      "alpha = 0.12 beta = 0.11\n",
      "alpha = 0.12 beta = 0.12\n",
      "alpha = 0.12 beta = 0.13\n",
      "alpha = 0.12 beta = 0.14\n",
      "alpha = 0.12 beta = 0.15\n",
      "alpha = 0.12 beta = 0.16\n",
      "alpha = 0.12 beta = 0.17\n",
      "alpha = 0.12 beta = 0.18\n",
      "alpha = 0.12 beta = 0.19\n",
      "alpha = 0.13 beta = 0.0\n",
      "alpha = 0.13 beta = 0.01\n",
      "alpha = 0.13 beta = 0.02\n",
      "alpha = 0.13 beta = 0.03\n",
      "alpha = 0.13 beta = 0.04\n",
      "alpha = 0.13 beta = 0.05\n",
      "alpha = 0.13 beta = 0.06\n",
      "alpha = 0.13 beta = 0.07\n",
      "alpha = 0.13 beta = 0.08\n",
      "alpha = 0.13 beta = 0.09\n",
      "alpha = 0.13 beta = 0.1\n",
      "alpha = 0.13 beta = 0.11\n",
      "alpha = 0.13 beta = 0.12\n",
      "alpha = 0.13 beta = 0.13\n",
      "alpha = 0.13 beta = 0.14\n",
      "alpha = 0.13 beta = 0.15\n",
      "alpha = 0.13 beta = 0.16\n",
      "alpha = 0.13 beta = 0.17\n",
      "alpha = 0.13 beta = 0.18\n",
      "alpha = 0.13 beta = 0.19\n",
      "alpha = 0.14 beta = 0.0\n",
      "alpha = 0.14 beta = 0.01\n",
      "alpha = 0.14 beta = 0.02\n",
      "alpha = 0.14 beta = 0.03\n",
      "alpha = 0.14 beta = 0.04\n",
      "alpha = 0.14 beta = 0.05\n",
      "alpha = 0.14 beta = 0.06\n",
      "alpha = 0.14 beta = 0.07\n",
      "alpha = 0.14 beta = 0.08\n",
      "alpha = 0.14 beta = 0.09\n",
      "alpha = 0.14 beta = 0.1\n",
      "alpha = 0.14 beta = 0.11\n",
      "alpha = 0.14 beta = 0.12\n",
      "alpha = 0.14 beta = 0.13\n",
      "alpha = 0.14 beta = 0.14\n",
      "alpha = 0.14 beta = 0.15\n",
      "alpha = 0.14 beta = 0.16\n",
      "alpha = 0.14 beta = 0.17\n",
      "alpha = 0.14 beta = 0.18\n",
      "alpha = 0.14 beta = 0.19\n",
      "alpha = 0.15 beta = 0.0\n",
      "alpha = 0.15 beta = 0.01\n",
      "alpha = 0.15 beta = 0.02\n",
      "alpha = 0.15 beta = 0.03\n",
      "alpha = 0.15 beta = 0.04\n",
      "alpha = 0.15 beta = 0.05\n",
      "alpha = 0.15 beta = 0.06\n",
      "alpha = 0.15 beta = 0.07\n",
      "alpha = 0.15 beta = 0.08\n",
      "alpha = 0.15 beta = 0.09\n",
      "alpha = 0.15 beta = 0.1\n",
      "alpha = 0.15 beta = 0.11\n",
      "alpha = 0.15 beta = 0.12\n",
      "alpha = 0.15 beta = 0.13\n",
      "alpha = 0.15 beta = 0.14\n",
      "alpha = 0.15 beta = 0.15\n",
      "alpha = 0.15 beta = 0.16\n",
      "alpha = 0.15 beta = 0.17\n",
      "alpha = 0.15 beta = 0.18\n",
      "alpha = 0.15 beta = 0.19\n",
      "alpha = 0.16 beta = 0.0\n",
      "alpha = 0.16 beta = 0.01\n",
      "alpha = 0.16 beta = 0.02\n",
      "alpha = 0.16 beta = 0.03\n",
      "alpha = 0.16 beta = 0.04\n",
      "alpha = 0.16 beta = 0.05\n",
      "alpha = 0.16 beta = 0.06\n",
      "alpha = 0.16 beta = 0.07\n",
      "alpha = 0.16 beta = 0.08\n",
      "alpha = 0.16 beta = 0.09\n",
      "alpha = 0.16 beta = 0.1\n",
      "alpha = 0.16 beta = 0.11\n",
      "alpha = 0.16 beta = 0.12\n",
      "alpha = 0.16 beta = 0.13\n",
      "alpha = 0.16 beta = 0.14\n",
      "alpha = 0.16 beta = 0.15\n",
      "alpha = 0.16 beta = 0.16\n",
      "alpha = 0.16 beta = 0.17\n",
      "alpha = 0.16 beta = 0.18\n",
      "alpha = 0.16 beta = 0.19\n",
      "alpha = 0.17 beta = 0.0\n",
      "alpha = 0.17 beta = 0.01\n",
      "alpha = 0.17 beta = 0.02\n",
      "alpha = 0.17 beta = 0.03\n",
      "alpha = 0.17 beta = 0.04\n",
      "alpha = 0.17 beta = 0.05\n",
      "alpha = 0.17 beta = 0.06\n",
      "alpha = 0.17 beta = 0.07\n",
      "alpha = 0.17 beta = 0.08\n",
      "alpha = 0.17 beta = 0.09\n",
      "alpha = 0.17 beta = 0.1\n",
      "alpha = 0.17 beta = 0.11\n",
      "alpha = 0.17 beta = 0.12\n",
      "alpha = 0.17 beta = 0.13\n",
      "alpha = 0.17 beta = 0.14\n",
      "alpha = 0.17 beta = 0.15\n",
      "alpha = 0.17 beta = 0.16\n",
      "alpha = 0.17 beta = 0.17\n",
      "alpha = 0.17 beta = 0.18\n",
      "alpha = 0.17 beta = 0.19\n",
      "alpha = 0.18 beta = 0.0\n",
      "alpha = 0.18 beta = 0.01\n",
      "alpha = 0.18 beta = 0.02\n",
      "alpha = 0.18 beta = 0.03\n",
      "alpha = 0.18 beta = 0.04\n",
      "alpha = 0.18 beta = 0.05\n",
      "alpha = 0.18 beta = 0.06\n",
      "alpha = 0.18 beta = 0.07\n",
      "alpha = 0.18 beta = 0.08\n",
      "alpha = 0.18 beta = 0.09\n",
      "alpha = 0.18 beta = 0.1\n",
      "alpha = 0.18 beta = 0.11\n",
      "alpha = 0.18 beta = 0.12\n",
      "alpha = 0.18 beta = 0.13\n",
      "alpha = 0.18 beta = 0.14\n",
      "alpha = 0.18 beta = 0.15\n",
      "alpha = 0.18 beta = 0.16\n",
      "alpha = 0.18 beta = 0.17\n",
      "alpha = 0.18 beta = 0.18\n",
      "alpha = 0.18 beta = 0.19\n",
      "alpha = 0.19 beta = 0.0\n",
      "alpha = 0.19 beta = 0.01\n",
      "alpha = 0.19 beta = 0.02\n",
      "alpha = 0.19 beta = 0.03\n",
      "alpha = 0.19 beta = 0.04\n",
      "alpha = 0.19 beta = 0.05\n",
      "alpha = 0.19 beta = 0.06\n",
      "alpha = 0.19 beta = 0.07\n",
      "alpha = 0.19 beta = 0.08\n",
      "alpha = 0.19 beta = 0.09\n",
      "alpha = 0.19 beta = 0.1\n",
      "alpha = 0.19 beta = 0.11\n",
      "alpha = 0.19 beta = 0.12\n",
      "alpha = 0.19 beta = 0.13\n",
      "alpha = 0.19 beta = 0.14\n",
      "alpha = 0.19 beta = 0.15\n",
      "alpha = 0.19 beta = 0.16\n",
      "alpha = 0.19 beta = 0.17\n",
      "alpha = 0.19 beta = 0.18\n",
      "alpha = 0.19 beta = 0.19\n",
      "alpha = 0.0 beta = 0.0\n",
      "alpha = 0.0 beta = 0.01\n",
      "alpha = 0.0 beta = 0.02\n",
      "alpha = 0.0 beta = 0.03\n",
      "alpha = 0.0 beta = 0.04\n",
      "alpha = 0.0 beta = 0.05\n",
      "alpha = 0.0 beta = 0.06\n",
      "alpha = 0.0 beta = 0.07\n",
      "alpha = 0.0 beta = 0.08\n",
      "alpha = 0.0 beta = 0.09\n",
      "alpha = 0.0 beta = 0.1\n",
      "alpha = 0.0 beta = 0.11\n",
      "alpha = 0.0 beta = 0.12\n",
      "alpha = 0.0 beta = 0.13\n",
      "alpha = 0.0 beta = 0.14\n",
      "alpha = 0.0 beta = 0.15\n",
      "alpha = 0.0 beta = 0.16\n",
      "alpha = 0.0 beta = 0.17\n",
      "alpha = 0.0 beta = 0.18\n",
      "alpha = 0.0 beta = 0.19\n",
      "alpha = 0.01 beta = 0.0\n",
      "alpha = 0.01 beta = 0.01\n",
      "alpha = 0.01 beta = 0.02\n",
      "alpha = 0.01 beta = 0.03\n",
      "alpha = 0.01 beta = 0.04\n",
      "alpha = 0.01 beta = 0.05\n",
      "alpha = 0.01 beta = 0.06\n",
      "alpha = 0.01 beta = 0.07\n",
      "alpha = 0.01 beta = 0.08\n",
      "alpha = 0.01 beta = 0.09\n",
      "alpha = 0.01 beta = 0.1\n",
      "alpha = 0.01 beta = 0.11\n",
      "alpha = 0.01 beta = 0.12\n",
      "alpha = 0.01 beta = 0.13\n",
      "alpha = 0.01 beta = 0.14\n",
      "alpha = 0.01 beta = 0.15\n",
      "alpha = 0.01 beta = 0.16\n",
      "alpha = 0.01 beta = 0.17\n",
      "alpha = 0.01 beta = 0.18\n",
      "alpha = 0.01 beta = 0.19\n",
      "alpha = 0.02 beta = 0.0\n",
      "alpha = 0.02 beta = 0.01\n",
      "alpha = 0.02 beta = 0.02\n",
      "alpha = 0.02 beta = 0.03\n",
      "alpha = 0.02 beta = 0.04\n",
      "alpha = 0.02 beta = 0.05\n",
      "alpha = 0.02 beta = 0.06\n",
      "alpha = 0.02 beta = 0.07\n",
      "alpha = 0.02 beta = 0.08\n",
      "alpha = 0.02 beta = 0.09\n",
      "alpha = 0.02 beta = 0.1\n",
      "alpha = 0.02 beta = 0.11\n",
      "alpha = 0.02 beta = 0.12\n",
      "alpha = 0.02 beta = 0.13\n",
      "alpha = 0.02 beta = 0.14\n",
      "alpha = 0.02 beta = 0.15\n",
      "alpha = 0.02 beta = 0.16\n",
      "alpha = 0.02 beta = 0.17\n",
      "alpha = 0.02 beta = 0.18\n",
      "alpha = 0.02 beta = 0.19\n",
      "alpha = 0.03 beta = 0.0\n",
      "alpha = 0.03 beta = 0.01\n",
      "alpha = 0.03 beta = 0.02\n",
      "alpha = 0.03 beta = 0.03\n",
      "alpha = 0.03 beta = 0.04\n",
      "alpha = 0.03 beta = 0.05\n",
      "alpha = 0.03 beta = 0.06\n",
      "alpha = 0.03 beta = 0.07\n",
      "alpha = 0.03 beta = 0.08\n",
      "alpha = 0.03 beta = 0.09\n",
      "alpha = 0.03 beta = 0.1\n",
      "alpha = 0.03 beta = 0.11\n",
      "alpha = 0.03 beta = 0.12\n",
      "alpha = 0.03 beta = 0.13\n",
      "alpha = 0.03 beta = 0.14\n",
      "alpha = 0.03 beta = 0.15\n",
      "alpha = 0.03 beta = 0.16\n",
      "alpha = 0.03 beta = 0.17\n",
      "alpha = 0.03 beta = 0.18\n",
      "alpha = 0.03 beta = 0.19\n",
      "alpha = 0.04 beta = 0.0\n",
      "alpha = 0.04 beta = 0.01\n",
      "alpha = 0.04 beta = 0.02\n",
      "alpha = 0.04 beta = 0.03\n",
      "alpha = 0.04 beta = 0.04\n",
      "alpha = 0.04 beta = 0.05\n",
      "alpha = 0.04 beta = 0.06\n",
      "alpha = 0.04 beta = 0.07\n",
      "alpha = 0.04 beta = 0.08\n",
      "alpha = 0.04 beta = 0.09\n",
      "alpha = 0.04 beta = 0.1\n",
      "alpha = 0.04 beta = 0.11\n",
      "alpha = 0.04 beta = 0.12\n",
      "alpha = 0.04 beta = 0.13\n",
      "alpha = 0.04 beta = 0.14\n",
      "alpha = 0.04 beta = 0.15\n",
      "alpha = 0.04 beta = 0.16\n",
      "alpha = 0.04 beta = 0.17\n",
      "alpha = 0.04 beta = 0.18\n",
      "alpha = 0.04 beta = 0.19\n",
      "alpha = 0.05 beta = 0.0\n",
      "alpha = 0.05 beta = 0.01\n",
      "alpha = 0.05 beta = 0.02\n",
      "alpha = 0.05 beta = 0.03\n",
      "alpha = 0.05 beta = 0.04\n",
      "alpha = 0.05 beta = 0.05\n",
      "alpha = 0.05 beta = 0.06\n",
      "alpha = 0.05 beta = 0.07\n",
      "alpha = 0.05 beta = 0.08\n",
      "alpha = 0.05 beta = 0.09\n",
      "alpha = 0.05 beta = 0.1\n",
      "alpha = 0.05 beta = 0.11\n",
      "alpha = 0.05 beta = 0.12\n",
      "alpha = 0.05 beta = 0.13\n",
      "alpha = 0.05 beta = 0.14\n",
      "alpha = 0.05 beta = 0.15\n",
      "alpha = 0.05 beta = 0.16\n",
      "alpha = 0.05 beta = 0.17\n",
      "alpha = 0.05 beta = 0.18\n",
      "alpha = 0.05 beta = 0.19\n",
      "alpha = 0.06 beta = 0.0\n",
      "alpha = 0.06 beta = 0.01\n",
      "alpha = 0.06 beta = 0.02\n",
      "alpha = 0.06 beta = 0.03\n",
      "alpha = 0.06 beta = 0.04\n",
      "alpha = 0.06 beta = 0.05\n",
      "alpha = 0.06 beta = 0.06\n",
      "alpha = 0.06 beta = 0.07\n",
      "alpha = 0.06 beta = 0.08\n",
      "alpha = 0.06 beta = 0.09\n",
      "alpha = 0.06 beta = 0.1\n",
      "alpha = 0.06 beta = 0.11\n",
      "alpha = 0.06 beta = 0.12\n",
      "alpha = 0.06 beta = 0.13\n",
      "alpha = 0.06 beta = 0.14\n",
      "alpha = 0.06 beta = 0.15\n",
      "alpha = 0.06 beta = 0.16\n",
      "alpha = 0.06 beta = 0.17\n",
      "alpha = 0.06 beta = 0.18\n",
      "alpha = 0.06 beta = 0.19\n",
      "alpha = 0.07 beta = 0.0\n",
      "alpha = 0.07 beta = 0.01\n",
      "alpha = 0.07 beta = 0.02\n",
      "alpha = 0.07 beta = 0.03\n",
      "alpha = 0.07 beta = 0.04\n",
      "alpha = 0.07 beta = 0.05\n",
      "alpha = 0.07 beta = 0.06\n",
      "alpha = 0.07 beta = 0.07\n",
      "alpha = 0.07 beta = 0.08\n",
      "alpha = 0.07 beta = 0.09\n",
      "alpha = 0.07 beta = 0.1\n",
      "alpha = 0.07 beta = 0.11\n",
      "alpha = 0.07 beta = 0.12\n",
      "alpha = 0.07 beta = 0.13\n",
      "alpha = 0.07 beta = 0.14\n",
      "alpha = 0.07 beta = 0.15\n",
      "alpha = 0.07 beta = 0.16\n",
      "alpha = 0.07 beta = 0.17\n",
      "alpha = 0.07 beta = 0.18\n",
      "alpha = 0.07 beta = 0.19\n",
      "alpha = 0.08 beta = 0.0\n",
      "alpha = 0.08 beta = 0.01\n",
      "alpha = 0.08 beta = 0.02\n",
      "alpha = 0.08 beta = 0.03\n",
      "alpha = 0.08 beta = 0.04\n",
      "alpha = 0.08 beta = 0.05\n",
      "alpha = 0.08 beta = 0.06\n",
      "alpha = 0.08 beta = 0.07\n",
      "alpha = 0.08 beta = 0.08\n",
      "alpha = 0.08 beta = 0.09\n",
      "alpha = 0.08 beta = 0.1\n",
      "alpha = 0.08 beta = 0.11\n",
      "alpha = 0.08 beta = 0.12\n",
      "alpha = 0.08 beta = 0.13\n",
      "alpha = 0.08 beta = 0.14\n",
      "alpha = 0.08 beta = 0.15\n",
      "alpha = 0.08 beta = 0.16\n",
      "alpha = 0.08 beta = 0.17\n",
      "alpha = 0.08 beta = 0.18\n",
      "alpha = 0.08 beta = 0.19\n",
      "alpha = 0.09 beta = 0.0\n",
      "alpha = 0.09 beta = 0.01\n",
      "alpha = 0.09 beta = 0.02\n",
      "alpha = 0.09 beta = 0.03\n",
      "alpha = 0.09 beta = 0.04\n",
      "alpha = 0.09 beta = 0.05\n",
      "alpha = 0.09 beta = 0.06\n",
      "alpha = 0.09 beta = 0.07\n",
      "alpha = 0.09 beta = 0.08\n",
      "alpha = 0.09 beta = 0.09\n",
      "alpha = 0.09 beta = 0.1\n",
      "alpha = 0.09 beta = 0.11\n",
      "alpha = 0.09 beta = 0.12\n",
      "alpha = 0.09 beta = 0.13\n",
      "alpha = 0.09 beta = 0.14\n",
      "alpha = 0.09 beta = 0.15\n",
      "alpha = 0.09 beta = 0.16\n",
      "alpha = 0.09 beta = 0.17\n",
      "alpha = 0.09 beta = 0.18\n",
      "alpha = 0.09 beta = 0.19\n",
      "alpha = 0.1 beta = 0.0\n",
      "alpha = 0.1 beta = 0.01\n",
      "alpha = 0.1 beta = 0.02\n",
      "alpha = 0.1 beta = 0.03\n",
      "alpha = 0.1 beta = 0.04\n",
      "alpha = 0.1 beta = 0.05\n",
      "alpha = 0.1 beta = 0.06\n",
      "alpha = 0.1 beta = 0.07\n",
      "alpha = 0.1 beta = 0.08\n",
      "alpha = 0.1 beta = 0.09\n",
      "alpha = 0.1 beta = 0.1\n",
      "alpha = 0.1 beta = 0.11\n",
      "alpha = 0.1 beta = 0.12\n",
      "alpha = 0.1 beta = 0.13\n",
      "alpha = 0.1 beta = 0.14\n",
      "alpha = 0.1 beta = 0.15\n",
      "alpha = 0.1 beta = 0.16\n",
      "alpha = 0.1 beta = 0.17\n",
      "alpha = 0.1 beta = 0.18\n",
      "alpha = 0.1 beta = 0.19\n",
      "alpha = 0.11 beta = 0.0\n",
      "alpha = 0.11 beta = 0.01\n",
      "alpha = 0.11 beta = 0.02\n",
      "alpha = 0.11 beta = 0.03\n",
      "alpha = 0.11 beta = 0.04\n",
      "alpha = 0.11 beta = 0.05\n",
      "alpha = 0.11 beta = 0.06\n",
      "alpha = 0.11 beta = 0.07\n",
      "alpha = 0.11 beta = 0.08\n",
      "alpha = 0.11 beta = 0.09\n",
      "alpha = 0.11 beta = 0.1\n",
      "alpha = 0.11 beta = 0.11\n",
      "alpha = 0.11 beta = 0.12\n",
      "alpha = 0.11 beta = 0.13\n",
      "alpha = 0.11 beta = 0.14\n",
      "alpha = 0.11 beta = 0.15\n",
      "alpha = 0.11 beta = 0.16\n",
      "alpha = 0.11 beta = 0.17\n",
      "alpha = 0.11 beta = 0.18\n",
      "alpha = 0.11 beta = 0.19\n",
      "alpha = 0.12 beta = 0.0\n",
      "alpha = 0.12 beta = 0.01\n",
      "alpha = 0.12 beta = 0.02\n",
      "alpha = 0.12 beta = 0.03\n",
      "alpha = 0.12 beta = 0.04\n",
      "alpha = 0.12 beta = 0.05\n",
      "alpha = 0.12 beta = 0.06\n",
      "alpha = 0.12 beta = 0.07\n",
      "alpha = 0.12 beta = 0.08\n",
      "alpha = 0.12 beta = 0.09\n",
      "alpha = 0.12 beta = 0.1\n",
      "alpha = 0.12 beta = 0.11\n",
      "alpha = 0.12 beta = 0.12\n",
      "alpha = 0.12 beta = 0.13\n",
      "alpha = 0.12 beta = 0.14\n",
      "alpha = 0.12 beta = 0.15\n",
      "alpha = 0.12 beta = 0.16\n",
      "alpha = 0.12 beta = 0.17\n",
      "alpha = 0.12 beta = 0.18\n",
      "alpha = 0.12 beta = 0.19\n",
      "alpha = 0.13 beta = 0.0\n",
      "alpha = 0.13 beta = 0.01\n",
      "alpha = 0.13 beta = 0.02\n",
      "alpha = 0.13 beta = 0.03\n",
      "alpha = 0.13 beta = 0.04\n",
      "alpha = 0.13 beta = 0.05\n",
      "alpha = 0.13 beta = 0.06\n",
      "alpha = 0.13 beta = 0.07\n",
      "alpha = 0.13 beta = 0.08\n",
      "alpha = 0.13 beta = 0.09\n",
      "alpha = 0.13 beta = 0.1\n",
      "alpha = 0.13 beta = 0.11\n",
      "alpha = 0.13 beta = 0.12\n",
      "alpha = 0.13 beta = 0.13\n",
      "alpha = 0.13 beta = 0.14\n",
      "alpha = 0.13 beta = 0.15\n",
      "alpha = 0.13 beta = 0.16\n",
      "alpha = 0.13 beta = 0.17\n",
      "alpha = 0.13 beta = 0.18\n",
      "alpha = 0.13 beta = 0.19\n",
      "alpha = 0.14 beta = 0.0\n",
      "alpha = 0.14 beta = 0.01\n",
      "alpha = 0.14 beta = 0.02\n",
      "alpha = 0.14 beta = 0.03\n",
      "alpha = 0.14 beta = 0.04\n",
      "alpha = 0.14 beta = 0.05\n",
      "alpha = 0.14 beta = 0.06\n",
      "alpha = 0.14 beta = 0.07\n",
      "alpha = 0.14 beta = 0.08\n",
      "alpha = 0.14 beta = 0.09\n",
      "alpha = 0.14 beta = 0.1\n",
      "alpha = 0.14 beta = 0.11\n",
      "alpha = 0.14 beta = 0.12\n",
      "alpha = 0.14 beta = 0.13\n",
      "alpha = 0.14 beta = 0.14\n",
      "alpha = 0.14 beta = 0.15\n",
      "alpha = 0.14 beta = 0.16\n",
      "alpha = 0.14 beta = 0.17\n",
      "alpha = 0.14 beta = 0.18\n",
      "alpha = 0.14 beta = 0.19\n",
      "alpha = 0.15 beta = 0.0\n",
      "alpha = 0.15 beta = 0.01\n",
      "alpha = 0.15 beta = 0.02\n",
      "alpha = 0.15 beta = 0.03\n",
      "alpha = 0.15 beta = 0.04\n",
      "alpha = 0.15 beta = 0.05\n",
      "alpha = 0.15 beta = 0.06\n",
      "alpha = 0.15 beta = 0.07\n",
      "alpha = 0.15 beta = 0.08\n",
      "alpha = 0.15 beta = 0.09\n",
      "alpha = 0.15 beta = 0.1\n",
      "alpha = 0.15 beta = 0.11\n",
      "alpha = 0.15 beta = 0.12\n",
      "alpha = 0.15 beta = 0.13\n",
      "alpha = 0.15 beta = 0.14\n",
      "alpha = 0.15 beta = 0.15\n",
      "alpha = 0.15 beta = 0.16\n",
      "alpha = 0.15 beta = 0.17\n",
      "alpha = 0.15 beta = 0.18\n",
      "alpha = 0.15 beta = 0.19\n",
      "alpha = 0.16 beta = 0.0\n",
      "alpha = 0.16 beta = 0.01\n",
      "alpha = 0.16 beta = 0.02\n",
      "alpha = 0.16 beta = 0.03\n",
      "alpha = 0.16 beta = 0.04\n",
      "alpha = 0.16 beta = 0.05\n",
      "alpha = 0.16 beta = 0.06\n",
      "alpha = 0.16 beta = 0.07\n",
      "alpha = 0.16 beta = 0.08\n",
      "alpha = 0.16 beta = 0.09\n",
      "alpha = 0.16 beta = 0.1\n",
      "alpha = 0.16 beta = 0.11\n",
      "alpha = 0.16 beta = 0.12\n",
      "alpha = 0.16 beta = 0.13\n",
      "alpha = 0.16 beta = 0.14\n",
      "alpha = 0.16 beta = 0.15\n",
      "alpha = 0.16 beta = 0.16\n",
      "alpha = 0.16 beta = 0.17\n",
      "alpha = 0.16 beta = 0.18\n",
      "alpha = 0.16 beta = 0.19\n",
      "alpha = 0.17 beta = 0.0\n",
      "alpha = 0.17 beta = 0.01\n",
      "alpha = 0.17 beta = 0.02\n",
      "alpha = 0.17 beta = 0.03\n",
      "alpha = 0.17 beta = 0.04\n",
      "alpha = 0.17 beta = 0.05\n",
      "alpha = 0.17 beta = 0.06\n",
      "alpha = 0.17 beta = 0.07\n",
      "alpha = 0.17 beta = 0.08\n",
      "alpha = 0.17 beta = 0.09\n",
      "alpha = 0.17 beta = 0.1\n",
      "alpha = 0.17 beta = 0.11\n",
      "alpha = 0.17 beta = 0.12\n",
      "alpha = 0.17 beta = 0.13\n",
      "alpha = 0.17 beta = 0.14\n",
      "alpha = 0.17 beta = 0.15\n",
      "alpha = 0.17 beta = 0.16\n",
      "alpha = 0.17 beta = 0.17\n",
      "alpha = 0.17 beta = 0.18\n",
      "alpha = 0.17 beta = 0.19\n",
      "alpha = 0.18 beta = 0.0\n",
      "alpha = 0.18 beta = 0.01\n",
      "alpha = 0.18 beta = 0.02\n",
      "alpha = 0.18 beta = 0.03\n",
      "alpha = 0.18 beta = 0.04\n",
      "alpha = 0.18 beta = 0.05\n",
      "alpha = 0.18 beta = 0.06\n",
      "alpha = 0.18 beta = 0.07\n",
      "alpha = 0.18 beta = 0.08\n",
      "alpha = 0.18 beta = 0.09\n",
      "alpha = 0.18 beta = 0.1\n",
      "alpha = 0.18 beta = 0.11\n",
      "alpha = 0.18 beta = 0.12\n",
      "alpha = 0.18 beta = 0.13\n",
      "alpha = 0.18 beta = 0.14\n",
      "alpha = 0.18 beta = 0.15\n",
      "alpha = 0.18 beta = 0.16\n",
      "alpha = 0.18 beta = 0.17\n",
      "alpha = 0.18 beta = 0.18\n",
      "alpha = 0.18 beta = 0.19\n",
      "alpha = 0.19 beta = 0.0\n",
      "alpha = 0.19 beta = 0.01\n",
      "alpha = 0.19 beta = 0.02\n",
      "alpha = 0.19 beta = 0.03\n",
      "alpha = 0.19 beta = 0.04\n",
      "alpha = 0.19 beta = 0.05\n",
      "alpha = 0.19 beta = 0.06\n",
      "alpha = 0.19 beta = 0.07\n",
      "alpha = 0.19 beta = 0.08\n",
      "alpha = 0.19 beta = 0.09\n",
      "alpha = 0.19 beta = 0.1\n",
      "alpha = 0.19 beta = 0.11\n",
      "alpha = 0.19 beta = 0.12\n",
      "alpha = 0.19 beta = 0.13\n",
      "alpha = 0.19 beta = 0.14\n",
      "alpha = 0.19 beta = 0.15\n",
      "alpha = 0.19 beta = 0.16\n",
      "alpha = 0.19 beta = 0.17\n",
      "alpha = 0.19 beta = 0.18\n",
      "alpha = 0.19 beta = 0.19\n",
      "alpha = 0.0 beta = 0.0\n",
      "alpha = 0.0 beta = 0.01\n",
      "alpha = 0.0 beta = 0.02\n",
      "alpha = 0.0 beta = 0.03\n",
      "alpha = 0.0 beta = 0.04\n",
      "alpha = 0.0 beta = 0.05\n",
      "alpha = 0.0 beta = 0.06\n",
      "alpha = 0.0 beta = 0.07\n",
      "alpha = 0.0 beta = 0.08\n",
      "alpha = 0.0 beta = 0.09\n",
      "alpha = 0.0 beta = 0.1\n",
      "alpha = 0.0 beta = 0.11\n",
      "alpha = 0.0 beta = 0.12\n",
      "alpha = 0.0 beta = 0.13\n",
      "alpha = 0.0 beta = 0.14\n",
      "alpha = 0.0 beta = 0.15\n",
      "alpha = 0.0 beta = 0.16\n",
      "alpha = 0.0 beta = 0.17\n",
      "alpha = 0.0 beta = 0.18\n",
      "alpha = 0.0 beta = 0.19\n",
      "alpha = 0.01 beta = 0.0\n",
      "alpha = 0.01 beta = 0.01\n",
      "alpha = 0.01 beta = 0.02\n",
      "alpha = 0.01 beta = 0.03\n",
      "alpha = 0.01 beta = 0.04\n",
      "alpha = 0.01 beta = 0.05\n",
      "alpha = 0.01 beta = 0.06\n",
      "alpha = 0.01 beta = 0.07\n",
      "alpha = 0.01 beta = 0.08\n",
      "alpha = 0.01 beta = 0.09\n",
      "alpha = 0.01 beta = 0.1\n",
      "alpha = 0.01 beta = 0.11\n",
      "alpha = 0.01 beta = 0.12\n",
      "alpha = 0.01 beta = 0.13\n",
      "alpha = 0.01 beta = 0.14\n",
      "alpha = 0.01 beta = 0.15\n",
      "alpha = 0.01 beta = 0.16\n",
      "alpha = 0.01 beta = 0.17\n",
      "alpha = 0.01 beta = 0.18\n",
      "alpha = 0.01 beta = 0.19\n",
      "alpha = 0.02 beta = 0.0\n",
      "alpha = 0.02 beta = 0.01\n",
      "alpha = 0.02 beta = 0.02\n",
      "alpha = 0.02 beta = 0.03\n",
      "alpha = 0.02 beta = 0.04\n",
      "alpha = 0.02 beta = 0.05\n",
      "alpha = 0.02 beta = 0.06\n",
      "alpha = 0.02 beta = 0.07\n",
      "alpha = 0.02 beta = 0.08\n",
      "alpha = 0.02 beta = 0.09\n",
      "alpha = 0.02 beta = 0.1\n",
      "alpha = 0.02 beta = 0.11\n",
      "alpha = 0.02 beta = 0.12\n",
      "alpha = 0.02 beta = 0.13\n",
      "alpha = 0.02 beta = 0.14\n",
      "alpha = 0.02 beta = 0.15\n",
      "alpha = 0.02 beta = 0.16\n",
      "alpha = 0.02 beta = 0.17\n",
      "alpha = 0.02 beta = 0.18\n",
      "alpha = 0.02 beta = 0.19\n",
      "alpha = 0.03 beta = 0.0\n",
      "alpha = 0.03 beta = 0.01\n",
      "alpha = 0.03 beta = 0.02\n",
      "alpha = 0.03 beta = 0.03\n",
      "alpha = 0.03 beta = 0.04\n",
      "alpha = 0.03 beta = 0.05\n",
      "alpha = 0.03 beta = 0.06\n",
      "alpha = 0.03 beta = 0.07\n",
      "alpha = 0.03 beta = 0.08\n",
      "alpha = 0.03 beta = 0.09\n",
      "alpha = 0.03 beta = 0.1\n",
      "alpha = 0.03 beta = 0.11\n",
      "alpha = 0.03 beta = 0.12\n",
      "alpha = 0.03 beta = 0.13\n",
      "alpha = 0.03 beta = 0.14\n",
      "alpha = 0.03 beta = 0.15\n",
      "alpha = 0.03 beta = 0.16\n",
      "alpha = 0.03 beta = 0.17\n",
      "alpha = 0.03 beta = 0.18\n",
      "alpha = 0.03 beta = 0.19\n",
      "alpha = 0.04 beta = 0.0\n",
      "alpha = 0.04 beta = 0.01\n",
      "alpha = 0.04 beta = 0.02\n",
      "alpha = 0.04 beta = 0.03\n",
      "alpha = 0.04 beta = 0.04\n",
      "alpha = 0.04 beta = 0.05\n",
      "alpha = 0.04 beta = 0.06\n",
      "alpha = 0.04 beta = 0.07\n",
      "alpha = 0.04 beta = 0.08\n",
      "alpha = 0.04 beta = 0.09\n",
      "alpha = 0.04 beta = 0.1\n",
      "alpha = 0.04 beta = 0.11\n",
      "alpha = 0.04 beta = 0.12\n",
      "alpha = 0.04 beta = 0.13\n",
      "alpha = 0.04 beta = 0.14\n",
      "alpha = 0.04 beta = 0.15\n",
      "alpha = 0.04 beta = 0.16\n",
      "alpha = 0.04 beta = 0.17\n",
      "alpha = 0.04 beta = 0.18\n",
      "alpha = 0.04 beta = 0.19\n",
      "alpha = 0.05 beta = 0.0\n",
      "alpha = 0.05 beta = 0.01\n",
      "alpha = 0.05 beta = 0.02\n",
      "alpha = 0.05 beta = 0.03\n",
      "alpha = 0.05 beta = 0.04\n",
      "alpha = 0.05 beta = 0.05\n",
      "alpha = 0.05 beta = 0.06\n",
      "alpha = 0.05 beta = 0.07\n",
      "alpha = 0.05 beta = 0.08\n",
      "alpha = 0.05 beta = 0.09\n",
      "alpha = 0.05 beta = 0.1\n",
      "alpha = 0.05 beta = 0.11\n",
      "alpha = 0.05 beta = 0.12\n",
      "alpha = 0.05 beta = 0.13\n",
      "alpha = 0.05 beta = 0.14\n",
      "alpha = 0.05 beta = 0.15\n",
      "alpha = 0.05 beta = 0.16\n",
      "alpha = 0.05 beta = 0.17\n",
      "alpha = 0.05 beta = 0.18\n",
      "alpha = 0.05 beta = 0.19\n",
      "alpha = 0.06 beta = 0.0\n",
      "alpha = 0.06 beta = 0.01\n",
      "alpha = 0.06 beta = 0.02\n",
      "alpha = 0.06 beta = 0.03\n",
      "alpha = 0.06 beta = 0.04\n",
      "alpha = 0.06 beta = 0.05\n",
      "alpha = 0.06 beta = 0.06\n",
      "alpha = 0.06 beta = 0.07\n",
      "alpha = 0.06 beta = 0.08\n",
      "alpha = 0.06 beta = 0.09\n",
      "alpha = 0.06 beta = 0.1\n",
      "alpha = 0.06 beta = 0.11\n",
      "alpha = 0.06 beta = 0.12\n",
      "alpha = 0.06 beta = 0.13\n",
      "alpha = 0.06 beta = 0.14\n",
      "alpha = 0.06 beta = 0.15\n",
      "alpha = 0.06 beta = 0.16\n",
      "alpha = 0.06 beta = 0.17\n",
      "alpha = 0.06 beta = 0.18\n",
      "alpha = 0.06 beta = 0.19\n",
      "alpha = 0.07 beta = 0.0\n",
      "alpha = 0.07 beta = 0.01\n",
      "alpha = 0.07 beta = 0.02\n",
      "alpha = 0.07 beta = 0.03\n",
      "alpha = 0.07 beta = 0.04\n",
      "alpha = 0.07 beta = 0.05\n",
      "alpha = 0.07 beta = 0.06\n",
      "alpha = 0.07 beta = 0.07\n",
      "alpha = 0.07 beta = 0.08\n",
      "alpha = 0.07 beta = 0.09\n",
      "alpha = 0.07 beta = 0.1\n",
      "alpha = 0.07 beta = 0.11\n",
      "alpha = 0.07 beta = 0.12\n",
      "alpha = 0.07 beta = 0.13\n",
      "alpha = 0.07 beta = 0.14\n",
      "alpha = 0.07 beta = 0.15\n",
      "alpha = 0.07 beta = 0.16\n",
      "alpha = 0.07 beta = 0.17\n",
      "alpha = 0.07 beta = 0.18\n",
      "alpha = 0.07 beta = 0.19\n",
      "alpha = 0.08 beta = 0.0\n",
      "alpha = 0.08 beta = 0.01\n",
      "alpha = 0.08 beta = 0.02\n",
      "alpha = 0.08 beta = 0.03\n",
      "alpha = 0.08 beta = 0.04\n",
      "alpha = 0.08 beta = 0.05\n",
      "alpha = 0.08 beta = 0.06\n",
      "alpha = 0.08 beta = 0.07\n",
      "alpha = 0.08 beta = 0.08\n",
      "alpha = 0.08 beta = 0.09\n",
      "alpha = 0.08 beta = 0.1\n",
      "alpha = 0.08 beta = 0.11\n",
      "alpha = 0.08 beta = 0.12\n",
      "alpha = 0.08 beta = 0.13\n",
      "alpha = 0.08 beta = 0.14\n",
      "alpha = 0.08 beta = 0.15\n",
      "alpha = 0.08 beta = 0.16\n",
      "alpha = 0.08 beta = 0.17\n",
      "alpha = 0.08 beta = 0.18\n",
      "alpha = 0.08 beta = 0.19\n",
      "alpha = 0.09 beta = 0.0\n",
      "alpha = 0.09 beta = 0.01\n",
      "alpha = 0.09 beta = 0.02\n",
      "alpha = 0.09 beta = 0.03\n",
      "alpha = 0.09 beta = 0.04\n",
      "alpha = 0.09 beta = 0.05\n",
      "alpha = 0.09 beta = 0.06\n",
      "alpha = 0.09 beta = 0.07\n",
      "alpha = 0.09 beta = 0.08\n",
      "alpha = 0.09 beta = 0.09\n",
      "alpha = 0.09 beta = 0.1\n",
      "alpha = 0.09 beta = 0.11\n",
      "alpha = 0.09 beta = 0.12\n",
      "alpha = 0.09 beta = 0.13\n",
      "alpha = 0.09 beta = 0.14\n",
      "alpha = 0.09 beta = 0.15\n",
      "alpha = 0.09 beta = 0.16\n",
      "alpha = 0.09 beta = 0.17\n",
      "alpha = 0.09 beta = 0.18\n",
      "alpha = 0.09 beta = 0.19\n",
      "alpha = 0.1 beta = 0.0\n",
      "alpha = 0.1 beta = 0.01\n",
      "alpha = 0.1 beta = 0.02\n",
      "alpha = 0.1 beta = 0.03\n",
      "alpha = 0.1 beta = 0.04\n",
      "alpha = 0.1 beta = 0.05\n",
      "alpha = 0.1 beta = 0.06\n",
      "alpha = 0.1 beta = 0.07\n",
      "alpha = 0.1 beta = 0.08\n",
      "alpha = 0.1 beta = 0.09\n",
      "alpha = 0.1 beta = 0.1\n",
      "alpha = 0.1 beta = 0.11\n",
      "alpha = 0.1 beta = 0.12\n",
      "alpha = 0.1 beta = 0.13\n",
      "alpha = 0.1 beta = 0.14\n",
      "alpha = 0.1 beta = 0.15\n",
      "alpha = 0.1 beta = 0.16\n",
      "alpha = 0.1 beta = 0.17\n",
      "alpha = 0.1 beta = 0.18\n",
      "alpha = 0.1 beta = 0.19\n",
      "alpha = 0.11 beta = 0.0\n",
      "alpha = 0.11 beta = 0.01\n",
      "alpha = 0.11 beta = 0.02\n",
      "alpha = 0.11 beta = 0.03\n",
      "alpha = 0.11 beta = 0.04\n",
      "alpha = 0.11 beta = 0.05\n",
      "alpha = 0.11 beta = 0.06\n",
      "alpha = 0.11 beta = 0.07\n",
      "alpha = 0.11 beta = 0.08\n",
      "alpha = 0.11 beta = 0.09\n",
      "alpha = 0.11 beta = 0.1\n",
      "alpha = 0.11 beta = 0.11\n",
      "alpha = 0.11 beta = 0.12\n",
      "alpha = 0.11 beta = 0.13\n",
      "alpha = 0.11 beta = 0.14\n",
      "alpha = 0.11 beta = 0.15\n",
      "alpha = 0.11 beta = 0.16\n",
      "alpha = 0.11 beta = 0.17\n",
      "alpha = 0.11 beta = 0.18\n",
      "alpha = 0.11 beta = 0.19\n",
      "alpha = 0.12 beta = 0.0\n",
      "alpha = 0.12 beta = 0.01\n",
      "alpha = 0.12 beta = 0.02\n",
      "alpha = 0.12 beta = 0.03\n",
      "alpha = 0.12 beta = 0.04\n",
      "alpha = 0.12 beta = 0.05\n",
      "alpha = 0.12 beta = 0.06\n",
      "alpha = 0.12 beta = 0.07\n",
      "alpha = 0.12 beta = 0.08\n",
      "alpha = 0.12 beta = 0.09\n",
      "alpha = 0.12 beta = 0.1\n",
      "alpha = 0.12 beta = 0.11\n",
      "alpha = 0.12 beta = 0.12\n",
      "alpha = 0.12 beta = 0.13\n",
      "alpha = 0.12 beta = 0.14\n",
      "alpha = 0.12 beta = 0.15\n",
      "alpha = 0.12 beta = 0.16\n",
      "alpha = 0.12 beta = 0.17\n",
      "alpha = 0.12 beta = 0.18\n",
      "alpha = 0.12 beta = 0.19\n",
      "alpha = 0.13 beta = 0.0\n",
      "alpha = 0.13 beta = 0.01\n",
      "alpha = 0.13 beta = 0.02\n",
      "alpha = 0.13 beta = 0.03\n",
      "alpha = 0.13 beta = 0.04\n",
      "alpha = 0.13 beta = 0.05\n",
      "alpha = 0.13 beta = 0.06\n",
      "alpha = 0.13 beta = 0.07\n",
      "alpha = 0.13 beta = 0.08\n",
      "alpha = 0.13 beta = 0.09\n",
      "alpha = 0.13 beta = 0.1\n",
      "alpha = 0.13 beta = 0.11\n",
      "alpha = 0.13 beta = 0.12\n",
      "alpha = 0.13 beta = 0.13\n",
      "alpha = 0.13 beta = 0.14\n",
      "alpha = 0.13 beta = 0.15\n",
      "alpha = 0.13 beta = 0.16\n",
      "alpha = 0.13 beta = 0.17\n",
      "alpha = 0.13 beta = 0.18\n",
      "alpha = 0.13 beta = 0.19\n",
      "alpha = 0.14 beta = 0.0\n",
      "alpha = 0.14 beta = 0.01\n",
      "alpha = 0.14 beta = 0.02\n",
      "alpha = 0.14 beta = 0.03\n",
      "alpha = 0.14 beta = 0.04\n",
      "alpha = 0.14 beta = 0.05\n",
      "alpha = 0.14 beta = 0.06\n",
      "alpha = 0.14 beta = 0.07\n",
      "alpha = 0.14 beta = 0.08\n",
      "alpha = 0.14 beta = 0.09\n",
      "alpha = 0.14 beta = 0.1\n",
      "alpha = 0.14 beta = 0.11\n",
      "alpha = 0.14 beta = 0.12\n",
      "alpha = 0.14 beta = 0.13\n",
      "alpha = 0.14 beta = 0.14\n",
      "alpha = 0.14 beta = 0.15\n",
      "alpha = 0.14 beta = 0.16\n",
      "alpha = 0.14 beta = 0.17\n",
      "alpha = 0.14 beta = 0.18\n",
      "alpha = 0.14 beta = 0.19\n",
      "alpha = 0.15 beta = 0.0\n",
      "alpha = 0.15 beta = 0.01\n",
      "alpha = 0.15 beta = 0.02\n",
      "alpha = 0.15 beta = 0.03\n",
      "alpha = 0.15 beta = 0.04\n",
      "alpha = 0.15 beta = 0.05\n",
      "alpha = 0.15 beta = 0.06\n",
      "alpha = 0.15 beta = 0.07\n",
      "alpha = 0.15 beta = 0.08\n",
      "alpha = 0.15 beta = 0.09\n",
      "alpha = 0.15 beta = 0.1\n",
      "alpha = 0.15 beta = 0.11\n",
      "alpha = 0.15 beta = 0.12\n",
      "alpha = 0.15 beta = 0.13\n",
      "alpha = 0.15 beta = 0.14\n",
      "alpha = 0.15 beta = 0.15\n",
      "alpha = 0.15 beta = 0.16\n",
      "alpha = 0.15 beta = 0.17\n",
      "alpha = 0.15 beta = 0.18\n",
      "alpha = 0.15 beta = 0.19\n",
      "alpha = 0.16 beta = 0.0\n",
      "alpha = 0.16 beta = 0.01\n",
      "alpha = 0.16 beta = 0.02\n",
      "alpha = 0.16 beta = 0.03\n",
      "alpha = 0.16 beta = 0.04\n",
      "alpha = 0.16 beta = 0.05\n",
      "alpha = 0.16 beta = 0.06\n",
      "alpha = 0.16 beta = 0.07\n",
      "alpha = 0.16 beta = 0.08\n",
      "alpha = 0.16 beta = 0.09\n",
      "alpha = 0.16 beta = 0.1\n",
      "alpha = 0.16 beta = 0.11\n",
      "alpha = 0.16 beta = 0.12\n",
      "alpha = 0.16 beta = 0.13\n",
      "alpha = 0.16 beta = 0.14\n",
      "alpha = 0.16 beta = 0.15\n",
      "alpha = 0.16 beta = 0.16\n",
      "alpha = 0.16 beta = 0.17\n",
      "alpha = 0.16 beta = 0.18\n",
      "alpha = 0.16 beta = 0.19\n",
      "alpha = 0.17 beta = 0.0\n",
      "alpha = 0.17 beta = 0.01\n",
      "alpha = 0.17 beta = 0.02\n",
      "alpha = 0.17 beta = 0.03\n",
      "alpha = 0.17 beta = 0.04\n",
      "alpha = 0.17 beta = 0.05\n",
      "alpha = 0.17 beta = 0.06\n",
      "alpha = 0.17 beta = 0.07\n",
      "alpha = 0.17 beta = 0.08\n",
      "alpha = 0.17 beta = 0.09\n",
      "alpha = 0.17 beta = 0.1\n",
      "alpha = 0.17 beta = 0.11\n",
      "alpha = 0.17 beta = 0.12\n",
      "alpha = 0.17 beta = 0.13\n",
      "alpha = 0.17 beta = 0.14\n",
      "alpha = 0.17 beta = 0.15\n",
      "alpha = 0.17 beta = 0.16\n",
      "alpha = 0.17 beta = 0.17\n",
      "alpha = 0.17 beta = 0.18\n",
      "alpha = 0.17 beta = 0.19\n",
      "alpha = 0.18 beta = 0.0\n",
      "alpha = 0.18 beta = 0.01\n",
      "alpha = 0.18 beta = 0.02\n",
      "alpha = 0.18 beta = 0.03\n",
      "alpha = 0.18 beta = 0.04\n",
      "alpha = 0.18 beta = 0.05\n",
      "alpha = 0.18 beta = 0.06\n",
      "alpha = 0.18 beta = 0.07\n",
      "alpha = 0.18 beta = 0.08\n",
      "alpha = 0.18 beta = 0.09\n",
      "alpha = 0.18 beta = 0.1\n",
      "alpha = 0.18 beta = 0.11\n",
      "alpha = 0.18 beta = 0.12\n",
      "alpha = 0.18 beta = 0.13\n",
      "alpha = 0.18 beta = 0.14\n",
      "alpha = 0.18 beta = 0.15\n",
      "alpha = 0.18 beta = 0.16\n",
      "alpha = 0.18 beta = 0.17\n",
      "alpha = 0.18 beta = 0.18\n",
      "alpha = 0.18 beta = 0.19\n",
      "alpha = 0.19 beta = 0.0\n",
      "alpha = 0.19 beta = 0.01\n",
      "alpha = 0.19 beta = 0.02\n",
      "alpha = 0.19 beta = 0.03\n",
      "alpha = 0.19 beta = 0.04\n",
      "alpha = 0.19 beta = 0.05\n",
      "alpha = 0.19 beta = 0.06\n",
      "alpha = 0.19 beta = 0.07\n",
      "alpha = 0.19 beta = 0.08\n",
      "alpha = 0.19 beta = 0.09\n",
      "alpha = 0.19 beta = 0.1\n",
      "alpha = 0.19 beta = 0.11\n",
      "alpha = 0.19 beta = 0.12\n",
      "alpha = 0.19 beta = 0.13\n",
      "alpha = 0.19 beta = 0.14\n",
      "alpha = 0.19 beta = 0.15\n",
      "alpha = 0.19 beta = 0.16\n",
      "alpha = 0.19 beta = 0.17\n",
      "alpha = 0.19 beta = 0.18\n",
      "alpha = 0.19 beta = 0.19\n",
      "alpha = 0.0 beta = 0.0\n",
      "alpha = 0.0 beta = 0.01\n",
      "alpha = 0.0 beta = 0.02\n",
      "alpha = 0.0 beta = 0.03\n",
      "alpha = 0.0 beta = 0.04\n",
      "alpha = 0.0 beta = 0.05\n",
      "alpha = 0.0 beta = 0.06\n",
      "alpha = 0.0 beta = 0.07\n",
      "alpha = 0.0 beta = 0.08\n",
      "alpha = 0.0 beta = 0.09\n",
      "alpha = 0.0 beta = 0.1\n",
      "alpha = 0.0 beta = 0.11\n",
      "alpha = 0.0 beta = 0.12\n",
      "alpha = 0.0 beta = 0.13\n",
      "alpha = 0.0 beta = 0.14\n",
      "alpha = 0.0 beta = 0.15\n",
      "alpha = 0.0 beta = 0.16\n",
      "alpha = 0.0 beta = 0.17\n",
      "alpha = 0.0 beta = 0.18\n",
      "alpha = 0.0 beta = 0.19\n",
      "alpha = 0.01 beta = 0.0\n",
      "alpha = 0.01 beta = 0.01\n",
      "alpha = 0.01 beta = 0.02\n",
      "alpha = 0.01 beta = 0.03\n",
      "alpha = 0.01 beta = 0.04\n",
      "alpha = 0.01 beta = 0.05\n",
      "alpha = 0.01 beta = 0.06\n",
      "alpha = 0.01 beta = 0.07\n",
      "alpha = 0.01 beta = 0.08\n",
      "alpha = 0.01 beta = 0.09\n",
      "alpha = 0.01 beta = 0.1\n",
      "alpha = 0.01 beta = 0.11\n",
      "alpha = 0.01 beta = 0.12\n",
      "alpha = 0.01 beta = 0.13\n",
      "alpha = 0.01 beta = 0.14\n",
      "alpha = 0.01 beta = 0.15\n",
      "alpha = 0.01 beta = 0.16\n",
      "alpha = 0.01 beta = 0.17\n",
      "alpha = 0.01 beta = 0.18\n",
      "alpha = 0.01 beta = 0.19\n",
      "alpha = 0.02 beta = 0.0\n",
      "alpha = 0.02 beta = 0.01\n",
      "alpha = 0.02 beta = 0.02\n",
      "alpha = 0.02 beta = 0.03\n",
      "alpha = 0.02 beta = 0.04\n",
      "alpha = 0.02 beta = 0.05\n",
      "alpha = 0.02 beta = 0.06\n",
      "alpha = 0.02 beta = 0.07\n",
      "alpha = 0.02 beta = 0.08\n",
      "alpha = 0.02 beta = 0.09\n",
      "alpha = 0.02 beta = 0.1\n",
      "alpha = 0.02 beta = 0.11\n",
      "alpha = 0.02 beta = 0.12\n",
      "alpha = 0.02 beta = 0.13\n",
      "alpha = 0.02 beta = 0.14\n",
      "alpha = 0.02 beta = 0.15\n",
      "alpha = 0.02 beta = 0.16\n",
      "alpha = 0.02 beta = 0.17\n",
      "alpha = 0.02 beta = 0.18\n",
      "alpha = 0.02 beta = 0.19\n",
      "alpha = 0.03 beta = 0.0\n",
      "alpha = 0.03 beta = 0.01\n",
      "alpha = 0.03 beta = 0.02\n",
      "alpha = 0.03 beta = 0.03\n",
      "alpha = 0.03 beta = 0.04\n",
      "alpha = 0.03 beta = 0.05\n",
      "alpha = 0.03 beta = 0.06\n",
      "alpha = 0.03 beta = 0.07\n",
      "alpha = 0.03 beta = 0.08\n",
      "alpha = 0.03 beta = 0.09\n",
      "alpha = 0.03 beta = 0.1\n",
      "alpha = 0.03 beta = 0.11\n",
      "alpha = 0.03 beta = 0.12\n",
      "alpha = 0.03 beta = 0.13\n",
      "alpha = 0.03 beta = 0.14\n",
      "alpha = 0.03 beta = 0.15\n",
      "alpha = 0.03 beta = 0.16\n",
      "alpha = 0.03 beta = 0.17\n",
      "alpha = 0.03 beta = 0.18\n",
      "alpha = 0.03 beta = 0.19\n",
      "alpha = 0.04 beta = 0.0\n",
      "alpha = 0.04 beta = 0.01\n",
      "alpha = 0.04 beta = 0.02\n",
      "alpha = 0.04 beta = 0.03\n",
      "alpha = 0.04 beta = 0.04\n",
      "alpha = 0.04 beta = 0.05\n",
      "alpha = 0.04 beta = 0.06\n",
      "alpha = 0.04 beta = 0.07\n",
      "alpha = 0.04 beta = 0.08\n",
      "alpha = 0.04 beta = 0.09\n",
      "alpha = 0.04 beta = 0.1\n",
      "alpha = 0.04 beta = 0.11\n",
      "alpha = 0.04 beta = 0.12\n",
      "alpha = 0.04 beta = 0.13\n",
      "alpha = 0.04 beta = 0.14\n",
      "alpha = 0.04 beta = 0.15\n",
      "alpha = 0.04 beta = 0.16\n",
      "alpha = 0.04 beta = 0.17\n",
      "alpha = 0.04 beta = 0.18\n",
      "alpha = 0.04 beta = 0.19\n",
      "alpha = 0.05 beta = 0.0\n",
      "alpha = 0.05 beta = 0.01\n",
      "alpha = 0.05 beta = 0.02\n",
      "alpha = 0.05 beta = 0.03\n",
      "alpha = 0.05 beta = 0.04\n",
      "alpha = 0.05 beta = 0.05\n",
      "alpha = 0.05 beta = 0.06\n",
      "alpha = 0.05 beta = 0.07\n",
      "alpha = 0.05 beta = 0.08\n",
      "alpha = 0.05 beta = 0.09\n",
      "alpha = 0.05 beta = 0.1\n",
      "alpha = 0.05 beta = 0.11\n",
      "alpha = 0.05 beta = 0.12\n",
      "alpha = 0.05 beta = 0.13\n",
      "alpha = 0.05 beta = 0.14\n",
      "alpha = 0.05 beta = 0.15\n",
      "alpha = 0.05 beta = 0.16\n",
      "alpha = 0.05 beta = 0.17\n",
      "alpha = 0.05 beta = 0.18\n",
      "alpha = 0.05 beta = 0.19\n",
      "alpha = 0.06 beta = 0.0\n",
      "alpha = 0.06 beta = 0.01\n",
      "alpha = 0.06 beta = 0.02\n",
      "alpha = 0.06 beta = 0.03\n",
      "alpha = 0.06 beta = 0.04\n",
      "alpha = 0.06 beta = 0.05\n",
      "alpha = 0.06 beta = 0.06\n",
      "alpha = 0.06 beta = 0.07\n",
      "alpha = 0.06 beta = 0.08\n",
      "alpha = 0.06 beta = 0.09\n",
      "alpha = 0.06 beta = 0.1\n",
      "alpha = 0.06 beta = 0.11\n",
      "alpha = 0.06 beta = 0.12\n",
      "alpha = 0.06 beta = 0.13\n",
      "alpha = 0.06 beta = 0.14\n",
      "alpha = 0.06 beta = 0.15\n",
      "alpha = 0.06 beta = 0.16\n",
      "alpha = 0.06 beta = 0.17\n",
      "alpha = 0.06 beta = 0.18\n",
      "alpha = 0.06 beta = 0.19\n",
      "alpha = 0.07 beta = 0.0\n",
      "alpha = 0.07 beta = 0.01\n",
      "alpha = 0.07 beta = 0.02\n",
      "alpha = 0.07 beta = 0.03\n",
      "alpha = 0.07 beta = 0.04\n",
      "alpha = 0.07 beta = 0.05\n",
      "alpha = 0.07 beta = 0.06\n",
      "alpha = 0.07 beta = 0.07\n",
      "alpha = 0.07 beta = 0.08\n",
      "alpha = 0.07 beta = 0.09\n",
      "alpha = 0.07 beta = 0.1\n",
      "alpha = 0.07 beta = 0.11\n",
      "alpha = 0.07 beta = 0.12\n",
      "alpha = 0.07 beta = 0.13\n",
      "alpha = 0.07 beta = 0.14\n",
      "alpha = 0.07 beta = 0.15\n",
      "alpha = 0.07 beta = 0.16\n",
      "alpha = 0.07 beta = 0.17\n",
      "alpha = 0.07 beta = 0.18\n",
      "alpha = 0.07 beta = 0.19\n",
      "alpha = 0.08 beta = 0.0\n",
      "alpha = 0.08 beta = 0.01\n",
      "alpha = 0.08 beta = 0.02\n",
      "alpha = 0.08 beta = 0.03\n",
      "alpha = 0.08 beta = 0.04\n",
      "alpha = 0.08 beta = 0.05\n",
      "alpha = 0.08 beta = 0.06\n",
      "alpha = 0.08 beta = 0.07\n",
      "alpha = 0.08 beta = 0.08\n",
      "alpha = 0.08 beta = 0.09\n",
      "alpha = 0.08 beta = 0.1\n",
      "alpha = 0.08 beta = 0.11\n",
      "alpha = 0.08 beta = 0.12\n",
      "alpha = 0.08 beta = 0.13\n",
      "alpha = 0.08 beta = 0.14\n",
      "alpha = 0.08 beta = 0.15\n",
      "alpha = 0.08 beta = 0.16\n",
      "alpha = 0.08 beta = 0.17\n",
      "alpha = 0.08 beta = 0.18\n",
      "alpha = 0.08 beta = 0.19\n",
      "alpha = 0.09 beta = 0.0\n",
      "alpha = 0.09 beta = 0.01\n",
      "alpha = 0.09 beta = 0.02\n",
      "alpha = 0.09 beta = 0.03\n",
      "alpha = 0.09 beta = 0.04\n",
      "alpha = 0.09 beta = 0.05\n",
      "alpha = 0.09 beta = 0.06\n",
      "alpha = 0.09 beta = 0.07\n",
      "alpha = 0.09 beta = 0.08\n",
      "alpha = 0.09 beta = 0.09\n",
      "alpha = 0.09 beta = 0.1\n",
      "alpha = 0.09 beta = 0.11\n",
      "alpha = 0.09 beta = 0.12\n",
      "alpha = 0.09 beta = 0.13\n",
      "alpha = 0.09 beta = 0.14\n",
      "alpha = 0.09 beta = 0.15\n",
      "alpha = 0.09 beta = 0.16\n",
      "alpha = 0.09 beta = 0.17\n",
      "alpha = 0.09 beta = 0.18\n",
      "alpha = 0.09 beta = 0.19\n",
      "alpha = 0.1 beta = 0.0\n",
      "alpha = 0.1 beta = 0.01\n",
      "alpha = 0.1 beta = 0.02\n",
      "alpha = 0.1 beta = 0.03\n",
      "alpha = 0.1 beta = 0.04\n",
      "alpha = 0.1 beta = 0.05\n",
      "alpha = 0.1 beta = 0.06\n",
      "alpha = 0.1 beta = 0.07\n",
      "alpha = 0.1 beta = 0.08\n",
      "alpha = 0.1 beta = 0.09\n",
      "alpha = 0.1 beta = 0.1\n",
      "alpha = 0.1 beta = 0.11\n",
      "alpha = 0.1 beta = 0.12\n",
      "alpha = 0.1 beta = 0.13\n",
      "alpha = 0.1 beta = 0.14\n",
      "alpha = 0.1 beta = 0.15\n",
      "alpha = 0.1 beta = 0.16\n",
      "alpha = 0.1 beta = 0.17\n",
      "alpha = 0.1 beta = 0.18\n",
      "alpha = 0.1 beta = 0.19\n",
      "alpha = 0.11 beta = 0.0\n",
      "alpha = 0.11 beta = 0.01\n",
      "alpha = 0.11 beta = 0.02\n",
      "alpha = 0.11 beta = 0.03\n",
      "alpha = 0.11 beta = 0.04\n",
      "alpha = 0.11 beta = 0.05\n",
      "alpha = 0.11 beta = 0.06\n",
      "alpha = 0.11 beta = 0.07\n",
      "alpha = 0.11 beta = 0.08\n",
      "alpha = 0.11 beta = 0.09\n",
      "alpha = 0.11 beta = 0.1\n",
      "alpha = 0.11 beta = 0.11\n",
      "alpha = 0.11 beta = 0.12\n",
      "alpha = 0.11 beta = 0.13\n",
      "alpha = 0.11 beta = 0.14\n",
      "alpha = 0.11 beta = 0.15\n",
      "alpha = 0.11 beta = 0.16\n",
      "alpha = 0.11 beta = 0.17\n",
      "alpha = 0.11 beta = 0.18\n",
      "alpha = 0.11 beta = 0.19\n",
      "alpha = 0.12 beta = 0.0\n",
      "alpha = 0.12 beta = 0.01\n",
      "alpha = 0.12 beta = 0.02\n",
      "alpha = 0.12 beta = 0.03\n",
      "alpha = 0.12 beta = 0.04\n",
      "alpha = 0.12 beta = 0.05\n",
      "alpha = 0.12 beta = 0.06\n",
      "alpha = 0.12 beta = 0.07\n",
      "alpha = 0.12 beta = 0.08\n",
      "alpha = 0.12 beta = 0.09\n",
      "alpha = 0.12 beta = 0.1\n",
      "alpha = 0.12 beta = 0.11\n",
      "alpha = 0.12 beta = 0.12\n",
      "alpha = 0.12 beta = 0.13\n",
      "alpha = 0.12 beta = 0.14\n",
      "alpha = 0.12 beta = 0.15\n",
      "alpha = 0.12 beta = 0.16\n",
      "alpha = 0.12 beta = 0.17\n",
      "alpha = 0.12 beta = 0.18\n",
      "alpha = 0.12 beta = 0.19\n",
      "alpha = 0.13 beta = 0.0\n",
      "alpha = 0.13 beta = 0.01\n",
      "alpha = 0.13 beta = 0.02\n",
      "alpha = 0.13 beta = 0.03\n",
      "alpha = 0.13 beta = 0.04\n",
      "alpha = 0.13 beta = 0.05\n",
      "alpha = 0.13 beta = 0.06\n",
      "alpha = 0.13 beta = 0.07\n",
      "alpha = 0.13 beta = 0.08\n",
      "alpha = 0.13 beta = 0.09\n",
      "alpha = 0.13 beta = 0.1\n",
      "alpha = 0.13 beta = 0.11\n",
      "alpha = 0.13 beta = 0.12\n",
      "alpha = 0.13 beta = 0.13\n",
      "alpha = 0.13 beta = 0.14\n",
      "alpha = 0.13 beta = 0.15\n",
      "alpha = 0.13 beta = 0.16\n",
      "alpha = 0.13 beta = 0.17\n",
      "alpha = 0.13 beta = 0.18\n",
      "alpha = 0.13 beta = 0.19\n",
      "alpha = 0.14 beta = 0.0\n",
      "alpha = 0.14 beta = 0.01\n",
      "alpha = 0.14 beta = 0.02\n",
      "alpha = 0.14 beta = 0.03\n",
      "alpha = 0.14 beta = 0.04\n",
      "alpha = 0.14 beta = 0.05\n",
      "alpha = 0.14 beta = 0.06\n",
      "alpha = 0.14 beta = 0.07\n",
      "alpha = 0.14 beta = 0.08\n",
      "alpha = 0.14 beta = 0.09\n",
      "alpha = 0.14 beta = 0.1\n",
      "alpha = 0.14 beta = 0.11\n",
      "alpha = 0.14 beta = 0.12\n",
      "alpha = 0.14 beta = 0.13\n",
      "alpha = 0.14 beta = 0.14\n",
      "alpha = 0.14 beta = 0.15\n",
      "alpha = 0.14 beta = 0.16\n",
      "alpha = 0.14 beta = 0.17\n",
      "alpha = 0.14 beta = 0.18\n",
      "alpha = 0.14 beta = 0.19\n",
      "alpha = 0.15 beta = 0.0\n",
      "alpha = 0.15 beta = 0.01\n",
      "alpha = 0.15 beta = 0.02\n",
      "alpha = 0.15 beta = 0.03\n",
      "alpha = 0.15 beta = 0.04\n",
      "alpha = 0.15 beta = 0.05\n",
      "alpha = 0.15 beta = 0.06\n",
      "alpha = 0.15 beta = 0.07\n",
      "alpha = 0.15 beta = 0.08\n",
      "alpha = 0.15 beta = 0.09\n",
      "alpha = 0.15 beta = 0.1\n",
      "alpha = 0.15 beta = 0.11\n",
      "alpha = 0.15 beta = 0.12\n",
      "alpha = 0.15 beta = 0.13\n",
      "alpha = 0.15 beta = 0.14\n",
      "alpha = 0.15 beta = 0.15\n",
      "alpha = 0.15 beta = 0.16\n",
      "alpha = 0.15 beta = 0.17\n",
      "alpha = 0.15 beta = 0.18\n",
      "alpha = 0.15 beta = 0.19\n",
      "alpha = 0.16 beta = 0.0\n",
      "alpha = 0.16 beta = 0.01\n",
      "alpha = 0.16 beta = 0.02\n",
      "alpha = 0.16 beta = 0.03\n",
      "alpha = 0.16 beta = 0.04\n",
      "alpha = 0.16 beta = 0.05\n",
      "alpha = 0.16 beta = 0.06\n",
      "alpha = 0.16 beta = 0.07\n",
      "alpha = 0.16 beta = 0.08\n",
      "alpha = 0.16 beta = 0.09\n",
      "alpha = 0.16 beta = 0.1\n",
      "alpha = 0.16 beta = 0.11\n",
      "alpha = 0.16 beta = 0.12\n",
      "alpha = 0.16 beta = 0.13\n",
      "alpha = 0.16 beta = 0.14\n",
      "alpha = 0.16 beta = 0.15\n",
      "alpha = 0.16 beta = 0.16\n",
      "alpha = 0.16 beta = 0.17\n",
      "alpha = 0.16 beta = 0.18\n",
      "alpha = 0.16 beta = 0.19\n",
      "alpha = 0.17 beta = 0.0\n",
      "alpha = 0.17 beta = 0.01\n",
      "alpha = 0.17 beta = 0.02\n",
      "alpha = 0.17 beta = 0.03\n",
      "alpha = 0.17 beta = 0.04\n",
      "alpha = 0.17 beta = 0.05\n",
      "alpha = 0.17 beta = 0.06\n",
      "alpha = 0.17 beta = 0.07\n",
      "alpha = 0.17 beta = 0.08\n",
      "alpha = 0.17 beta = 0.09\n",
      "alpha = 0.17 beta = 0.1\n",
      "alpha = 0.17 beta = 0.11\n",
      "alpha = 0.17 beta = 0.12\n",
      "alpha = 0.17 beta = 0.13\n",
      "alpha = 0.17 beta = 0.14\n",
      "alpha = 0.17 beta = 0.15\n",
      "alpha = 0.17 beta = 0.16\n",
      "alpha = 0.17 beta = 0.17\n",
      "alpha = 0.17 beta = 0.18\n",
      "alpha = 0.17 beta = 0.19\n",
      "alpha = 0.18 beta = 0.0\n",
      "alpha = 0.18 beta = 0.01\n",
      "alpha = 0.18 beta = 0.02\n",
      "alpha = 0.18 beta = 0.03\n",
      "alpha = 0.18 beta = 0.04\n",
      "alpha = 0.18 beta = 0.05\n",
      "alpha = 0.18 beta = 0.06\n",
      "alpha = 0.18 beta = 0.07\n",
      "alpha = 0.18 beta = 0.08\n",
      "alpha = 0.18 beta = 0.09\n",
      "alpha = 0.18 beta = 0.1\n",
      "alpha = 0.18 beta = 0.11\n",
      "alpha = 0.18 beta = 0.12\n",
      "alpha = 0.18 beta = 0.13\n",
      "alpha = 0.18 beta = 0.14\n",
      "alpha = 0.18 beta = 0.15\n",
      "alpha = 0.18 beta = 0.16\n",
      "alpha = 0.18 beta = 0.17\n",
      "alpha = 0.18 beta = 0.18\n",
      "alpha = 0.18 beta = 0.19\n",
      "alpha = 0.19 beta = 0.0\n",
      "alpha = 0.19 beta = 0.01\n",
      "alpha = 0.19 beta = 0.02\n",
      "alpha = 0.19 beta = 0.03\n",
      "alpha = 0.19 beta = 0.04\n",
      "alpha = 0.19 beta = 0.05\n",
      "alpha = 0.19 beta = 0.06\n",
      "alpha = 0.19 beta = 0.07\n",
      "alpha = 0.19 beta = 0.08\n",
      "alpha = 0.19 beta = 0.09\n",
      "alpha = 0.19 beta = 0.1\n",
      "alpha = 0.19 beta = 0.11\n",
      "alpha = 0.19 beta = 0.12\n",
      "alpha = 0.19 beta = 0.13\n",
      "alpha = 0.19 beta = 0.14\n",
      "alpha = 0.19 beta = 0.15\n",
      "alpha = 0.19 beta = 0.16\n",
      "alpha = 0.19 beta = 0.17\n",
      "alpha = 0.19 beta = 0.18\n",
      "alpha = 0.19 beta = 0.19\n",
      "alpha = 0.0 beta = 0.0\n",
      "alpha = 0.0 beta = 0.01\n",
      "alpha = 0.0 beta = 0.02\n",
      "alpha = 0.0 beta = 0.03\n",
      "alpha = 0.0 beta = 0.04\n",
      "alpha = 0.0 beta = 0.05\n",
      "alpha = 0.0 beta = 0.06\n",
      "alpha = 0.0 beta = 0.07\n",
      "alpha = 0.0 beta = 0.08\n",
      "alpha = 0.0 beta = 0.09\n",
      "alpha = 0.0 beta = 0.1\n",
      "alpha = 0.0 beta = 0.11\n",
      "alpha = 0.0 beta = 0.12\n",
      "alpha = 0.0 beta = 0.13\n",
      "alpha = 0.0 beta = 0.14\n",
      "alpha = 0.0 beta = 0.15\n",
      "alpha = 0.0 beta = 0.16\n",
      "alpha = 0.0 beta = 0.17\n",
      "alpha = 0.0 beta = 0.18\n",
      "alpha = 0.0 beta = 0.19\n",
      "alpha = 0.01 beta = 0.0\n",
      "alpha = 0.01 beta = 0.01\n",
      "alpha = 0.01 beta = 0.02\n",
      "alpha = 0.01 beta = 0.03\n",
      "alpha = 0.01 beta = 0.04\n",
      "alpha = 0.01 beta = 0.05\n",
      "alpha = 0.01 beta = 0.06\n",
      "alpha = 0.01 beta = 0.07\n",
      "alpha = 0.01 beta = 0.08\n",
      "alpha = 0.01 beta = 0.09\n",
      "alpha = 0.01 beta = 0.1\n",
      "alpha = 0.01 beta = 0.11\n",
      "alpha = 0.01 beta = 0.12\n",
      "alpha = 0.01 beta = 0.13\n",
      "alpha = 0.01 beta = 0.14\n",
      "alpha = 0.01 beta = 0.15\n",
      "alpha = 0.01 beta = 0.16\n",
      "alpha = 0.01 beta = 0.17\n",
      "alpha = 0.01 beta = 0.18\n",
      "alpha = 0.01 beta = 0.19\n",
      "alpha = 0.02 beta = 0.0\n",
      "alpha = 0.02 beta = 0.01\n",
      "alpha = 0.02 beta = 0.02\n",
      "alpha = 0.02 beta = 0.03\n",
      "alpha = 0.02 beta = 0.04\n",
      "alpha = 0.02 beta = 0.05\n",
      "alpha = 0.02 beta = 0.06\n",
      "alpha = 0.02 beta = 0.07\n",
      "alpha = 0.02 beta = 0.08\n",
      "alpha = 0.02 beta = 0.09\n",
      "alpha = 0.02 beta = 0.1\n",
      "alpha = 0.02 beta = 0.11\n",
      "alpha = 0.02 beta = 0.12\n",
      "alpha = 0.02 beta = 0.13\n",
      "alpha = 0.02 beta = 0.14\n",
      "alpha = 0.02 beta = 0.15\n",
      "alpha = 0.02 beta = 0.16\n",
      "alpha = 0.02 beta = 0.17\n",
      "alpha = 0.02 beta = 0.18\n",
      "alpha = 0.02 beta = 0.19\n",
      "alpha = 0.03 beta = 0.0\n",
      "alpha = 0.03 beta = 0.01\n",
      "alpha = 0.03 beta = 0.02\n",
      "alpha = 0.03 beta = 0.03\n",
      "alpha = 0.03 beta = 0.04\n",
      "alpha = 0.03 beta = 0.05\n",
      "alpha = 0.03 beta = 0.06\n",
      "alpha = 0.03 beta = 0.07\n",
      "alpha = 0.03 beta = 0.08\n",
      "alpha = 0.03 beta = 0.09\n",
      "alpha = 0.03 beta = 0.1\n",
      "alpha = 0.03 beta = 0.11\n",
      "alpha = 0.03 beta = 0.12\n",
      "alpha = 0.03 beta = 0.13\n",
      "alpha = 0.03 beta = 0.14\n",
      "alpha = 0.03 beta = 0.15\n",
      "alpha = 0.03 beta = 0.16\n",
      "alpha = 0.03 beta = 0.17\n",
      "alpha = 0.03 beta = 0.18\n",
      "alpha = 0.03 beta = 0.19\n",
      "alpha = 0.04 beta = 0.0\n",
      "alpha = 0.04 beta = 0.01\n",
      "alpha = 0.04 beta = 0.02\n",
      "alpha = 0.04 beta = 0.03\n",
      "alpha = 0.04 beta = 0.04\n",
      "alpha = 0.04 beta = 0.05\n",
      "alpha = 0.04 beta = 0.06\n",
      "alpha = 0.04 beta = 0.07\n",
      "alpha = 0.04 beta = 0.08\n",
      "alpha = 0.04 beta = 0.09\n",
      "alpha = 0.04 beta = 0.1\n",
      "alpha = 0.04 beta = 0.11\n",
      "alpha = 0.04 beta = 0.12\n",
      "alpha = 0.04 beta = 0.13\n",
      "alpha = 0.04 beta = 0.14\n",
      "alpha = 0.04 beta = 0.15\n",
      "alpha = 0.04 beta = 0.16\n",
      "alpha = 0.04 beta = 0.17\n",
      "alpha = 0.04 beta = 0.18\n",
      "alpha = 0.04 beta = 0.19\n",
      "alpha = 0.05 beta = 0.0\n",
      "alpha = 0.05 beta = 0.01\n",
      "alpha = 0.05 beta = 0.02\n",
      "alpha = 0.05 beta = 0.03\n",
      "alpha = 0.05 beta = 0.04\n",
      "alpha = 0.05 beta = 0.05\n",
      "alpha = 0.05 beta = 0.06\n",
      "alpha = 0.05 beta = 0.07\n",
      "alpha = 0.05 beta = 0.08\n",
      "alpha = 0.05 beta = 0.09\n",
      "alpha = 0.05 beta = 0.1\n",
      "alpha = 0.05 beta = 0.11\n",
      "alpha = 0.05 beta = 0.12\n",
      "alpha = 0.05 beta = 0.13\n",
      "alpha = 0.05 beta = 0.14\n",
      "alpha = 0.05 beta = 0.15\n",
      "alpha = 0.05 beta = 0.16\n",
      "alpha = 0.05 beta = 0.17\n",
      "alpha = 0.05 beta = 0.18\n",
      "alpha = 0.05 beta = 0.19\n",
      "alpha = 0.06 beta = 0.0\n",
      "alpha = 0.06 beta = 0.01\n",
      "alpha = 0.06 beta = 0.02\n",
      "alpha = 0.06 beta = 0.03\n",
      "alpha = 0.06 beta = 0.04\n",
      "alpha = 0.06 beta = 0.05\n",
      "alpha = 0.06 beta = 0.06\n",
      "alpha = 0.06 beta = 0.07\n",
      "alpha = 0.06 beta = 0.08\n",
      "alpha = 0.06 beta = 0.09\n",
      "alpha = 0.06 beta = 0.1\n",
      "alpha = 0.06 beta = 0.11\n",
      "alpha = 0.06 beta = 0.12\n",
      "alpha = 0.06 beta = 0.13\n",
      "alpha = 0.06 beta = 0.14\n",
      "alpha = 0.06 beta = 0.15\n",
      "alpha = 0.06 beta = 0.16\n",
      "alpha = 0.06 beta = 0.17\n",
      "alpha = 0.06 beta = 0.18\n",
      "alpha = 0.06 beta = 0.19\n",
      "alpha = 0.07 beta = 0.0\n",
      "alpha = 0.07 beta = 0.01\n",
      "alpha = 0.07 beta = 0.02\n",
      "alpha = 0.07 beta = 0.03\n",
      "alpha = 0.07 beta = 0.04\n",
      "alpha = 0.07 beta = 0.05\n",
      "alpha = 0.07 beta = 0.06\n",
      "alpha = 0.07 beta = 0.07\n",
      "alpha = 0.07 beta = 0.08\n",
      "alpha = 0.07 beta = 0.09\n",
      "alpha = 0.07 beta = 0.1\n",
      "alpha = 0.07 beta = 0.11\n",
      "alpha = 0.07 beta = 0.12\n",
      "alpha = 0.07 beta = 0.13\n",
      "alpha = 0.07 beta = 0.14\n",
      "alpha = 0.07 beta = 0.15\n",
      "alpha = 0.07 beta = 0.16\n",
      "alpha = 0.07 beta = 0.17\n",
      "alpha = 0.07 beta = 0.18\n",
      "alpha = 0.07 beta = 0.19\n",
      "alpha = 0.08 beta = 0.0\n",
      "alpha = 0.08 beta = 0.01\n",
      "alpha = 0.08 beta = 0.02\n",
      "alpha = 0.08 beta = 0.03\n",
      "alpha = 0.08 beta = 0.04\n",
      "alpha = 0.08 beta = 0.05\n",
      "alpha = 0.08 beta = 0.06\n",
      "alpha = 0.08 beta = 0.07\n",
      "alpha = 0.08 beta = 0.08\n",
      "alpha = 0.08 beta = 0.09\n",
      "alpha = 0.08 beta = 0.1\n",
      "alpha = 0.08 beta = 0.11\n",
      "alpha = 0.08 beta = 0.12\n",
      "alpha = 0.08 beta = 0.13\n",
      "alpha = 0.08 beta = 0.14\n",
      "alpha = 0.08 beta = 0.15\n",
      "alpha = 0.08 beta = 0.16\n",
      "alpha = 0.08 beta = 0.17\n",
      "alpha = 0.08 beta = 0.18\n",
      "alpha = 0.08 beta = 0.19\n",
      "alpha = 0.09 beta = 0.0\n",
      "alpha = 0.09 beta = 0.01\n",
      "alpha = 0.09 beta = 0.02\n",
      "alpha = 0.09 beta = 0.03\n",
      "alpha = 0.09 beta = 0.04\n",
      "alpha = 0.09 beta = 0.05\n",
      "alpha = 0.09 beta = 0.06\n",
      "alpha = 0.09 beta = 0.07\n",
      "alpha = 0.09 beta = 0.08\n",
      "alpha = 0.09 beta = 0.09\n",
      "alpha = 0.09 beta = 0.1\n",
      "alpha = 0.09 beta = 0.11\n",
      "alpha = 0.09 beta = 0.12\n",
      "alpha = 0.09 beta = 0.13\n",
      "alpha = 0.09 beta = 0.14\n",
      "alpha = 0.09 beta = 0.15\n",
      "alpha = 0.09 beta = 0.16\n",
      "alpha = 0.09 beta = 0.17\n",
      "alpha = 0.09 beta = 0.18\n",
      "alpha = 0.09 beta = 0.19\n",
      "alpha = 0.1 beta = 0.0\n",
      "alpha = 0.1 beta = 0.01\n",
      "alpha = 0.1 beta = 0.02\n",
      "alpha = 0.1 beta = 0.03\n",
      "alpha = 0.1 beta = 0.04\n",
      "alpha = 0.1 beta = 0.05\n",
      "alpha = 0.1 beta = 0.06\n",
      "alpha = 0.1 beta = 0.07\n",
      "alpha = 0.1 beta = 0.08\n",
      "alpha = 0.1 beta = 0.09\n",
      "alpha = 0.1 beta = 0.1\n",
      "alpha = 0.1 beta = 0.11\n",
      "alpha = 0.1 beta = 0.12\n",
      "alpha = 0.1 beta = 0.13\n",
      "alpha = 0.1 beta = 0.14\n",
      "alpha = 0.1 beta = 0.15\n",
      "alpha = 0.1 beta = 0.16\n",
      "alpha = 0.1 beta = 0.17\n",
      "alpha = 0.1 beta = 0.18\n",
      "alpha = 0.1 beta = 0.19\n",
      "alpha = 0.11 beta = 0.0\n",
      "alpha = 0.11 beta = 0.01\n",
      "alpha = 0.11 beta = 0.02\n",
      "alpha = 0.11 beta = 0.03\n",
      "alpha = 0.11 beta = 0.04\n",
      "alpha = 0.11 beta = 0.05\n",
      "alpha = 0.11 beta = 0.06\n",
      "alpha = 0.11 beta = 0.07\n",
      "alpha = 0.11 beta = 0.08\n",
      "alpha = 0.11 beta = 0.09\n",
      "alpha = 0.11 beta = 0.1\n",
      "alpha = 0.11 beta = 0.11\n",
      "alpha = 0.11 beta = 0.12\n",
      "alpha = 0.11 beta = 0.13\n",
      "alpha = 0.11 beta = 0.14\n",
      "alpha = 0.11 beta = 0.15\n",
      "alpha = 0.11 beta = 0.16\n",
      "alpha = 0.11 beta = 0.17\n",
      "alpha = 0.11 beta = 0.18\n",
      "alpha = 0.11 beta = 0.19\n",
      "alpha = 0.12 beta = 0.0\n",
      "alpha = 0.12 beta = 0.01\n",
      "alpha = 0.12 beta = 0.02\n",
      "alpha = 0.12 beta = 0.03\n",
      "alpha = 0.12 beta = 0.04\n",
      "alpha = 0.12 beta = 0.05\n",
      "alpha = 0.12 beta = 0.06\n",
      "alpha = 0.12 beta = 0.07\n",
      "alpha = 0.12 beta = 0.08\n",
      "alpha = 0.12 beta = 0.09\n",
      "alpha = 0.12 beta = 0.1\n",
      "alpha = 0.12 beta = 0.11\n",
      "alpha = 0.12 beta = 0.12\n",
      "alpha = 0.12 beta = 0.13\n",
      "alpha = 0.12 beta = 0.14\n",
      "alpha = 0.12 beta = 0.15\n",
      "alpha = 0.12 beta = 0.16\n",
      "alpha = 0.12 beta = 0.17\n",
      "alpha = 0.12 beta = 0.18\n",
      "alpha = 0.12 beta = 0.19\n",
      "alpha = 0.13 beta = 0.0\n",
      "alpha = 0.13 beta = 0.01\n",
      "alpha = 0.13 beta = 0.02\n",
      "alpha = 0.13 beta = 0.03\n",
      "alpha = 0.13 beta = 0.04\n",
      "alpha = 0.13 beta = 0.05\n",
      "alpha = 0.13 beta = 0.06\n",
      "alpha = 0.13 beta = 0.07\n",
      "alpha = 0.13 beta = 0.08\n",
      "alpha = 0.13 beta = 0.09\n",
      "alpha = 0.13 beta = 0.1\n",
      "alpha = 0.13 beta = 0.11\n",
      "alpha = 0.13 beta = 0.12\n",
      "alpha = 0.13 beta = 0.13\n",
      "alpha = 0.13 beta = 0.14\n",
      "alpha = 0.13 beta = 0.15\n",
      "alpha = 0.13 beta = 0.16\n",
      "alpha = 0.13 beta = 0.17\n",
      "alpha = 0.13 beta = 0.18\n",
      "alpha = 0.13 beta = 0.19\n",
      "alpha = 0.14 beta = 0.0\n",
      "alpha = 0.14 beta = 0.01\n",
      "alpha = 0.14 beta = 0.02\n",
      "alpha = 0.14 beta = 0.03\n",
      "alpha = 0.14 beta = 0.04\n",
      "alpha = 0.14 beta = 0.05\n",
      "alpha = 0.14 beta = 0.06\n",
      "alpha = 0.14 beta = 0.07\n",
      "alpha = 0.14 beta = 0.08\n",
      "alpha = 0.14 beta = 0.09\n",
      "alpha = 0.14 beta = 0.1\n",
      "alpha = 0.14 beta = 0.11\n",
      "alpha = 0.14 beta = 0.12\n",
      "alpha = 0.14 beta = 0.13\n",
      "alpha = 0.14 beta = 0.14\n",
      "alpha = 0.14 beta = 0.15\n",
      "alpha = 0.14 beta = 0.16\n",
      "alpha = 0.14 beta = 0.17\n",
      "alpha = 0.14 beta = 0.18\n",
      "alpha = 0.14 beta = 0.19\n",
      "alpha = 0.15 beta = 0.0\n",
      "alpha = 0.15 beta = 0.01\n",
      "alpha = 0.15 beta = 0.02\n",
      "alpha = 0.15 beta = 0.03\n",
      "alpha = 0.15 beta = 0.04\n",
      "alpha = 0.15 beta = 0.05\n",
      "alpha = 0.15 beta = 0.06\n",
      "alpha = 0.15 beta = 0.07\n",
      "alpha = 0.15 beta = 0.08\n",
      "alpha = 0.15 beta = 0.09\n",
      "alpha = 0.15 beta = 0.1\n",
      "alpha = 0.15 beta = 0.11\n",
      "alpha = 0.15 beta = 0.12\n",
      "alpha = 0.15 beta = 0.13\n",
      "alpha = 0.15 beta = 0.14\n",
      "alpha = 0.15 beta = 0.15\n",
      "alpha = 0.15 beta = 0.16\n",
      "alpha = 0.15 beta = 0.17\n",
      "alpha = 0.15 beta = 0.18\n",
      "alpha = 0.15 beta = 0.19\n",
      "alpha = 0.16 beta = 0.0\n",
      "alpha = 0.16 beta = 0.01\n",
      "alpha = 0.16 beta = 0.02\n",
      "alpha = 0.16 beta = 0.03\n",
      "alpha = 0.16 beta = 0.04\n",
      "alpha = 0.16 beta = 0.05\n",
      "alpha = 0.16 beta = 0.06\n",
      "alpha = 0.16 beta = 0.07\n",
      "alpha = 0.16 beta = 0.08\n",
      "alpha = 0.16 beta = 0.09\n",
      "alpha = 0.16 beta = 0.1\n",
      "alpha = 0.16 beta = 0.11\n",
      "alpha = 0.16 beta = 0.12\n",
      "alpha = 0.16 beta = 0.13\n",
      "alpha = 0.16 beta = 0.14\n",
      "alpha = 0.16 beta = 0.15\n",
      "alpha = 0.16 beta = 0.16\n",
      "alpha = 0.16 beta = 0.17\n",
      "alpha = 0.16 beta = 0.18\n",
      "alpha = 0.16 beta = 0.19\n",
      "alpha = 0.17 beta = 0.0\n",
      "alpha = 0.17 beta = 0.01\n",
      "alpha = 0.17 beta = 0.02\n",
      "alpha = 0.17 beta = 0.03\n",
      "alpha = 0.17 beta = 0.04\n",
      "alpha = 0.17 beta = 0.05\n",
      "alpha = 0.17 beta = 0.06\n",
      "alpha = 0.17 beta = 0.07\n",
      "alpha = 0.17 beta = 0.08\n",
      "alpha = 0.17 beta = 0.09\n",
      "alpha = 0.17 beta = 0.1\n",
      "alpha = 0.17 beta = 0.11\n",
      "alpha = 0.17 beta = 0.12\n",
      "alpha = 0.17 beta = 0.13\n",
      "alpha = 0.17 beta = 0.14\n",
      "alpha = 0.17 beta = 0.15\n",
      "alpha = 0.17 beta = 0.16\n",
      "alpha = 0.17 beta = 0.17\n",
      "alpha = 0.17 beta = 0.18\n",
      "alpha = 0.17 beta = 0.19\n",
      "alpha = 0.18 beta = 0.0\n",
      "alpha = 0.18 beta = 0.01\n",
      "alpha = 0.18 beta = 0.02\n",
      "alpha = 0.18 beta = 0.03\n",
      "alpha = 0.18 beta = 0.04\n",
      "alpha = 0.18 beta = 0.05\n",
      "alpha = 0.18 beta = 0.06\n",
      "alpha = 0.18 beta = 0.07\n",
      "alpha = 0.18 beta = 0.08\n",
      "alpha = 0.18 beta = 0.09\n",
      "alpha = 0.18 beta = 0.1\n",
      "alpha = 0.18 beta = 0.11\n",
      "alpha = 0.18 beta = 0.12\n",
      "alpha = 0.18 beta = 0.13\n",
      "alpha = 0.18 beta = 0.14\n",
      "alpha = 0.18 beta = 0.15\n",
      "alpha = 0.18 beta = 0.16\n",
      "alpha = 0.18 beta = 0.17\n",
      "alpha = 0.18 beta = 0.18\n",
      "alpha = 0.18 beta = 0.19\n",
      "alpha = 0.19 beta = 0.0\n",
      "alpha = 0.19 beta = 0.01\n",
      "alpha = 0.19 beta = 0.02\n",
      "alpha = 0.19 beta = 0.03\n",
      "alpha = 0.19 beta = 0.04\n",
      "alpha = 0.19 beta = 0.05\n",
      "alpha = 0.19 beta = 0.06\n",
      "alpha = 0.19 beta = 0.07\n",
      "alpha = 0.19 beta = 0.08\n",
      "alpha = 0.19 beta = 0.09\n",
      "alpha = 0.19 beta = 0.1\n",
      "alpha = 0.19 beta = 0.11\n",
      "alpha = 0.19 beta = 0.12\n",
      "alpha = 0.19 beta = 0.13\n",
      "alpha = 0.19 beta = 0.14\n",
      "alpha = 0.19 beta = 0.15\n",
      "alpha = 0.19 beta = 0.16\n",
      "alpha = 0.19 beta = 0.17\n",
      "alpha = 0.19 beta = 0.18\n",
      "alpha = 0.19 beta = 0.19\n",
      "alpha = 0.0 beta = 0.0\n",
      "alpha = 0.0 beta = 0.01\n",
      "alpha = 0.0 beta = 0.02\n",
      "alpha = 0.0 beta = 0.03\n",
      "alpha = 0.0 beta = 0.04\n",
      "alpha = 0.0 beta = 0.05\n",
      "alpha = 0.0 beta = 0.06\n",
      "alpha = 0.0 beta = 0.07\n",
      "alpha = 0.0 beta = 0.08\n",
      "alpha = 0.0 beta = 0.09\n",
      "alpha = 0.0 beta = 0.1\n",
      "alpha = 0.0 beta = 0.11\n",
      "alpha = 0.0 beta = 0.12\n",
      "alpha = 0.0 beta = 0.13\n",
      "alpha = 0.0 beta = 0.14\n",
      "alpha = 0.0 beta = 0.15\n",
      "alpha = 0.0 beta = 0.16\n",
      "alpha = 0.0 beta = 0.17\n",
      "alpha = 0.0 beta = 0.18\n",
      "alpha = 0.0 beta = 0.19\n",
      "alpha = 0.01 beta = 0.0\n",
      "alpha = 0.01 beta = 0.01\n",
      "alpha = 0.01 beta = 0.02\n",
      "alpha = 0.01 beta = 0.03\n",
      "alpha = 0.01 beta = 0.04\n",
      "alpha = 0.01 beta = 0.05\n",
      "alpha = 0.01 beta = 0.06\n",
      "alpha = 0.01 beta = 0.07\n",
      "alpha = 0.01 beta = 0.08\n",
      "alpha = 0.01 beta = 0.09\n",
      "alpha = 0.01 beta = 0.1\n",
      "alpha = 0.01 beta = 0.11\n",
      "alpha = 0.01 beta = 0.12\n",
      "alpha = 0.01 beta = 0.13\n",
      "alpha = 0.01 beta = 0.14\n",
      "alpha = 0.01 beta = 0.15\n",
      "alpha = 0.01 beta = 0.16\n",
      "alpha = 0.01 beta = 0.17\n",
      "alpha = 0.01 beta = 0.18\n",
      "alpha = 0.01 beta = 0.19\n",
      "alpha = 0.02 beta = 0.0\n",
      "alpha = 0.02 beta = 0.01\n",
      "alpha = 0.02 beta = 0.02\n",
      "alpha = 0.02 beta = 0.03\n",
      "alpha = 0.02 beta = 0.04\n",
      "alpha = 0.02 beta = 0.05\n",
      "alpha = 0.02 beta = 0.06\n",
      "alpha = 0.02 beta = 0.07\n",
      "alpha = 0.02 beta = 0.08\n",
      "alpha = 0.02 beta = 0.09\n",
      "alpha = 0.02 beta = 0.1\n",
      "alpha = 0.02 beta = 0.11\n",
      "alpha = 0.02 beta = 0.12\n",
      "alpha = 0.02 beta = 0.13\n",
      "alpha = 0.02 beta = 0.14\n",
      "alpha = 0.02 beta = 0.15\n",
      "alpha = 0.02 beta = 0.16\n",
      "alpha = 0.02 beta = 0.17\n",
      "alpha = 0.02 beta = 0.18\n",
      "alpha = 0.02 beta = 0.19\n",
      "alpha = 0.03 beta = 0.0\n",
      "alpha = 0.03 beta = 0.01\n",
      "alpha = 0.03 beta = 0.02\n",
      "alpha = 0.03 beta = 0.03\n",
      "alpha = 0.03 beta = 0.04\n",
      "alpha = 0.03 beta = 0.05\n",
      "alpha = 0.03 beta = 0.06\n",
      "alpha = 0.03 beta = 0.07\n",
      "alpha = 0.03 beta = 0.08\n",
      "alpha = 0.03 beta = 0.09\n",
      "alpha = 0.03 beta = 0.1\n",
      "alpha = 0.03 beta = 0.11\n",
      "alpha = 0.03 beta = 0.12\n",
      "alpha = 0.03 beta = 0.13\n",
      "alpha = 0.03 beta = 0.14\n",
      "alpha = 0.03 beta = 0.15\n",
      "alpha = 0.03 beta = 0.16\n",
      "alpha = 0.03 beta = 0.17\n",
      "alpha = 0.03 beta = 0.18\n",
      "alpha = 0.03 beta = 0.19\n",
      "alpha = 0.04 beta = 0.0\n",
      "alpha = 0.04 beta = 0.01\n",
      "alpha = 0.04 beta = 0.02\n",
      "alpha = 0.04 beta = 0.03\n",
      "alpha = 0.04 beta = 0.04\n",
      "alpha = 0.04 beta = 0.05\n",
      "alpha = 0.04 beta = 0.06\n",
      "alpha = 0.04 beta = 0.07\n",
      "alpha = 0.04 beta = 0.08\n",
      "alpha = 0.04 beta = 0.09\n",
      "alpha = 0.04 beta = 0.1\n",
      "alpha = 0.04 beta = 0.11\n",
      "alpha = 0.04 beta = 0.12\n",
      "alpha = 0.04 beta = 0.13\n",
      "alpha = 0.04 beta = 0.14\n",
      "alpha = 0.04 beta = 0.15\n",
      "alpha = 0.04 beta = 0.16\n",
      "alpha = 0.04 beta = 0.17\n",
      "alpha = 0.04 beta = 0.18\n",
      "alpha = 0.04 beta = 0.19\n",
      "alpha = 0.05 beta = 0.0\n",
      "alpha = 0.05 beta = 0.01\n",
      "alpha = 0.05 beta = 0.02\n",
      "alpha = 0.05 beta = 0.03\n",
      "alpha = 0.05 beta = 0.04\n",
      "alpha = 0.05 beta = 0.05\n",
      "alpha = 0.05 beta = 0.06\n",
      "alpha = 0.05 beta = 0.07\n",
      "alpha = 0.05 beta = 0.08\n",
      "alpha = 0.05 beta = 0.09\n",
      "alpha = 0.05 beta = 0.1\n",
      "alpha = 0.05 beta = 0.11\n",
      "alpha = 0.05 beta = 0.12\n",
      "alpha = 0.05 beta = 0.13\n",
      "alpha = 0.05 beta = 0.14\n",
      "alpha = 0.05 beta = 0.15\n",
      "alpha = 0.05 beta = 0.16\n",
      "alpha = 0.05 beta = 0.17\n",
      "alpha = 0.05 beta = 0.18\n",
      "alpha = 0.05 beta = 0.19\n",
      "alpha = 0.06 beta = 0.0\n",
      "alpha = 0.06 beta = 0.01\n",
      "alpha = 0.06 beta = 0.02\n",
      "alpha = 0.06 beta = 0.03\n",
      "alpha = 0.06 beta = 0.04\n",
      "alpha = 0.06 beta = 0.05\n",
      "alpha = 0.06 beta = 0.06\n",
      "alpha = 0.06 beta = 0.07\n",
      "alpha = 0.06 beta = 0.08\n",
      "alpha = 0.06 beta = 0.09\n",
      "alpha = 0.06 beta = 0.1\n",
      "alpha = 0.06 beta = 0.11\n",
      "alpha = 0.06 beta = 0.12\n",
      "alpha = 0.06 beta = 0.13\n",
      "alpha = 0.06 beta = 0.14\n",
      "alpha = 0.06 beta = 0.15\n",
      "alpha = 0.06 beta = 0.16\n",
      "alpha = 0.06 beta = 0.17\n",
      "alpha = 0.06 beta = 0.18\n",
      "alpha = 0.06 beta = 0.19\n",
      "alpha = 0.07 beta = 0.0\n",
      "alpha = 0.07 beta = 0.01\n",
      "alpha = 0.07 beta = 0.02\n",
      "alpha = 0.07 beta = 0.03\n",
      "alpha = 0.07 beta = 0.04\n",
      "alpha = 0.07 beta = 0.05\n",
      "alpha = 0.07 beta = 0.06\n",
      "alpha = 0.07 beta = 0.07\n",
      "alpha = 0.07 beta = 0.08\n",
      "alpha = 0.07 beta = 0.09\n",
      "alpha = 0.07 beta = 0.1\n",
      "alpha = 0.07 beta = 0.11\n",
      "alpha = 0.07 beta = 0.12\n",
      "alpha = 0.07 beta = 0.13\n",
      "alpha = 0.07 beta = 0.14\n",
      "alpha = 0.07 beta = 0.15\n",
      "alpha = 0.07 beta = 0.16\n",
      "alpha = 0.07 beta = 0.17\n",
      "alpha = 0.07 beta = 0.18\n",
      "alpha = 0.07 beta = 0.19\n",
      "alpha = 0.08 beta = 0.0\n",
      "alpha = 0.08 beta = 0.01\n",
      "alpha = 0.08 beta = 0.02\n",
      "alpha = 0.08 beta = 0.03\n",
      "alpha = 0.08 beta = 0.04\n",
      "alpha = 0.08 beta = 0.05\n",
      "alpha = 0.08 beta = 0.06\n",
      "alpha = 0.08 beta = 0.07\n",
      "alpha = 0.08 beta = 0.08\n",
      "alpha = 0.08 beta = 0.09\n",
      "alpha = 0.08 beta = 0.1\n",
      "alpha = 0.08 beta = 0.11\n",
      "alpha = 0.08 beta = 0.12\n",
      "alpha = 0.08 beta = 0.13\n",
      "alpha = 0.08 beta = 0.14\n",
      "alpha = 0.08 beta = 0.15\n",
      "alpha = 0.08 beta = 0.16\n",
      "alpha = 0.08 beta = 0.17\n",
      "alpha = 0.08 beta = 0.18\n",
      "alpha = 0.08 beta = 0.19\n",
      "alpha = 0.09 beta = 0.0\n",
      "alpha = 0.09 beta = 0.01\n",
      "alpha = 0.09 beta = 0.02\n",
      "alpha = 0.09 beta = 0.03\n",
      "alpha = 0.09 beta = 0.04\n",
      "alpha = 0.09 beta = 0.05\n",
      "alpha = 0.09 beta = 0.06\n",
      "alpha = 0.09 beta = 0.07\n",
      "alpha = 0.09 beta = 0.08\n",
      "alpha = 0.09 beta = 0.09\n",
      "alpha = 0.09 beta = 0.1\n",
      "alpha = 0.09 beta = 0.11\n",
      "alpha = 0.09 beta = 0.12\n",
      "alpha = 0.09 beta = 0.13\n",
      "alpha = 0.09 beta = 0.14\n",
      "alpha = 0.09 beta = 0.15\n",
      "alpha = 0.09 beta = 0.16\n",
      "alpha = 0.09 beta = 0.17\n",
      "alpha = 0.09 beta = 0.18\n",
      "alpha = 0.09 beta = 0.19\n",
      "alpha = 0.1 beta = 0.0\n",
      "alpha = 0.1 beta = 0.01\n",
      "alpha = 0.1 beta = 0.02\n",
      "alpha = 0.1 beta = 0.03\n",
      "alpha = 0.1 beta = 0.04\n",
      "alpha = 0.1 beta = 0.05\n",
      "alpha = 0.1 beta = 0.06\n",
      "alpha = 0.1 beta = 0.07\n",
      "alpha = 0.1 beta = 0.08\n",
      "alpha = 0.1 beta = 0.09\n",
      "alpha = 0.1 beta = 0.1\n",
      "alpha = 0.1 beta = 0.11\n",
      "alpha = 0.1 beta = 0.12\n",
      "alpha = 0.1 beta = 0.13\n",
      "alpha = 0.1 beta = 0.14\n",
      "alpha = 0.1 beta = 0.15\n",
      "alpha = 0.1 beta = 0.16\n",
      "alpha = 0.1 beta = 0.17\n",
      "alpha = 0.1 beta = 0.18\n",
      "alpha = 0.1 beta = 0.19\n",
      "alpha = 0.11 beta = 0.0\n",
      "alpha = 0.11 beta = 0.01\n",
      "alpha = 0.11 beta = 0.02\n",
      "alpha = 0.11 beta = 0.03\n",
      "alpha = 0.11 beta = 0.04\n",
      "alpha = 0.11 beta = 0.05\n",
      "alpha = 0.11 beta = 0.06\n",
      "alpha = 0.11 beta = 0.07\n",
      "alpha = 0.11 beta = 0.08\n",
      "alpha = 0.11 beta = 0.09\n",
      "alpha = 0.11 beta = 0.1\n",
      "alpha = 0.11 beta = 0.11\n",
      "alpha = 0.11 beta = 0.12\n",
      "alpha = 0.11 beta = 0.13\n",
      "alpha = 0.11 beta = 0.14\n",
      "alpha = 0.11 beta = 0.15\n",
      "alpha = 0.11 beta = 0.16\n",
      "alpha = 0.11 beta = 0.17\n",
      "alpha = 0.11 beta = 0.18\n",
      "alpha = 0.11 beta = 0.19\n",
      "alpha = 0.12 beta = 0.0\n",
      "alpha = 0.12 beta = 0.01\n",
      "alpha = 0.12 beta = 0.02\n",
      "alpha = 0.12 beta = 0.03\n",
      "alpha = 0.12 beta = 0.04\n",
      "alpha = 0.12 beta = 0.05\n",
      "alpha = 0.12 beta = 0.06\n",
      "alpha = 0.12 beta = 0.07\n",
      "alpha = 0.12 beta = 0.08\n",
      "alpha = 0.12 beta = 0.09\n",
      "alpha = 0.12 beta = 0.1\n",
      "alpha = 0.12 beta = 0.11\n",
      "alpha = 0.12 beta = 0.12\n",
      "alpha = 0.12 beta = 0.13\n",
      "alpha = 0.12 beta = 0.14\n",
      "alpha = 0.12 beta = 0.15\n",
      "alpha = 0.12 beta = 0.16\n",
      "alpha = 0.12 beta = 0.17\n",
      "alpha = 0.12 beta = 0.18\n",
      "alpha = 0.12 beta = 0.19\n",
      "alpha = 0.13 beta = 0.0\n",
      "alpha = 0.13 beta = 0.01\n",
      "alpha = 0.13 beta = 0.02\n",
      "alpha = 0.13 beta = 0.03\n",
      "alpha = 0.13 beta = 0.04\n",
      "alpha = 0.13 beta = 0.05\n",
      "alpha = 0.13 beta = 0.06\n",
      "alpha = 0.13 beta = 0.07\n",
      "alpha = 0.13 beta = 0.08\n",
      "alpha = 0.13 beta = 0.09\n",
      "alpha = 0.13 beta = 0.1\n",
      "alpha = 0.13 beta = 0.11\n",
      "alpha = 0.13 beta = 0.12\n",
      "alpha = 0.13 beta = 0.13\n",
      "alpha = 0.13 beta = 0.14\n",
      "alpha = 0.13 beta = 0.15\n",
      "alpha = 0.13 beta = 0.16\n",
      "alpha = 0.13 beta = 0.17\n",
      "alpha = 0.13 beta = 0.18\n",
      "alpha = 0.13 beta = 0.19\n",
      "alpha = 0.14 beta = 0.0\n",
      "alpha = 0.14 beta = 0.01\n",
      "alpha = 0.14 beta = 0.02\n",
      "alpha = 0.14 beta = 0.03\n",
      "alpha = 0.14 beta = 0.04\n",
      "alpha = 0.14 beta = 0.05\n",
      "alpha = 0.14 beta = 0.06\n",
      "alpha = 0.14 beta = 0.07\n",
      "alpha = 0.14 beta = 0.08\n",
      "alpha = 0.14 beta = 0.09\n",
      "alpha = 0.14 beta = 0.1\n",
      "alpha = 0.14 beta = 0.11\n",
      "alpha = 0.14 beta = 0.12\n",
      "alpha = 0.14 beta = 0.13\n",
      "alpha = 0.14 beta = 0.14\n",
      "alpha = 0.14 beta = 0.15\n",
      "alpha = 0.14 beta = 0.16\n",
      "alpha = 0.14 beta = 0.17\n",
      "alpha = 0.14 beta = 0.18\n",
      "alpha = 0.14 beta = 0.19\n",
      "alpha = 0.15 beta = 0.0\n",
      "alpha = 0.15 beta = 0.01\n",
      "alpha = 0.15 beta = 0.02\n",
      "alpha = 0.15 beta = 0.03\n",
      "alpha = 0.15 beta = 0.04\n",
      "alpha = 0.15 beta = 0.05\n",
      "alpha = 0.15 beta = 0.06\n",
      "alpha = 0.15 beta = 0.07\n",
      "alpha = 0.15 beta = 0.08\n",
      "alpha = 0.15 beta = 0.09\n",
      "alpha = 0.15 beta = 0.1\n",
      "alpha = 0.15 beta = 0.11\n",
      "alpha = 0.15 beta = 0.12\n",
      "alpha = 0.15 beta = 0.13\n",
      "alpha = 0.15 beta = 0.14\n",
      "alpha = 0.15 beta = 0.15\n",
      "alpha = 0.15 beta = 0.16\n",
      "alpha = 0.15 beta = 0.17\n",
      "alpha = 0.15 beta = 0.18\n",
      "alpha = 0.15 beta = 0.19\n",
      "alpha = 0.16 beta = 0.0\n",
      "alpha = 0.16 beta = 0.01\n",
      "alpha = 0.16 beta = 0.02\n",
      "alpha = 0.16 beta = 0.03\n",
      "alpha = 0.16 beta = 0.04\n",
      "alpha = 0.16 beta = 0.05\n",
      "alpha = 0.16 beta = 0.06\n",
      "alpha = 0.16 beta = 0.07\n",
      "alpha = 0.16 beta = 0.08\n",
      "alpha = 0.16 beta = 0.09\n",
      "alpha = 0.16 beta = 0.1\n",
      "alpha = 0.16 beta = 0.11\n",
      "alpha = 0.16 beta = 0.12\n",
      "alpha = 0.16 beta = 0.13\n",
      "alpha = 0.16 beta = 0.14\n",
      "alpha = 0.16 beta = 0.15\n",
      "alpha = 0.16 beta = 0.16\n",
      "alpha = 0.16 beta = 0.17\n",
      "alpha = 0.16 beta = 0.18\n",
      "alpha = 0.16 beta = 0.19\n",
      "alpha = 0.17 beta = 0.0\n",
      "alpha = 0.17 beta = 0.01\n",
      "alpha = 0.17 beta = 0.02\n",
      "alpha = 0.17 beta = 0.03\n",
      "alpha = 0.17 beta = 0.04\n",
      "alpha = 0.17 beta = 0.05\n",
      "alpha = 0.17 beta = 0.06\n",
      "alpha = 0.17 beta = 0.07\n",
      "alpha = 0.17 beta = 0.08\n",
      "alpha = 0.17 beta = 0.09\n",
      "alpha = 0.17 beta = 0.1\n",
      "alpha = 0.17 beta = 0.11\n",
      "alpha = 0.17 beta = 0.12\n",
      "alpha = 0.17 beta = 0.13\n",
      "alpha = 0.17 beta = 0.14\n",
      "alpha = 0.17 beta = 0.15\n",
      "alpha = 0.17 beta = 0.16\n",
      "alpha = 0.17 beta = 0.17\n",
      "alpha = 0.17 beta = 0.18\n",
      "alpha = 0.17 beta = 0.19\n",
      "alpha = 0.18 beta = 0.0\n",
      "alpha = 0.18 beta = 0.01\n",
      "alpha = 0.18 beta = 0.02\n",
      "alpha = 0.18 beta = 0.03\n",
      "alpha = 0.18 beta = 0.04\n",
      "alpha = 0.18 beta = 0.05\n",
      "alpha = 0.18 beta = 0.06\n",
      "alpha = 0.18 beta = 0.07\n",
      "alpha = 0.18 beta = 0.08\n",
      "alpha = 0.18 beta = 0.09\n",
      "alpha = 0.18 beta = 0.1\n",
      "alpha = 0.18 beta = 0.11\n",
      "alpha = 0.18 beta = 0.12\n",
      "alpha = 0.18 beta = 0.13\n",
      "alpha = 0.18 beta = 0.14\n",
      "alpha = 0.18 beta = 0.15\n",
      "alpha = 0.18 beta = 0.16\n",
      "alpha = 0.18 beta = 0.17\n",
      "alpha = 0.18 beta = 0.18\n",
      "alpha = 0.18 beta = 0.19\n",
      "alpha = 0.19 beta = 0.0\n",
      "alpha = 0.19 beta = 0.01\n",
      "alpha = 0.19 beta = 0.02\n",
      "alpha = 0.19 beta = 0.03\n",
      "alpha = 0.19 beta = 0.04\n",
      "alpha = 0.19 beta = 0.05\n",
      "alpha = 0.19 beta = 0.06\n",
      "alpha = 0.19 beta = 0.07\n",
      "alpha = 0.19 beta = 0.08\n",
      "alpha = 0.19 beta = 0.09\n",
      "alpha = 0.19 beta = 0.1\n",
      "alpha = 0.19 beta = 0.11\n",
      "alpha = 0.19 beta = 0.12\n",
      "alpha = 0.19 beta = 0.13\n",
      "alpha = 0.19 beta = 0.14\n",
      "alpha = 0.19 beta = 0.15\n",
      "alpha = 0.19 beta = 0.16\n",
      "alpha = 0.19 beta = 0.17\n",
      "alpha = 0.19 beta = 0.18\n",
      "alpha = 0.19 beta = 0.19\n",
      "alpha = 0.0 beta = 0.0\n",
      "alpha = 0.0 beta = 0.01\n",
      "alpha = 0.0 beta = 0.02\n",
      "alpha = 0.0 beta = 0.03\n",
      "alpha = 0.0 beta = 0.04\n",
      "alpha = 0.0 beta = 0.05\n",
      "alpha = 0.0 beta = 0.06\n",
      "alpha = 0.0 beta = 0.07\n",
      "alpha = 0.0 beta = 0.08\n",
      "alpha = 0.0 beta = 0.09\n",
      "alpha = 0.0 beta = 0.1\n",
      "alpha = 0.0 beta = 0.11\n",
      "alpha = 0.0 beta = 0.12\n",
      "alpha = 0.0 beta = 0.13\n",
      "alpha = 0.0 beta = 0.14\n",
      "alpha = 0.0 beta = 0.15\n",
      "alpha = 0.0 beta = 0.16\n",
      "alpha = 0.0 beta = 0.17\n",
      "alpha = 0.0 beta = 0.18\n",
      "alpha = 0.0 beta = 0.19\n",
      "alpha = 0.01 beta = 0.0\n",
      "alpha = 0.01 beta = 0.01\n",
      "alpha = 0.01 beta = 0.02\n",
      "alpha = 0.01 beta = 0.03\n",
      "alpha = 0.01 beta = 0.04\n",
      "alpha = 0.01 beta = 0.05\n",
      "alpha = 0.01 beta = 0.06\n",
      "alpha = 0.01 beta = 0.07\n",
      "alpha = 0.01 beta = 0.08\n",
      "alpha = 0.01 beta = 0.09\n",
      "alpha = 0.01 beta = 0.1\n",
      "alpha = 0.01 beta = 0.11\n",
      "alpha = 0.01 beta = 0.12\n",
      "alpha = 0.01 beta = 0.13\n",
      "alpha = 0.01 beta = 0.14\n",
      "alpha = 0.01 beta = 0.15\n",
      "alpha = 0.01 beta = 0.16\n",
      "alpha = 0.01 beta = 0.17\n",
      "alpha = 0.01 beta = 0.18\n",
      "alpha = 0.01 beta = 0.19\n",
      "alpha = 0.02 beta = 0.0\n",
      "alpha = 0.02 beta = 0.01\n",
      "alpha = 0.02 beta = 0.02\n",
      "alpha = 0.02 beta = 0.03\n",
      "alpha = 0.02 beta = 0.04\n",
      "alpha = 0.02 beta = 0.05\n",
      "alpha = 0.02 beta = 0.06\n",
      "alpha = 0.02 beta = 0.07\n",
      "alpha = 0.02 beta = 0.08\n",
      "alpha = 0.02 beta = 0.09\n",
      "alpha = 0.02 beta = 0.1\n",
      "alpha = 0.02 beta = 0.11\n",
      "alpha = 0.02 beta = 0.12\n",
      "alpha = 0.02 beta = 0.13\n",
      "alpha = 0.02 beta = 0.14\n",
      "alpha = 0.02 beta = 0.15\n",
      "alpha = 0.02 beta = 0.16\n",
      "alpha = 0.02 beta = 0.17\n",
      "alpha = 0.02 beta = 0.18\n",
      "alpha = 0.02 beta = 0.19\n",
      "alpha = 0.03 beta = 0.0\n",
      "alpha = 0.03 beta = 0.01\n",
      "alpha = 0.03 beta = 0.02\n",
      "alpha = 0.03 beta = 0.03\n",
      "alpha = 0.03 beta = 0.04\n",
      "alpha = 0.03 beta = 0.05\n",
      "alpha = 0.03 beta = 0.06\n",
      "alpha = 0.03 beta = 0.07\n",
      "alpha = 0.03 beta = 0.08\n",
      "alpha = 0.03 beta = 0.09\n",
      "alpha = 0.03 beta = 0.1\n",
      "alpha = 0.03 beta = 0.11\n",
      "alpha = 0.03 beta = 0.12\n",
      "alpha = 0.03 beta = 0.13\n",
      "alpha = 0.03 beta = 0.14\n",
      "alpha = 0.03 beta = 0.15\n",
      "alpha = 0.03 beta = 0.16\n",
      "alpha = 0.03 beta = 0.17\n",
      "alpha = 0.03 beta = 0.18\n",
      "alpha = 0.03 beta = 0.19\n",
      "alpha = 0.04 beta = 0.0\n",
      "alpha = 0.04 beta = 0.01\n",
      "alpha = 0.04 beta = 0.02\n",
      "alpha = 0.04 beta = 0.03\n",
      "alpha = 0.04 beta = 0.04\n",
      "alpha = 0.04 beta = 0.05\n",
      "alpha = 0.04 beta = 0.06\n",
      "alpha = 0.04 beta = 0.07\n",
      "alpha = 0.04 beta = 0.08\n",
      "alpha = 0.04 beta = 0.09\n",
      "alpha = 0.04 beta = 0.1\n",
      "alpha = 0.04 beta = 0.11\n",
      "alpha = 0.04 beta = 0.12\n",
      "alpha = 0.04 beta = 0.13\n",
      "alpha = 0.04 beta = 0.14\n",
      "alpha = 0.04 beta = 0.15\n",
      "alpha = 0.04 beta = 0.16\n",
      "alpha = 0.04 beta = 0.17\n",
      "alpha = 0.04 beta = 0.18\n",
      "alpha = 0.04 beta = 0.19\n",
      "alpha = 0.05 beta = 0.0\n",
      "alpha = 0.05 beta = 0.01\n",
      "alpha = 0.05 beta = 0.02\n",
      "alpha = 0.05 beta = 0.03\n",
      "alpha = 0.05 beta = 0.04\n",
      "alpha = 0.05 beta = 0.05\n",
      "alpha = 0.05 beta = 0.06\n",
      "alpha = 0.05 beta = 0.07\n",
      "alpha = 0.05 beta = 0.08\n",
      "alpha = 0.05 beta = 0.09\n",
      "alpha = 0.05 beta = 0.1\n",
      "alpha = 0.05 beta = 0.11\n",
      "alpha = 0.05 beta = 0.12\n",
      "alpha = 0.05 beta = 0.13\n",
      "alpha = 0.05 beta = 0.14\n",
      "alpha = 0.05 beta = 0.15\n",
      "alpha = 0.05 beta = 0.16\n",
      "alpha = 0.05 beta = 0.17\n",
      "alpha = 0.05 beta = 0.18\n",
      "alpha = 0.05 beta = 0.19\n",
      "alpha = 0.06 beta = 0.0\n",
      "alpha = 0.06 beta = 0.01\n",
      "alpha = 0.06 beta = 0.02\n",
      "alpha = 0.06 beta = 0.03\n",
      "alpha = 0.06 beta = 0.04\n",
      "alpha = 0.06 beta = 0.05\n",
      "alpha = 0.06 beta = 0.06\n",
      "alpha = 0.06 beta = 0.07\n",
      "alpha = 0.06 beta = 0.08\n",
      "alpha = 0.06 beta = 0.09\n",
      "alpha = 0.06 beta = 0.1\n",
      "alpha = 0.06 beta = 0.11\n",
      "alpha = 0.06 beta = 0.12\n",
      "alpha = 0.06 beta = 0.13\n",
      "alpha = 0.06 beta = 0.14\n",
      "alpha = 0.06 beta = 0.15\n",
      "alpha = 0.06 beta = 0.16\n",
      "alpha = 0.06 beta = 0.17\n",
      "alpha = 0.06 beta = 0.18\n",
      "alpha = 0.06 beta = 0.19\n",
      "alpha = 0.07 beta = 0.0\n",
      "alpha = 0.07 beta = 0.01\n",
      "alpha = 0.07 beta = 0.02\n",
      "alpha = 0.07 beta = 0.03\n",
      "alpha = 0.07 beta = 0.04\n",
      "alpha = 0.07 beta = 0.05\n",
      "alpha = 0.07 beta = 0.06\n",
      "alpha = 0.07 beta = 0.07\n",
      "alpha = 0.07 beta = 0.08\n",
      "alpha = 0.07 beta = 0.09\n",
      "alpha = 0.07 beta = 0.1\n",
      "alpha = 0.07 beta = 0.11\n",
      "alpha = 0.07 beta = 0.12\n",
      "alpha = 0.07 beta = 0.13\n",
      "alpha = 0.07 beta = 0.14\n",
      "alpha = 0.07 beta = 0.15\n",
      "alpha = 0.07 beta = 0.16\n",
      "alpha = 0.07 beta = 0.17\n",
      "alpha = 0.07 beta = 0.18\n",
      "alpha = 0.07 beta = 0.19\n",
      "alpha = 0.08 beta = 0.0\n",
      "alpha = 0.08 beta = 0.01\n",
      "alpha = 0.08 beta = 0.02\n",
      "alpha = 0.08 beta = 0.03\n",
      "alpha = 0.08 beta = 0.04\n",
      "alpha = 0.08 beta = 0.05\n",
      "alpha = 0.08 beta = 0.06\n",
      "alpha = 0.08 beta = 0.07\n",
      "alpha = 0.08 beta = 0.08\n",
      "alpha = 0.08 beta = 0.09\n",
      "alpha = 0.08 beta = 0.1\n",
      "alpha = 0.08 beta = 0.11\n",
      "alpha = 0.08 beta = 0.12\n",
      "alpha = 0.08 beta = 0.13\n",
      "alpha = 0.08 beta = 0.14\n",
      "alpha = 0.08 beta = 0.15\n",
      "alpha = 0.08 beta = 0.16\n",
      "alpha = 0.08 beta = 0.17\n",
      "alpha = 0.08 beta = 0.18\n",
      "alpha = 0.08 beta = 0.19\n",
      "alpha = 0.09 beta = 0.0\n",
      "alpha = 0.09 beta = 0.01\n",
      "alpha = 0.09 beta = 0.02\n",
      "alpha = 0.09 beta = 0.03\n",
      "alpha = 0.09 beta = 0.04\n",
      "alpha = 0.09 beta = 0.05\n",
      "alpha = 0.09 beta = 0.06\n",
      "alpha = 0.09 beta = 0.07\n",
      "alpha = 0.09 beta = 0.08\n",
      "alpha = 0.09 beta = 0.09\n",
      "alpha = 0.09 beta = 0.1\n",
      "alpha = 0.09 beta = 0.11\n",
      "alpha = 0.09 beta = 0.12\n",
      "alpha = 0.09 beta = 0.13\n",
      "alpha = 0.09 beta = 0.14\n",
      "alpha = 0.09 beta = 0.15\n",
      "alpha = 0.09 beta = 0.16\n",
      "alpha = 0.09 beta = 0.17\n",
      "alpha = 0.09 beta = 0.18\n",
      "alpha = 0.09 beta = 0.19\n",
      "alpha = 0.1 beta = 0.0\n",
      "alpha = 0.1 beta = 0.01\n",
      "alpha = 0.1 beta = 0.02\n",
      "alpha = 0.1 beta = 0.03\n",
      "alpha = 0.1 beta = 0.04\n",
      "alpha = 0.1 beta = 0.05\n",
      "alpha = 0.1 beta = 0.06\n",
      "alpha = 0.1 beta = 0.07\n",
      "alpha = 0.1 beta = 0.08\n",
      "alpha = 0.1 beta = 0.09\n",
      "alpha = 0.1 beta = 0.1\n",
      "alpha = 0.1 beta = 0.11\n",
      "alpha = 0.1 beta = 0.12\n",
      "alpha = 0.1 beta = 0.13\n",
      "alpha = 0.1 beta = 0.14\n",
      "alpha = 0.1 beta = 0.15\n",
      "alpha = 0.1 beta = 0.16\n",
      "alpha = 0.1 beta = 0.17\n",
      "alpha = 0.1 beta = 0.18\n",
      "alpha = 0.1 beta = 0.19\n",
      "alpha = 0.11 beta = 0.0\n",
      "alpha = 0.11 beta = 0.01\n",
      "alpha = 0.11 beta = 0.02\n",
      "alpha = 0.11 beta = 0.03\n",
      "alpha = 0.11 beta = 0.04\n",
      "alpha = 0.11 beta = 0.05\n",
      "alpha = 0.11 beta = 0.06\n",
      "alpha = 0.11 beta = 0.07\n",
      "alpha = 0.11 beta = 0.08\n",
      "alpha = 0.11 beta = 0.09\n",
      "alpha = 0.11 beta = 0.1\n",
      "alpha = 0.11 beta = 0.11\n",
      "alpha = 0.11 beta = 0.12\n",
      "alpha = 0.11 beta = 0.13\n",
      "alpha = 0.11 beta = 0.14\n",
      "alpha = 0.11 beta = 0.15\n",
      "alpha = 0.11 beta = 0.16\n",
      "alpha = 0.11 beta = 0.17\n",
      "alpha = 0.11 beta = 0.18\n",
      "alpha = 0.11 beta = 0.19\n",
      "alpha = 0.12 beta = 0.0\n",
      "alpha = 0.12 beta = 0.01\n",
      "alpha = 0.12 beta = 0.02\n",
      "alpha = 0.12 beta = 0.03\n",
      "alpha = 0.12 beta = 0.04\n",
      "alpha = 0.12 beta = 0.05\n",
      "alpha = 0.12 beta = 0.06\n",
      "alpha = 0.12 beta = 0.07\n",
      "alpha = 0.12 beta = 0.08\n",
      "alpha = 0.12 beta = 0.09\n",
      "alpha = 0.12 beta = 0.1\n",
      "alpha = 0.12 beta = 0.11\n",
      "alpha = 0.12 beta = 0.12\n",
      "alpha = 0.12 beta = 0.13\n",
      "alpha = 0.12 beta = 0.14\n",
      "alpha = 0.12 beta = 0.15\n",
      "alpha = 0.12 beta = 0.16\n",
      "alpha = 0.12 beta = 0.17\n",
      "alpha = 0.12 beta = 0.18\n",
      "alpha = 0.12 beta = 0.19\n",
      "alpha = 0.13 beta = 0.0\n",
      "alpha = 0.13 beta = 0.01\n",
      "alpha = 0.13 beta = 0.02\n",
      "alpha = 0.13 beta = 0.03\n",
      "alpha = 0.13 beta = 0.04\n",
      "alpha = 0.13 beta = 0.05\n",
      "alpha = 0.13 beta = 0.06\n",
      "alpha = 0.13 beta = 0.07\n",
      "alpha = 0.13 beta = 0.08\n",
      "alpha = 0.13 beta = 0.09\n",
      "alpha = 0.13 beta = 0.1\n",
      "alpha = 0.13 beta = 0.11\n",
      "alpha = 0.13 beta = 0.12\n",
      "alpha = 0.13 beta = 0.13\n",
      "alpha = 0.13 beta = 0.14\n",
      "alpha = 0.13 beta = 0.15\n",
      "alpha = 0.13 beta = 0.16\n",
      "alpha = 0.13 beta = 0.17\n",
      "alpha = 0.13 beta = 0.18\n",
      "alpha = 0.13 beta = 0.19\n",
      "alpha = 0.14 beta = 0.0\n",
      "alpha = 0.14 beta = 0.01\n",
      "alpha = 0.14 beta = 0.02\n",
      "alpha = 0.14 beta = 0.03\n",
      "alpha = 0.14 beta = 0.04\n",
      "alpha = 0.14 beta = 0.05\n",
      "alpha = 0.14 beta = 0.06\n",
      "alpha = 0.14 beta = 0.07\n",
      "alpha = 0.14 beta = 0.08\n",
      "alpha = 0.14 beta = 0.09\n",
      "alpha = 0.14 beta = 0.1\n",
      "alpha = 0.14 beta = 0.11\n",
      "alpha = 0.14 beta = 0.12\n",
      "alpha = 0.14 beta = 0.13\n",
      "alpha = 0.14 beta = 0.14\n",
      "alpha = 0.14 beta = 0.15\n",
      "alpha = 0.14 beta = 0.16\n",
      "alpha = 0.14 beta = 0.17\n",
      "alpha = 0.14 beta = 0.18\n",
      "alpha = 0.14 beta = 0.19\n",
      "alpha = 0.15 beta = 0.0\n",
      "alpha = 0.15 beta = 0.01\n",
      "alpha = 0.15 beta = 0.02\n",
      "alpha = 0.15 beta = 0.03\n",
      "alpha = 0.15 beta = 0.04\n",
      "alpha = 0.15 beta = 0.05\n",
      "alpha = 0.15 beta = 0.06\n",
      "alpha = 0.15 beta = 0.07\n",
      "alpha = 0.15 beta = 0.08\n",
      "alpha = 0.15 beta = 0.09\n",
      "alpha = 0.15 beta = 0.1\n",
      "alpha = 0.15 beta = 0.11\n",
      "alpha = 0.15 beta = 0.12\n",
      "alpha = 0.15 beta = 0.13\n",
      "alpha = 0.15 beta = 0.14\n",
      "alpha = 0.15 beta = 0.15\n",
      "alpha = 0.15 beta = 0.16\n",
      "alpha = 0.15 beta = 0.17\n",
      "alpha = 0.15 beta = 0.18\n",
      "alpha = 0.15 beta = 0.19\n",
      "alpha = 0.16 beta = 0.0\n",
      "alpha = 0.16 beta = 0.01\n",
      "alpha = 0.16 beta = 0.02\n",
      "alpha = 0.16 beta = 0.03\n",
      "alpha = 0.16 beta = 0.04\n",
      "alpha = 0.16 beta = 0.05\n",
      "alpha = 0.16 beta = 0.06\n",
      "alpha = 0.16 beta = 0.07\n",
      "alpha = 0.16 beta = 0.08\n",
      "alpha = 0.16 beta = 0.09\n",
      "alpha = 0.16 beta = 0.1\n",
      "alpha = 0.16 beta = 0.11\n",
      "alpha = 0.16 beta = 0.12\n",
      "alpha = 0.16 beta = 0.13\n",
      "alpha = 0.16 beta = 0.14\n",
      "alpha = 0.16 beta = 0.15\n",
      "alpha = 0.16 beta = 0.16\n",
      "alpha = 0.16 beta = 0.17\n",
      "alpha = 0.16 beta = 0.18\n",
      "alpha = 0.16 beta = 0.19\n",
      "alpha = 0.17 beta = 0.0\n",
      "alpha = 0.17 beta = 0.01\n",
      "alpha = 0.17 beta = 0.02\n",
      "alpha = 0.17 beta = 0.03\n",
      "alpha = 0.17 beta = 0.04\n",
      "alpha = 0.17 beta = 0.05\n",
      "alpha = 0.17 beta = 0.06\n",
      "alpha = 0.17 beta = 0.07\n",
      "alpha = 0.17 beta = 0.08\n",
      "alpha = 0.17 beta = 0.09\n",
      "alpha = 0.17 beta = 0.1\n",
      "alpha = 0.17 beta = 0.11\n",
      "alpha = 0.17 beta = 0.12\n",
      "alpha = 0.17 beta = 0.13\n",
      "alpha = 0.17 beta = 0.14\n",
      "alpha = 0.17 beta = 0.15\n",
      "alpha = 0.17 beta = 0.16\n",
      "alpha = 0.17 beta = 0.17\n",
      "alpha = 0.17 beta = 0.18\n",
      "alpha = 0.17 beta = 0.19\n",
      "alpha = 0.18 beta = 0.0\n",
      "alpha = 0.18 beta = 0.01\n",
      "alpha = 0.18 beta = 0.02\n",
      "alpha = 0.18 beta = 0.03\n",
      "alpha = 0.18 beta = 0.04\n",
      "alpha = 0.18 beta = 0.05\n",
      "alpha = 0.18 beta = 0.06\n",
      "alpha = 0.18 beta = 0.07\n",
      "alpha = 0.18 beta = 0.08\n",
      "alpha = 0.18 beta = 0.09\n",
      "alpha = 0.18 beta = 0.1\n",
      "alpha = 0.18 beta = 0.11\n",
      "alpha = 0.18 beta = 0.12\n",
      "alpha = 0.18 beta = 0.13\n",
      "alpha = 0.18 beta = 0.14\n",
      "alpha = 0.18 beta = 0.15\n",
      "alpha = 0.18 beta = 0.16\n",
      "alpha = 0.18 beta = 0.17\n",
      "alpha = 0.18 beta = 0.18\n",
      "alpha = 0.18 beta = 0.19\n",
      "alpha = 0.19 beta = 0.0\n",
      "alpha = 0.19 beta = 0.01\n",
      "alpha = 0.19 beta = 0.02\n",
      "alpha = 0.19 beta = 0.03\n",
      "alpha = 0.19 beta = 0.04\n",
      "alpha = 0.19 beta = 0.05\n",
      "alpha = 0.19 beta = 0.06\n",
      "alpha = 0.19 beta = 0.07\n",
      "alpha = 0.19 beta = 0.08\n",
      "alpha = 0.19 beta = 0.09\n",
      "alpha = 0.19 beta = 0.1\n",
      "alpha = 0.19 beta = 0.11\n",
      "alpha = 0.19 beta = 0.12\n",
      "alpha = 0.19 beta = 0.13\n",
      "alpha = 0.19 beta = 0.14\n",
      "alpha = 0.19 beta = 0.15\n",
      "alpha = 0.19 beta = 0.16\n",
      "alpha = 0.19 beta = 0.17\n",
      "alpha = 0.19 beta = 0.18\n",
      "alpha = 0.19 beta = 0.19\n"
     ]
    }
   ],
   "source": [
    "exp_rmses = np.zeros((10, len(np.arange(0, 0.2, .01)), len(np.arange(0, 0.2, .01))))\n",
    "\n",
    "i = 0\n",
    "for train_index, test_index in cv.split(tv_train):\n",
    "    tv_tt = tv_train.iloc[train_index]\n",
    "    tv_ho = tv_train.iloc[test_index]\n",
    "    \n",
    "    j = 0\n",
    "    for alpha in np.arange(0, 0.2, .01):\n",
    "        k = 0\n",
    "        for beta in np.arange(0, 0.2, .01):\n",
    "            print(\"alpha =\", alpha,\n",
    "                     \"beta =\", beta)\n",
    "\n",
    "            exp_smooth = Holt(tv_tt.imdb_rating.values).fit(smoothing_level=alpha, \n",
    "                                                                      smoothing_trend=beta,\n",
    "                                                                      optimized=False)\n",
    "\n",
    "            exp_rmses[i,j,k] = np.sqrt(mean_squared_error(tv_ho.imdb_rating.values, \n",
    "                                                          exp_smooth.forecast(len(tv_ho))))\n",
    "            k = k + 1\n",
    "        j = j + 1\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db9ff6a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 14)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## This gives us the indices of the smallest\n",
    "## avg cv rmse\n",
    "exp_ind = np.unravel_index(np.argmin(np.mean(exp_rmses, axis=0), axis=None), \n",
    "                           np.mean(exp_rmses, axis=0).shape)\n",
    "np.unravel_index(np.argmin(np.mean(exp_rmses, axis=0), axis=None), \n",
    "                 np.mean(exp_rmses, axis=0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2a3c5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The alpha and beta values that give a double exponential smoothing model with lowest avg cv rmse are alpha =  0.01 and beta =  0.14\n",
      "This model had an avg cv rmse of 0.453\n"
     ]
    }
   ],
   "source": [
    "print(\"The alpha and beta values that give a double exponential\",\n",
    "         \"smoothing model with lowest avg cv rmse are\",\n",
    "         \"alpha = \", np.arange(0, 0.2, .01)[exp_ind[0]],\n",
    "         \"and beta = \", np.arange(0, 0.2, .01)[exp_ind[1]])\n",
    "\n",
    "print(\"This model had an avg cv rmse of\",\n",
    "         np.round(np.mean(exp_rmses, axis=0)[exp_ind],3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3460aa8e",
   "metadata": {},
   "source": [
    "##### e.\n",
    "\n",
    "The final model you will try is an ARIMA model. \n",
    "\n",
    "First let's check the stationarity assumption for this time series. Make an autocorrelation plot of the training data. If you find that the ACF plot indicates that the time series is non-stationary, plot the ACF of the time series' first differences. Do these appear to be stationary?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa393f86",
   "metadata": {},
   "source": [
    "##### Sample Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30094ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89bf6854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(7,5))\n",
    "\n",
    "sm.graphics.tsa.plot_acf(tv_train.imdb_rating.values,\n",
    "                            alpha=None,\n",
    "                            lags = 40,\n",
    "                            ax = ax)\n",
    "\n",
    "plt.title('The Bachelorette IMDB rating ACF', fontsize=14)\n",
    "plt.ylabel(\"Autocorrelation\", fontsize=12)\n",
    "plt.xlabel(\"Lag\", fontsize=12)\n",
    "\n",
    "plt.ylim(-1.1,1.1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25154d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8,5))\n",
    "\n",
    "sm.graphics.tsa.plot_acf(tv_train.imdb_rating.diff().values[1:],\n",
    "                               alpha=None,\n",
    "                               lags=40,\n",
    "                               ax=ax)\n",
    "\n",
    "plt.title('The Bachelorette First Differences ACF', fontsize=14)\n",
    "plt.ylabel(\"Autocorrelation\", fontsize=12)\n",
    "plt.xlabel(\"Lag\", fontsize=12)\n",
    "\n",
    "plt.ylim(-1.1,1.1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175ae751",
   "metadata": {},
   "source": [
    "##### f.\n",
    "\n",
    "From what we saw above what we should set our $d$ value in the ARIMA model?. Set $d$ to this value and then perform hyperparameter tuning to find the values of $p$ and $q$ that give us the lowest mean CV RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7b5cec",
   "metadata": {},
   "source": [
    "##### Sample Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c62854f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.api import SARIMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "985d0404",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/erdos_sp_2024/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/erdos_sp_2024/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.01600D+00    |proj g|=  7.99934D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      2      6      1     0     0   2.446D-05   1.016D+00\n",
      "  F =   1.0159914027673631     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.25811D-01    |proj g|=  4.66441D-02\n",
      "\n",
      "At iterate    5    f=  9.22903D-01    |proj g|=  1.29666D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      6      9      1     0     0   8.571D-08   9.229D-01\n",
      "  F =  0.92290254585914355     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.25180D-01    |proj g|=  8.92337D-02\n",
      "\n",
      "At iterate    5    f=  9.18108D-01    |proj g|=  3.50774D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      8     11      1     0     0   1.037D-06   9.181D-01\n",
      "  F =  0.91810636987352523     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.01332D-01    |proj g|=  1.56611D-02\n",
      "\n",
      "At iterate    5    f=  9.00770D-01    |proj g|=  2.92696D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4      9     12      1     0     0   6.309D-06   9.008D-01\n",
      "  F =  0.90076206673633596     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.41817D-01    |proj g|=  8.62502D-03\n",
      "\n",
      "At iterate    5    f=  9.41808D-01    |proj g|=  1.24099D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      5      7      1     0     0   1.241D-06   9.418D-01\n",
      "  F =  0.94180785574852499     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.28813D-01    |proj g|=  4.28321D-02\n",
      "\n",
      "At iterate    5    f=  9.15963D-01    |proj g|=  1.08656D-01\n",
      "\n",
      "At iterate   10    f=  9.13439D-01    |proj g|=  6.46966D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     12     15      1     0     0   7.469D-06   9.134D-01\n",
      "  F =  0.91342959583845695     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.25033D-01    |proj g|=  7.82154D-02\n",
      "\n",
      "At iterate    5    f=  9.19476D-01    |proj g|=  9.59870D-03\n",
      "\n",
      "At iterate   10    f=  9.08483D-01    |proj g|=  2.41086D-02\n",
      "\n",
      "At iterate   15    f=  9.07285D-01    |proj g|=  1.90985D-02\n",
      "\n",
      "At iterate   20    f=  9.07127D-01    |proj g|=  1.03827D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4     21     26      1     0     0   7.025D-05   9.071D-01\n",
      "  F =  0.90712719903324379     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.01366D-01    |proj g|=  1.65944D-02\n",
      "\n",
      "At iterate    5    f=  9.00854D-01    |proj g|=  2.64704D-03\n",
      "\n",
      "At iterate   10    f=  9.00576D-01    |proj g|=  4.15619D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     13     17      1     0     0   5.648D-06   9.006D-01\n",
      "  F =  0.90057620612169964     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.36953D-01    |proj g|=  1.86593D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      3      5      1     0     0   3.861D-06   9.370D-01\n",
      "  F =  0.93695099935701032     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.02384D+00    |proj g|=  4.41111D-01\n",
      "\n",
      "At iterate    5    f=  9.32349D-01    |proj g|=  2.23099D-02\n",
      "\n",
      "At iterate   10    f=  9.09958D-01    |proj g|=  3.72188D-02\n",
      "\n",
      "At iterate   15    f=  9.04676D-01    |proj g|=  5.75984D-03\n",
      "\n",
      "At iterate   20    f=  9.04652D-01    |proj g|=  5.38506D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4     20     24      1     0     0   5.385D-06   9.047D-01\n",
      "  F =  0.90465189157771908     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.09460D-01    |proj g|=  8.03715D-02\n",
      "\n",
      "At iterate    5    f=  9.05630D-01    |proj g|=  1.30911D-02\n",
      "\n",
      "At iterate   10    f=  9.04738D-01    |proj g|=  3.59294D-03\n",
      "\n",
      "At iterate   15    f=  9.03873D-01    |proj g|=  8.38716D-03\n",
      "\n",
      "At iterate   20    f=  9.03650D-01    |proj g|=  1.70433D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     22     26      1     0     0   3.439D-06   9.037D-01\n",
      "  F =  0.90365026355274469     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            6     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.10450D-01    |proj g|=  2.05959D-01\n",
      "\n",
      "At iterate    5    f=  9.05480D-01    |proj g|=  7.43610D-03\n",
      "\n",
      "At iterate   10    f=  8.99646D-01    |proj g|=  3.71724D-02\n",
      "\n",
      "At iterate   15    f=  8.98835D-01    |proj g|=  2.82434D-03\n",
      "\n",
      "At iterate   20    f=  8.98818D-01    |proj g|=  8.92322D-03\n",
      "\n",
      "At iterate   25    f=  8.97780D-01    |proj g|=  3.38400D-02\n",
      "\n",
      "At iterate   30    f=  8.97030D-01    |proj g|=  2.54113D-03\n",
      "\n",
      "At iterate   35    f=  8.97010D-01    |proj g|=  9.81310D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    6     37     53      1     0     0   1.874D-05   8.970D-01\n",
      "  F =  0.89701035971488852     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.25725D-01    |proj g|=  7.72420D-03\n",
      "\n",
      "At iterate    5    f=  9.25719D-01    |proj g|=  6.30832D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4      5      7      1     0     0   6.308D-06   9.257D-01\n",
      "  F =  0.92571921042621852     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.19396D-01    |proj g|=  3.77669D-02\n",
      "\n",
      "At iterate    5    f=  9.15414D-01    |proj g|=  4.08754D-02\n",
      "\n",
      "At iterate   10    f=  9.04238D-01    |proj g|=  8.20983D-03\n",
      "\n",
      "At iterate   15    f=  9.03349D-01    |proj g|=  3.59194D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     19     23      1     0     0   2.095D-05   9.033D-01\n",
      "  F =  0.90332758858942153     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            6     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.10564D-01    |proj g|=  7.13473D-02\n",
      "\n",
      "At iterate    5    f=  9.07212D-01    |proj g|=  1.99094D-02\n",
      "\n",
      "At iterate   10    f=  9.03782D-01    |proj g|=  4.10015D-03\n",
      "\n",
      "At iterate   15    f=  9.03674D-01    |proj g|=  6.10612D-03\n",
      "\n",
      "At iterate   20    f=  9.03354D-01    |proj g|=  3.56746D-03\n",
      "\n",
      "At iterate   25    f=  9.03319D-01    |proj g|=  1.21331D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    6     27     31      1     0     0   7.445D-06   9.033D-01\n",
      "  F =  0.90331929791782739     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            7     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.36698D+00    |proj g|=  1.59172D+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/erdos_sp_2024/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate    5    f=  9.38427D-01    |proj g|=  8.34422D-02\n",
      "\n",
      "At iterate   10    f=  9.16847D-01    |proj g|=  4.29442D-02\n",
      "\n",
      "At iterate   15    f=  9.01987D-01    |proj g|=  2.54280D-01\n",
      "\n",
      "At iterate   20    f=  8.98362D-01    |proj g|=  4.59209D-02\n",
      "\n",
      "At iterate   25    f=  8.95527D-01    |proj g|=  1.20369D-01\n",
      "\n",
      "At iterate   30    f=  8.89529D-01    |proj g|=  2.13881D-02\n",
      "\n",
      "At iterate   35    f=  8.88859D-01    |proj g|=  2.34672D-03\n",
      "\n",
      "At iterate   40    f=  8.88752D-01    |proj g|=  9.16374D-03\n",
      "\n",
      "At iterate   45    f=  8.87980D-01    |proj g|=  3.62370D-03\n",
      "\n",
      "At iterate   50    f=  8.87765D-01    |proj g|=  2.25307D-02\n",
      "\n",
      "At iterate   55    f=  8.87744D-01    |proj g|=  1.15392D-03\n",
      "\n",
      "At iterate   60    f=  8.87743D-01    |proj g|=  5.10426D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    7     62    100      2     0     0   1.114D-04   8.877D-01\n",
      "  F =  0.88774323573870506     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Bad direction in the line search;\n",
      "   refresh the lbfgs memory and restart the iteration.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/erdos_sp_2024/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/erdos_sp_2024/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.02229D+00    |proj g|=  7.82271D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      2      6      1     0     0   2.437D-05   1.022D+00\n",
      "  F =   1.0222790961164308     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.32935D-01    |proj g|=  4.80571D-02\n",
      "\n",
      "At iterate    5    f=  9.29797D-01    |proj g|=  1.09477D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      6     12      1     0     0   3.083D-07   9.298D-01\n",
      "  F =  0.92979718965416103     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.31117D-01    |proj g|=  8.70604D-02\n",
      "\n",
      "At iterate    5    f=  9.23774D-01    |proj g|=  4.75715D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      8     11      1     0     0   3.448D-07   9.238D-01\n",
      "  F =  0.92377076537228198     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.06242D-01    |proj g|=  2.06563D-02\n",
      "\n",
      "At iterate    5    f=  9.05150D-01    |proj g|=  7.71545D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4      8     12      1     0     0   6.255D-07   9.052D-01\n",
      "  F =  0.90515006551139876     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.49783D-01    |proj g|=  8.42149D-03\n",
      "\n",
      "At iterate    5    f=  9.49774D-01    |proj g|=  8.70748D-07\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      5      7      1     0     0   8.707D-07   9.498D-01\n",
      "  F =  0.94977391031083669     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.35125D-01    |proj g|=  4.55336D-02\n",
      "\n",
      "At iterate    5    f=  9.19143D-01    |proj g|=  1.13945D-01\n",
      "\n",
      "At iterate   10    f=  9.16983D-01    |proj g|=  7.56750D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     11     14      1     0     0   2.127D-06   9.170D-01\n",
      "  F =  0.91698289455615323     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.31121D-01    |proj g|=  8.58821D-02\n",
      "\n",
      "At iterate    5    f=  9.24285D-01    |proj g|=  1.18056D-02\n",
      "\n",
      "At iterate   10    f=  9.10976D-01    |proj g|=  1.43680D-02\n",
      "\n",
      "At iterate   15    f=  9.09632D-01    |proj g|=  2.11371D-03\n",
      "\n",
      "At iterate   20    f=  9.09569D-01    |proj g|=  4.07627D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4     20     25      1     0     0   4.076D-06   9.096D-01\n",
      "  F =  0.90956891703099974     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.06060D-01    |proj g|=  2.13229D-02\n",
      "\n",
      "At iterate    5    f=  9.05197D-01    |proj g|=  3.11955D-03\n",
      "\n",
      "At iterate   10    f=  9.04756D-01    |proj g|=  4.76873D-03\n",
      "\n",
      "At iterate   15    f=  9.04713D-01    |proj g|=  5.21387D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     16     21      1     0     0   6.637D-07   9.047D-01\n",
      "  F =  0.90471336303434047     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.44474D-01    |proj g|=  1.82031D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      3      6      1     0     0   4.711D-06   9.445D-01\n",
      "  F =  0.94447222857277224     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.03013D+00    |proj g|=  4.36429D-01\n",
      "\n",
      "At iterate    5    f=  9.39578D-01    |proj g|=  2.17822D-02\n",
      "\n",
      "At iterate   10    f=  9.14252D-01    |proj g|=  5.10245D-02\n",
      "\n",
      "At iterate   15    f=  9.07534D-01    |proj g|=  1.59321D-02\n",
      "\n",
      "At iterate   20    f=  9.07345D-01    |proj g|=  2.57955D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4     20     23      1     0     0   2.580D-06   9.073D-01\n",
      "  F =  0.90734538864077929     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.12920D-01    |proj g|=  8.45671D-02\n",
      "\n",
      "At iterate    5    f=  9.08400D-01    |proj g|=  1.35372D-02\n",
      "\n",
      "At iterate   10    f=  9.07247D-01    |proj g|=  2.69405D-03\n",
      "\n",
      "At iterate   15    f=  9.06561D-01    |proj g|=  7.96100D-03\n",
      "\n",
      "At iterate   20    f=  9.06369D-01    |proj g|=  2.46393D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     23     27      1     0     0   2.519D-06   9.064D-01\n",
      "  F =  0.90636863181932392     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/erdos_sp_2024/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            6     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.16279D-01    |proj g|=  2.08464D-01\n",
      "\n",
      "At iterate    5    f=  9.07806D-01    |proj g|=  3.54992D-02\n",
      "\n",
      "At iterate   10    f=  9.06770D-01    |proj g|=  3.72830D-03\n",
      "\n",
      "At iterate   15    f=  9.05207D-01    |proj g|=  5.35232D-02\n",
      "\n",
      "At iterate   20    f=  9.03636D-01    |proj g|=  1.80216D-03\n",
      "\n",
      "At iterate   25    f=  9.03607D-01    |proj g|=  2.38446D-03\n",
      "\n",
      "At iterate   30    f=  9.03599D-01    |proj g|=  2.59644D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    6     30     36      1     0     0   2.596D-05   9.036D-01\n",
      "  F =  0.90359894702486576     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.32006D-01    |proj g|=  7.83070D-03\n",
      "\n",
      "At iterate    5    f=  9.32000D-01    |proj g|=  5.00264D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4      5      7      1     0     0   5.003D-06   9.320D-01\n",
      "  F =  0.93199979522652909     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.25626D-01    |proj g|=  3.82470D-02\n",
      "\n",
      "At iterate    5    f=  9.21647D-01    |proj g|=  4.05425D-02\n",
      "\n",
      "At iterate   10    f=  9.08044D-01    |proj g|=  1.48910D-02\n",
      "\n",
      "At iterate   15    f=  9.06245D-01    |proj g|=  2.09626D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     18     21      1     0     0   5.244D-06   9.062D-01\n",
      "  F =  0.90624264403711774     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            6     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.15153D-01    |proj g|=  7.06836D-02\n",
      "\n",
      "At iterate    5    f=  9.11492D-01    |proj g|=  2.47127D-02\n",
      "\n",
      "At iterate   10    f=  9.06502D-01    |proj g|=  1.72926D-03\n",
      "\n",
      "At iterate   15    f=  9.06482D-01    |proj g|=  2.33316D-03\n",
      "\n",
      "At iterate   20    f=  9.06213D-01    |proj g|=  6.45052D-03\n",
      "\n",
      "At iterate   25    f=  9.06193D-01    |proj g|=  3.19187D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    6     26     31      1     0     0   4.494D-06   9.062D-01\n",
      "  F =  0.90619252983726928     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            7     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.34872D+00    |proj g|=  1.49177D+00\n",
      "\n",
      "At iterate    5    f=  9.20216D-01    |proj g|=  6.27713D-02\n",
      "\n",
      "At iterate   10    f=  8.98416D-01    |proj g|=  1.12052D-01\n",
      "\n",
      "At iterate   15    f=  8.95805D-01    |proj g|=  3.54741D-02\n",
      "\n",
      "At iterate   20    f=  8.95276D-01    |proj g|=  3.41821D-02\n",
      "\n",
      "At iterate   25    f=  8.94510D-01    |proj g|=  1.80246D-02\n",
      "\n",
      "At iterate   30    f=  8.94497D-01    |proj g|=  1.63137D-03\n",
      "\n",
      "At iterate   35    f=  8.94398D-01    |proj g|=  5.53981D-03\n",
      "\n",
      "At iterate   40    f=  8.94354D-01    |proj g|=  1.03933D-02\n",
      "\n",
      "At iterate   45    f=  8.94351D-01    |proj g|=  7.14396D-04\n",
      "\n",
      "At iterate   50    f=  8.94351D-01    |proj g|=  8.99437D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    7     50     67      1     0     0   8.994D-05   8.944D-01\n",
      "  F =  0.89435053112735907     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.01525D+00    |proj g|=  7.75496D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      2      6      1     0     0   2.474D-05   1.015D+00\n",
      "  F =   1.0152411263307171     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.26882D-01    |proj g|=  4.96973D-02\n",
      "\n",
      "At iterate    5    f=  9.23482D-01    |proj g|=  9.69715D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      6      9      1     0     0   1.184D-06   9.235D-01\n",
      "  F =  0.92348246060907180     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.24750D-01    |proj g|=  9.04203D-02\n",
      "\n",
      "At iterate    5    f=  9.16926D-01    |proj g|=  3.84935D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      8     11      1     0     0   4.583D-07   9.169D-01\n",
      "  F =  0.91692354662989983     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.98890D-01    |proj g|=  1.90237D-02\n",
      "\n",
      "At iterate    5    f=  8.97894D-01    |proj g|=  7.66616D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4      9     12      1     0     0   7.073D-07   8.979D-01\n",
      "  F =  0.89788714823707227     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.43418D-01    |proj g|=  8.34467D-03\n",
      "\n",
      "At iterate    5    f=  9.43409D-01    |proj g|=  9.54836D-07\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      5      7      1     0     0   9.548D-07   9.434D-01\n",
      "  F =  0.94340899567076753     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.29280D-01    |proj g|=  4.64344D-02\n",
      "\n",
      "At iterate    5    f=  9.11819D-01    |proj g|=  1.24648D-01\n",
      "\n",
      "At iterate   10    f=  9.09985D-01    |proj g|=  4.18797D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     13     16      1     0     0   1.758D-06   9.100D-01\n",
      "  F =  0.90998025423029161     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.24745D-01    |proj g|=  9.11791D-02\n",
      "\n",
      "At iterate    5    f=  9.17217D-01    |proj g|=  1.22293D-02\n",
      "\n",
      "At iterate   10    f=  9.04451D-01    |proj g|=  1.09854D-02\n",
      "\n",
      "At iterate   15    f=  9.03725D-01    |proj g|=  3.81004D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4     19     24      1     0     0   1.688D-06   9.037D-01\n",
      "  F =  0.90371097326416050     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.98581D-01    |proj g|=  1.96252D-02\n",
      "\n",
      "At iterate    5    f=  8.97828D-01    |proj g|=  2.81503D-03\n",
      "\n",
      "At iterate   10    f=  8.97486D-01    |proj g|=  2.34039D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     14     17      1     0     0   6.817D-06   8.975D-01\n",
      "  F =  0.89748138006725053     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.38477D-01    |proj g|=  1.78503D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      3      5      1     0     0   3.224D-06   9.385D-01\n",
      "  F =  0.93847556270279586     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.02298D+00    |proj g|=  4.34054D-01\n",
      "\n",
      "At iterate    5    f=  9.33610D-01    |proj g|=  2.21906D-02\n",
      "\n",
      "At iterate   10    f=  9.09890D-01    |proj g|=  4.58155D-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/erdos_sp_2024/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/erdos_sp_2024/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   15    f=  9.01364D-01    |proj g|=  1.03425D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4     19     22      1     0     0   7.960D-07   9.013D-01\n",
      "  F =  0.90134744094604591     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.05463D-01    |proj g|=  8.53067D-02\n",
      "\n",
      "At iterate    5    f=  9.01440D-01    |proj g|=  1.15345D-02\n",
      "\n",
      "At iterate   10    f=  9.00514D-01    |proj g|=  2.87196D-03\n",
      "\n",
      "At iterate   15    f=  9.00074D-01    |proj g|=  7.16174D-03\n",
      "\n",
      "At iterate   20    f=  9.00043D-01    |proj g|=  2.27764D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     21     26      1     0     0   1.789D-05   9.000D-01\n",
      "  F =  0.90004300604240628     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            6     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.05139D-01    |proj g|=  1.59129D-01\n",
      "\n",
      "At iterate    5    f=  9.00689D-01    |proj g|=  6.16950D-02\n",
      "\n",
      "At iterate   10    f=  8.99112D-01    |proj g|=  8.48303D-03\n",
      "\n",
      "At iterate   15    f=  8.98902D-01    |proj g|=  1.02517D-02\n",
      "\n",
      "At iterate   20    f=  8.96759D-01    |proj g|=  1.83046D-02\n",
      "\n",
      "At iterate   25    f=  8.96191D-01    |proj g|=  2.49958D-03\n",
      "\n",
      "At iterate   30    f=  8.96181D-01    |proj g|=  9.42758D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    6     33     42      1     0     0   3.247D-05   8.962D-01\n",
      "  F =  0.89618047074112195     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.25697D-01    |proj g|=  7.50371D-03\n",
      "\n",
      "At iterate    5    f=  9.25691D-01    |proj g|=  5.89234D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4      5      7      1     0     0   5.892D-06   9.257D-01\n",
      "  F =  0.92569088829038193     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.19097D-01    |proj g|=  3.98040D-02\n",
      "\n",
      "At iterate    5    f=  9.14670D-01    |proj g|=  4.46629D-02\n",
      "\n",
      "At iterate   10    f=  9.00908D-01    |proj g|=  1.19975D-02\n",
      "\n",
      "At iterate   15    f=  8.99629D-01    |proj g|=  1.47036D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     18     22      1     0     0   5.666D-06   8.996D-01\n",
      "  F =  0.89962720368262294     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            6     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.07471D-01    |proj g|=  7.17471D-02\n",
      "\n",
      "At iterate    5    f=  9.03861D-01    |proj g|=  2.29519D-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/erdos_sp_2024/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   10    f=  8.99975D-01    |proj g|=  8.03308D-04\n",
      "\n",
      "At iterate   15    f=  8.99710D-01    |proj g|=  2.48349D-02\n",
      "\n",
      "At iterate   20    f=  8.99607D-01    |proj g|=  4.95600D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    6     21     25      1     0     0   2.243D-05   8.996D-01\n",
      "  F =  0.89960698801432759     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            7     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.32576D+00    |proj g|=  1.45675D+00\n",
      "\n",
      "At iterate    5    f=  9.07661D-01    |proj g|=  8.16914D-02\n",
      "\n",
      "At iterate   10    f=  8.89536D-01    |proj g|=  2.85205D-02\n",
      "\n",
      "At iterate   15    f=  8.88593D-01    |proj g|=  3.90268D-03\n",
      "\n",
      "At iterate   20    f=  8.88379D-01    |proj g|=  1.36195D-02\n",
      "\n",
      "At iterate   25    f=  8.88332D-01    |proj g|=  6.94844D-03\n",
      "\n",
      "At iterate   30    f=  8.88031D-01    |proj g|=  9.36277D-03\n",
      "\n",
      "At iterate   35    f=  8.87799D-01    |proj g|=  2.69295D-02\n",
      "\n",
      "At iterate   40    f=  8.87619D-01    |proj g|=  1.22438D-02\n",
      "\n",
      "At iterate   45    f=  8.87605D-01    |proj g|=  7.69126D-04\n",
      "\n",
      "At iterate   50    f=  8.87599D-01    |proj g|=  1.11053D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    7     52     73      1     0     0   7.178D-04   8.876D-01\n",
      "  F =  0.88759890853066670     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.01934D+00    |proj g|=  7.60456D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      2      6      1     0     0   2.452D-05   1.019D+00\n",
      "  F =   1.0193318385490540     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.26947D-01    |proj g|=  4.91582D-02\n",
      "\n",
      "At iterate    5    f=  9.23556D-01    |proj g|=  2.18204D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      6      9      1     0     0   8.582D-08   9.236D-01\n",
      "  F =  0.92355553134647972     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.25646D-01    |proj g|=  9.02040D-02\n",
      "\n",
      "At iterate    5    f=  9.17813D-01    |proj g|=  4.43811D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      8     11      1     0     0   1.419D-07   9.178D-01\n",
      "  F =  0.91780942740475202     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.99319D-01    |proj g|=  1.68543D-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/erdos_sp_2024/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/erdos_sp_2024/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate    5    f=  8.98497D-01    |proj g|=  3.18293D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4      9     13      1     0     0   9.217D-06   8.985D-01\n",
      "  F =  0.89849106248385613     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.43643D-01    |proj g|=  8.21593D-03\n",
      "\n",
      "At iterate    5    f=  9.43634D-01    |proj g|=  1.31750D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      5      7      1     0     0   1.318D-06   9.436D-01\n",
      "  F =  0.94363380127337249     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.30270D-01    |proj g|=  4.46051D-02\n",
      "\n",
      "At iterate    5    f=  9.13493D-01    |proj g|=  1.28049D-01\n",
      "\n",
      "At iterate   10    f=  9.11616D-01    |proj g|=  3.55504D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     12     15      1     0     0   4.496D-06   9.116D-01\n",
      "  F =  0.91161617542438500     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.25571D-01    |proj g|=  7.94806D-02\n",
      "\n",
      "At iterate    5    f=  9.19443D-01    |proj g|=  1.07617D-02\n",
      "\n",
      "At iterate   10    f=  9.06337D-01    |proj g|=  1.51509D-02\n",
      "\n",
      "At iterate   15    f=  9.05455D-01    |proj g|=  2.40185D-02\n",
      "\n",
      "At iterate   20    f=  9.05227D-01    |proj g|=  2.54767D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4     21     25      1     0     0   8.892D-07   9.052D-01\n",
      "  F =  0.90522748322257329     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.99024D-01    |proj g|=  1.76222D-02\n",
      "\n",
      "At iterate    5    f=  8.98419D-01    |proj g|=  2.07166D-03\n",
      "\n",
      "At iterate   10    f=  8.98268D-01    |proj g|=  3.43307D-03\n",
      "\n",
      "At iterate   15    f=  8.98241D-01    |proj g|=  1.81087D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     16     22      1     0     0   1.126D-06   8.982D-01\n",
      "  F =  0.89824080121598648     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.38810D-01    |proj g|=  1.79687D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      3      5      1     0     0   7.262D-06   9.388D-01\n",
      "  F =  0.93880824683779063     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.02774D+00    |proj g|=  4.45789D-01\n",
      "\n",
      "At iterate    5    f=  9.33927D-01    |proj g|=  2.28139D-02\n",
      "\n",
      "At iterate   10    f=  9.20046D-01    |proj g|=  8.88463D-02\n",
      "\n",
      "At iterate   15    f=  9.02464D-01    |proj g|=  7.16990D-03\n",
      "\n",
      "At iterate   20    f=  9.02422D-01    |proj g|=  1.32168D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4     20     24      1     0     0   1.322D-06   9.024D-01\n",
      "  F =  0.90242182131212578     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.06394D-01    |proj g|=  8.34229D-02\n",
      "\n",
      "At iterate    5    f=  9.02480D-01    |proj g|=  1.02089D-02\n",
      "\n",
      "At iterate   10    f=  9.01675D-01    |proj g|=  3.70460D-03\n",
      "\n",
      "At iterate   15    f=  9.01040D-01    |proj g|=  3.34973D-03\n",
      "\n",
      "At iterate   20    f=  9.01030D-01    |proj g|=  1.05159D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     20     25      1     0     0   1.052D-05   9.010D-01\n",
      "  F =  0.90102985490976428     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            6     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.04699D-01    |proj g|=  1.10613D-01\n",
      "\n",
      "At iterate    5    f=  9.02029D-01    |proj g|=  4.53348D-02\n",
      "\n",
      "At iterate   10    f=  8.99837D-01    |proj g|=  9.31031D-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   15    f=  8.99252D-01    |proj g|=  3.10364D-02\n",
      "\n",
      "At iterate   20    f=  8.97674D-01    |proj g|=  1.58326D-02\n",
      "\n",
      "At iterate   25    f=  8.97324D-01    |proj g|=  7.62439D-03\n",
      "\n",
      "At iterate   30    f=  8.97295D-01    |proj g|=  7.35921D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    6     30     38      1     0     0   7.359D-05   8.973D-01\n",
      "  F =  0.89729475572253337     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.26391D-01    |proj g|=  7.44686D-03\n",
      "\n",
      "At iterate    5    f=  9.26385D-01    |proj g|=  9.38046D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4      5      7      1     0     0   9.380D-06   9.264D-01\n",
      "  F =  0.92638540872912500     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.19772D-01    |proj g|=  3.94168D-02\n",
      "\n",
      "At iterate    5    f=  9.15423D-01    |proj g|=  4.35472D-02\n",
      "\n",
      "At iterate   10    f=  9.01573D-01    |proj g|=  1.13032D-02\n",
      "\n",
      "At iterate   15    f=  9.00489D-01    |proj g|=  1.39187D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     17     21      1     0     0   2.198D-06   9.005D-01\n",
      "  F =  0.90048874068681106     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            6     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.07993D-01    |proj g|=  7.36998D-02\n",
      "\n",
      "At iterate    5    f=  9.04385D-01    |proj g|=  2.00178D-02\n",
      "\n",
      "At iterate   10    f=  9.01068D-01    |proj g|=  2.13808D-03\n",
      "\n",
      "At iterate   15    f=  9.00946D-01    |proj g|=  8.39797D-03\n",
      "\n",
      "At iterate   20    f=  9.00485D-01    |proj g|=  1.01131D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    6     24     29      1     0     0   2.526D-06   9.005D-01\n",
      "  F =  0.90048349720948928     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            7     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.14392D-01    |proj g|=  6.45865D-01\n",
      "\n",
      "At iterate    5    f=  8.94622D-01    |proj g|=  6.72211D-02\n",
      "\n",
      "At iterate   10    f=  8.92491D-01    |proj g|=  6.72613D-02\n",
      "\n",
      "At iterate   15    f=  8.91203D-01    |proj g|=  1.97385D-02\n",
      "\n",
      "At iterate   20    f=  8.90676D-01    |proj g|=  9.17634D-02\n",
      "\n",
      "At iterate   25    f=  8.90311D-01    |proj g|=  1.93534D-03\n",
      "\n",
      "At iterate   30    f=  8.90163D-01    |proj g|=  2.93858D-02\n",
      "\n",
      "At iterate   35    f=  8.89681D-01    |proj g|=  4.91932D-02\n",
      "\n",
      "At iterate   40    f=  8.89519D-01    |proj g|=  1.86096D-02\n",
      "\n",
      "At iterate   45    f=  8.89407D-01    |proj g|=  3.55875D-03\n",
      "\n",
      "At iterate   50    f=  8.89356D-01    |proj g|=  6.88955D-03\n",
      "\n",
      "At iterate   55    f=  8.89330D-01    |proj g|=  1.38390D-02\n",
      "\n",
      "At iterate   60    f=  8.89304D-01    |proj g|=  9.69867D-03\n",
      "\n",
      "At iterate   65    f=  8.89295D-01    |proj g|=  8.11068D-03\n",
      "\n",
      "At iterate   70    f=  8.89290D-01    |proj g|=  1.63105D-03\n",
      "\n",
      "At iterate   75    f=  8.89288D-01    |proj g|=  4.62909D-03\n",
      "\n",
      "At iterate   80    f=  8.89285D-01    |proj g|=  6.22413D-03\n",
      "\n",
      "At iterate   85    f=  8.89282D-01    |proj g|=  2.15556D-03\n",
      "\n",
      "At iterate   90    f=  8.89281D-01    |proj g|=  1.65665D-03\n",
      "\n",
      "At iterate   95    f=  8.89280D-01    |proj g|=  5.05272D-04\n",
      "\n",
      "At iterate  100    f=  8.89279D-01    |proj g|=  6.26137D-04\n",
      "\n",
      "At iterate  105    f=  8.89279D-01    |proj g|=  5.74674D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    7    109    136      1     0     0   6.219D-04   8.893D-01\n",
      "  F =  0.88927904850547979     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.01734D+00    |proj g|=  7.50444D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      2      6      1     0     0   2.453D-05   1.017D+00\n",
      "  F =   1.0173327155313090     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.22633D-01    |proj g|=  4.86000D-02\n",
      "\n",
      "At iterate    5    f=  9.19263D-01    |proj g|=  2.47808D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      6      9      1     0     0   1.808D-07   9.193D-01\n",
      "  F =  0.91926295884602482     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.22418D-01    |proj g|=  9.48907D-02\n",
      "\n",
      "At iterate    5    f=  9.14059D-01    |proj g|=  5.91954D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      8     25      1     0     0   1.853D-05   9.141D-01\n",
      "  F =  0.91405799674417221     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.93526D-01    |proj g|=  1.61302D-02\n",
      "\n",
      "At iterate    5    f=  8.92749D-01    |proj g|=  3.39041D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4      8     12      1     0     0   6.964D-06   8.927D-01\n",
      "  F =  0.89274296368774164     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.38362D-01    |proj g|=  8.13599D-03\n",
      "\n",
      "At iterate    5    f=  9.38353D-01    |proj g|=  1.61167D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      5      7      1     0     0   1.612D-06   9.384D-01\n",
      "  F =  0.93835299209928869     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.27098D-01    |proj g|=  4.10843D-02\n",
      "\n",
      "At iterate    5    f=  9.13390D-01    |proj g|=  1.58238D-01\n",
      "\n",
      "At iterate   10    f=  9.07842D-01    |proj g|=  9.03918D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     14     17      1     0     0   1.561D-05   9.078D-01\n",
      "  F =  0.90781961698717561     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.22025D-01    |proj g|=  7.69417D-02\n",
      "\n",
      "At iterate    5    f=  9.16289D-01    |proj g|=  9.32255D-03\n",
      "\n",
      "At iterate   10    f=  9.02259D-01    |proj g|=  3.57050D-02\n",
      "\n",
      "At iterate   15    f=  9.00486D-01    |proj g|=  1.47818D-02\n",
      "\n",
      "At iterate   20    f=  9.00373D-01    |proj g|=  1.89360D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4     20     24      1     0     0   1.894D-06   9.004D-01\n",
      "  F =  0.90037303622934883     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.93131D-01    |proj g|=  1.73112D-02\n",
      "\n",
      "At iterate    5    f=  8.92610D-01    |proj g|=  1.56124D-03\n",
      "\n",
      "At iterate   10    f=  8.92527D-01    |proj g|=  2.71133D-03\n",
      "\n",
      "At iterate   15    f=  8.92513D-01    |proj g|=  1.13835D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     16     21      1     0     0   9.254D-06   8.925D-01\n",
      "  F =  0.89251319558465925     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.34249D-01    |proj g|=  1.79557D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      3      5      1     0     0   3.902D-06   9.342D-01\n",
      "  F =  0.93424671399617343     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.02634D+00    |proj g|=  4.59278D-01\n",
      "\n",
      "At iterate    5    f=  9.29568D-01    |proj g|=  2.32806D-02\n",
      "\n",
      "At iterate   10    f=  9.12575D-01    |proj g|=  4.22552D-02\n",
      "\n",
      "At iterate   15    f=  8.97220D-01    |proj g|=  7.54101D-03\n",
      "\n",
      "At iterate   20    f=  8.97022D-01    |proj g|=  6.40272D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4     20     23      1     0     0   6.403D-06   8.970D-01\n",
      "  F =  0.89702239737205947     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.00920D-01    |proj g|=  8.42886D-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/erdos_sp_2024/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/erdos_sp_2024/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate    5    f=  8.96952D-01    |proj g|=  1.09174D-02\n",
      "\n",
      "At iterate   10    f=  8.95985D-01    |proj g|=  5.79127D-03\n",
      "\n",
      "At iterate   15    f=  8.95385D-01    |proj g|=  3.16955D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     19     22      1     0     0   2.370D-05   8.954D-01\n",
      "  F =  0.89537907981972276     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            6     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.97996D-01    |proj g|=  8.18751D-02\n",
      "\n",
      "At iterate    5    f=  8.96144D-01    |proj g|=  2.76662D-02\n",
      "\n",
      "At iterate   10    f=  8.94155D-01    |proj g|=  7.35535D-03\n",
      "\n",
      "At iterate   15    f=  8.92302D-01    |proj g|=  2.29821D-02\n",
      "\n",
      "At iterate   20    f=  8.91743D-01    |proj g|=  2.61655D-03\n",
      "\n",
      "At iterate   25    f=  8.91709D-01    |proj g|=  2.27954D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    6     26     32      1     0     0   1.699D-05   8.917D-01\n",
      "  F =  0.89170930185060482     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.21482D-01    |proj g|=  7.20228D-03\n",
      "\n",
      "At iterate    5    f=  9.21476D-01    |proj g|=  1.36364D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4      6      8      1     0     0   2.680D-07   9.215D-01\n",
      "  F =  0.92147647069177152     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.14793D-01    |proj g|=  3.95755D-02\n",
      "\n",
      "At iterate    5    f=  9.10458D-01    |proj g|=  4.36495D-02\n",
      "\n",
      "At iterate   10    f=  8.96206D-01    |proj g|=  1.23607D-02\n",
      "\n",
      "At iterate   15    f=  8.94871D-01    |proj g|=  1.12550D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     18     21      1     0     0   4.729D-06   8.949D-01\n",
      "  F =  0.89486802529057630     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            6     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.02566D-01    |proj g|=  7.35456D-02\n",
      "\n",
      "At iterate    5    f=  8.98960D-01    |proj g|=  2.01805D-02\n",
      "\n",
      "At iterate   10    f=  8.95379D-01    |proj g|=  1.72855D-03\n",
      "\n",
      "At iterate   15    f=  8.95143D-01    |proj g|=  1.14444D-02\n",
      "\n",
      "At iterate   20    f=  8.94850D-01    |proj g|=  1.17038D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    6     23     27      1     0     0   1.302D-05   8.948D-01\n",
      "  F =  0.89484975778050380     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            7     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.93941D-01    |proj g|=  2.59271D-01\n",
      "\n",
      "At iterate    5    f=  8.88178D-01    |proj g|=  1.66222D-02\n",
      "\n",
      "At iterate   10    f=  8.87624D-01    |proj g|=  1.35937D-02\n",
      "\n",
      "At iterate   15    f=  8.87089D-01    |proj g|=  1.32222D-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   20    f=  8.87088D-01    |proj g|=  6.38279D-04\n",
      "\n",
      "At iterate   25    f=  8.87064D-01    |proj g|=  1.68973D-02\n",
      "\n",
      "At iterate   30    f=  8.86777D-01    |proj g|=  4.50204D-02\n",
      "\n",
      "At iterate   35    f=  8.86424D-01    |proj g|=  7.18204D-02\n",
      "\n",
      "At iterate   40    f=  8.85957D-01    |proj g|=  4.84829D-02\n",
      "\n",
      "At iterate   45    f=  8.85694D-01    |proj g|=  2.14870D-02\n",
      "\n",
      "At iterate   50    f=  8.85599D-01    |proj g|=  1.44618D-02\n",
      "\n",
      "At iterate   55    f=  8.85576D-01    |proj g|=  7.13599D-03\n",
      "\n",
      "At iterate   60    f=  8.85400D-01    |proj g|=  1.97115D-02\n",
      "\n",
      "At iterate   65    f=  8.85327D-01    |proj g|=  5.63886D-03\n",
      "\n",
      "At iterate   70    f=  8.85273D-01    |proj g|=  1.97844D-02\n",
      "\n",
      "At iterate   75    f=  8.85243D-01    |proj g|=  1.10756D-02\n",
      "\n",
      "At iterate   80    f=  8.85227D-01    |proj g|=  1.16006D-02\n",
      "\n",
      "At iterate   85    f=  8.85214D-01    |proj g|=  1.74543D-03\n",
      "\n",
      "At iterate   90    f=  8.85207D-01    |proj g|=  5.37956D-03\n",
      "\n",
      "At iterate   95    f=  8.85203D-01    |proj g|=  2.34354D-03\n",
      "\n",
      "At iterate  100    f=  8.85201D-01    |proj g|=  3.44373D-03\n",
      "\n",
      "At iterate  105    f=  8.85200D-01    |proj g|=  1.23276D-03\n",
      "\n",
      "At iterate  110    f=  8.85199D-01    |proj g|=  1.72347D-03\n",
      "\n",
      "At iterate  115    f=  8.85199D-01    |proj g|=  2.13192D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    7    119    144      1     0     0   1.728D-03   8.852D-01\n",
      "  F =  0.88519879121026557     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.01107D+00    |proj g|=  7.43877D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      2      6      1     0     0   2.488D-05   1.011D+00\n",
      "  F =   1.0110611217026697     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.16084D-01    |proj g|=  4.85866D-02\n",
      "\n",
      "At iterate    5    f=  9.12724D-01    |proj g|=  2.46867D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      6      9      1     0     0   1.327D-07   9.127D-01\n",
      "  F =  0.91272400734735171     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.15950D-01    |proj g|=  9.56862D-02\n",
      "\n",
      "At iterate    5    f=  9.07588D-01    |proj g|=  5.17523D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      7     10      1     0     0   9.578D-06   9.076D-01\n",
      "  F =  0.90758759080939522     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.87056D-01    |proj g|=  1.67246D-02\n",
      "\n",
      "At iterate    5    f=  8.86219D-01    |proj g|=  2.80820D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4      8     12      1     0     0   6.005D-06   8.862D-01\n",
      "  F =  0.88621614487117628     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.31764D-01    |proj g|=  8.06931D-03\n",
      "\n",
      "At iterate    5    f=  9.31756D-01    |proj g|=  1.91138D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      5      7      1     0     0   1.911D-06   9.318D-01\n",
      "  F =  0.93175563983032228     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.20643D-01    |proj g|=  4.08655D-02\n",
      "\n",
      "At iterate    5    f=  9.06396D-01    |proj g|=  1.61608D-01\n",
      "\n",
      "At iterate   10    f=  9.01370D-01    |proj g|=  8.21776D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     14     17      1     0     0   1.835D-05   9.013D-01\n",
      "  F =  0.90134881789891719     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.15590D-01    |proj g|=  8.00665D-02\n",
      "\n",
      "At iterate    5    f=  9.09603D-01    |proj g|=  9.13387D-03\n",
      "\n",
      "At iterate   10    f=  8.96906D-01    |proj g|=  4.06035D-02\n",
      "\n",
      "At iterate   15    f=  8.94506D-01    |proj g|=  1.17257D-02\n",
      "\n",
      "At iterate   20    f=  8.93795D-01    |proj g|=  9.11262D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4     22     28      1     0     0   2.380D-06   8.938D-01\n",
      "  F =  0.89379523805669336     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.86628D-01    |proj g|=  1.77176D-02\n",
      "\n",
      "At iterate    5    f=  8.86068D-01    |proj g|=  1.65472D-03\n",
      "\n",
      "At iterate   10    f=  8.85960D-01    |proj g|=  3.66557D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     13     17      1     0     0   1.033D-05   8.860D-01\n",
      "  F =  0.88595999847391271     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/erdos_sp_2024/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/erdos_sp_2024/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.27719D-01    |proj g|=  1.77218D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      4      6      1     0     0   3.486D-06   9.277D-01\n",
      "  F =  0.92771704873796701     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.02017D+00    |proj g|=  4.60444D-01\n",
      "\n",
      "At iterate    5    f=  9.23054D-01    |proj g|=  2.38665D-02\n",
      "\n",
      "At iterate   10    f=  8.99073D-01    |proj g|=  6.41572D-02\n",
      "\n",
      "At iterate   15    f=  8.90644D-01    |proj g|=  7.95962D-03\n",
      "\n",
      "At iterate   20    f=  8.90386D-01    |proj g|=  4.19699D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4     20     24      1     0     0   4.197D-06   8.904D-01\n",
      "  F =  0.89038590039051035     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.93975D-01    |proj g|=  8.41317D-02\n",
      "\n",
      "At iterate    5    f=  8.90097D-01    |proj g|=  1.14851D-02\n",
      "\n",
      "At iterate   10    f=  8.89142D-01    |proj g|=  5.73719D-03\n",
      "\n",
      "At iterate   15    f=  8.88687D-01    |proj g|=  7.62406D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     18     22      1     0     0   6.563D-06   8.887D-01\n",
      "  F =  0.88868539874997154     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            6     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.91416D-01    |proj g|=  8.31466D-02\n",
      "\n",
      "At iterate    5    f=  8.89597D-01    |proj g|=  2.62152D-02\n",
      "\n",
      "At iterate   10    f=  8.87778D-01    |proj g|=  7.27368D-03\n",
      "\n",
      "At iterate   15    f=  8.86469D-01    |proj g|=  2.16362D-02\n",
      "\n",
      "At iterate   20    f=  8.85251D-01    |proj g|=  3.85831D-03\n",
      "\n",
      "At iterate   25    f=  8.85211D-01    |proj g|=  2.39631D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    6     26     31      1     0     0   3.617D-06   8.852D-01\n",
      "  F =  0.88521131978112444     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.14831D-01    |proj g|=  6.90415D-03\n",
      "\n",
      "At iterate    5    f=  9.14826D-01    |proj g|=  1.88818D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4      6      8      1     0     0   7.833D-07   9.148D-01\n",
      "  F =  0.91482608635609197     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.08182D-01    |proj g|=  3.94722D-02\n",
      "\n",
      "At iterate    5    f=  9.03989D-01    |proj g|=  4.26772D-02\n",
      "\n",
      "At iterate   10    f=  8.89534D-01    |proj g|=  1.30629D-02\n",
      "\n",
      "At iterate   15    f=  8.88207D-01    |proj g|=  7.79280D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     18     21      1     0     0   4.524D-06   8.882D-01\n",
      "  F =  0.88820665639588892     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            6     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.95822D-01    |proj g|=  7.19482D-02\n",
      "\n",
      "At iterate    5    f=  8.92273D-01    |proj g|=  2.05408D-02\n",
      "\n",
      "At iterate   10    f=  8.88620D-01    |proj g|=  1.43688D-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   15    f=  8.88444D-01    |proj g|=  6.97481D-03\n",
      "\n",
      "At iterate   20    f=  8.88183D-01    |proj g|=  2.72841D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    6     23     28      1     0     0   6.085D-06   8.882D-01\n",
      "  F =  0.88818282965597184     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            7     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.88825D-01    |proj g|=  2.05840D-01\n",
      "\n",
      "At iterate    5    f=  8.82837D-01    |proj g|=  1.31841D-02\n",
      "\n",
      "At iterate   10    f=  8.82343D-01    |proj g|=  2.45567D-02\n",
      "\n",
      "At iterate   15    f=  8.81858D-01    |proj g|=  6.67972D-04\n",
      "\n",
      "At iterate   20    f=  8.81817D-01    |proj g|=  1.78128D-02\n",
      "\n",
      "At iterate   25    f=  8.81456D-01    |proj g|=  2.26654D-02\n",
      "\n",
      "At iterate   30    f=  8.81110D-01    |proj g|=  1.37518D-02\n",
      "\n",
      "At iterate   35    f=  8.81036D-01    |proj g|=  2.14699D-03\n",
      "\n",
      "At iterate   40    f=  8.81031D-01    |proj g|=  5.67176D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    7     43     52      1     0     0   4.615D-05   8.810D-01\n",
      "  F =  0.88103084450006575     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.00385D+00    |proj g|=  7.38287D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      2      6      1     0     0   2.539D-05   1.004D+00\n",
      "  F =   1.0038389957530633     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.08993D-01    |proj g|=  4.88396D-02\n",
      "\n",
      "At iterate    5    f=  9.05605D-01    |proj g|=  2.58268D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      6      9      1     0     0   2.973D-07   9.056D-01\n",
      "  F =  0.90560516087856402     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.08724D-01    |proj g|=  9.53960D-02\n",
      "\n",
      "At iterate    5    f=  9.00376D-01    |proj g|=  5.24547D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      7     10      1     0     0   1.413D-05   9.004D-01\n",
      "  F =  0.90037555135767366     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.79925D-01    |proj g|=  1.66309D-02\n",
      "\n",
      "At iterate    5    f=  8.79108D-01    |proj g|=  2.23457D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4      8     12      1     0     0   8.483D-07   8.791D-01\n",
      "  F =  0.87910603578818980     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.24762D-01    |proj g|=  8.00823D-03\n",
      "\n",
      "At iterate    5    f=  9.24754D-01    |proj g|=  2.25242D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      5      7      1     0     0   2.252D-06   9.248D-01\n",
      "  F =  0.92475390438879124     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.13491D-01    |proj g|=  4.12859D-02\n",
      "\n",
      "At iterate    5    f=  8.98528D-01    |proj g|=  1.62500D-01\n",
      "\n",
      "At iterate   10    f=  8.94126D-01    |proj g|=  4.84987D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     13     16      1     0     0   8.847D-06   8.941D-01\n",
      "  F =  0.89411735262901448     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.08390D-01    |proj g|=  7.98086D-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/erdos_sp_2024/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/erdos_sp_2024/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate    5    f=  9.02417D-01    |proj g|=  9.12283D-03\n",
      "\n",
      "At iterate   10    f=  8.89979D-01    |proj g|=  9.37138D-02\n",
      "\n",
      "At iterate   15    f=  8.87433D-01    |proj g|=  2.20497D-02\n",
      "\n",
      "At iterate   20    f=  8.86609D-01    |proj g|=  1.55415D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4     22     26      1     0     0   1.473D-05   8.866D-01\n",
      "  F =  0.88660903662161572     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.79511D-01    |proj g|=  1.77636D-02\n",
      "\n",
      "At iterate    5    f=  8.78964D-01    |proj g|=  1.66335D-03\n",
      "\n",
      "At iterate   10    f=  8.78856D-01    |proj g|=  9.17275D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     14     18      1     0     0   8.613D-07   8.789D-01\n",
      "  F =  0.87885516175443390     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.20678D-01    |proj g|=  1.74334D-03\n",
      "\n",
      "At iterate    5    f=  9.20677D-01    |proj g|=  5.02245D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      5      7      1     0     0   5.022D-06   9.207D-01\n",
      "  F =  0.92067653788203663     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.01296D+00    |proj g|=  4.60255D-01\n",
      "\n",
      "At iterate    5    f=  9.16016D-01    |proj g|=  2.45108D-02\n",
      "\n",
      "At iterate   10    f=  8.98184D-01    |proj g|=  8.06982D-02\n",
      "\n",
      "At iterate   15    f=  8.83373D-01    |proj g|=  1.22926D-02\n",
      "\n",
      "At iterate   20    f=  8.83247D-01    |proj g|=  6.72237D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4     20     23      1     0     0   6.722D-06   8.832D-01\n",
      "  F =  0.88324673166706069     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.86826D-01    |proj g|=  8.37884D-02\n",
      "\n",
      "At iterate    5    f=  8.82994D-01    |proj g|=  1.14967D-02\n",
      "\n",
      "At iterate   10    f=  8.82025D-01    |proj g|=  6.00633D-03\n",
      "\n",
      "At iterate   15    f=  8.81560D-01    |proj g|=  5.89543D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     18     22      1     0     0   3.220D-06   8.816D-01\n",
      "  F =  0.88155853443769616     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            6     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.83848D-01    |proj g|=  7.79827D-02\n",
      "\n",
      "At iterate    5    f=  8.82232D-01    |proj g|=  2.59126D-02\n",
      "\n",
      "At iterate   10    f=  8.80475D-01    |proj g|=  6.29992D-03\n",
      "\n",
      "At iterate   15    f=  8.79213D-01    |proj g|=  1.91083D-02\n",
      "\n",
      "At iterate   20    f=  8.78100D-01    |proj g|=  9.01312D-04\n",
      "\n",
      "At iterate   25    f=  8.78092D-01    |proj g|=  5.06616D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    6     26     31      1     0     0   4.100D-05   8.781D-01\n",
      "  F =  0.87809215719202516     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.07723D-01    |proj g|=  6.59431D-03\n",
      "\n",
      "At iterate    5    f=  9.07718D-01    |proj g|=  2.41481D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4      6      8      1     0     0   2.669D-06   9.077D-01\n",
      "  F =  0.90771845881217117     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.01051D-01    |proj g|=  3.96643D-02\n",
      "\n",
      "At iterate    5    f=  8.96896D-01    |proj g|=  4.22306D-02\n",
      "\n",
      "At iterate   10    f=  8.82376D-01    |proj g|=  1.34462D-02\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iterate   15    f=  8.81092D-01    |proj g|=  1.27762D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     18     22      1     0     0   8.019D-06   8.811D-01\n",
      "  F =  0.88109112579719573     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            6     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.88590D-01    |proj g|=  7.19756D-02\n",
      "\n",
      "At iterate    5    f=  8.85092D-01    |proj g|=  1.98408D-02\n",
      "\n",
      "At iterate   10    f=  8.81509D-01    |proj g|=  1.36203D-03\n",
      "\n",
      "At iterate   15    f=  8.81282D-01    |proj g|=  7.93941D-03\n",
      "\n",
      "At iterate   20    f=  8.81065D-01    |proj g|=  2.89848D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    6     23     28      1     0     0   5.211D-06   8.811D-01\n",
      "  F =  0.88106506358039238     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            7     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.81991D-01    |proj g|=  2.14602D-01\n",
      "\n",
      "At iterate    5    f=  8.75917D-01    |proj g|=  8.37166D-03\n",
      "\n",
      "At iterate   10    f=  8.75140D-01    |proj g|=  1.54112D-02\n",
      "\n",
      "At iterate   15    f=  8.75017D-01    |proj g|=  5.30126D-04\n",
      "\n",
      "At iterate   20    f=  8.74966D-01    |proj g|=  1.94981D-02\n",
      "\n",
      "At iterate   25    f=  8.74391D-01    |proj g|=  2.23900D-02\n",
      "\n",
      "At iterate   30    f=  8.74113D-01    |proj g|=  5.53853D-03\n",
      "\n",
      "At iterate   35    f=  8.74025D-01    |proj g|=  1.03809D-03\n",
      "\n",
      "At iterate   40    f=  8.74025D-01    |proj g|=  9.53937D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    7     40     46      1     0     0   9.539D-05   8.740D-01\n",
      "  F =  0.87402458095633395     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.97785D-01    |proj g|=  7.32041D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      2      6      1     0     0   2.526D-05   9.978D-01\n",
      "  F =  0.99777871611443880     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.02621D-01    |proj g|=  4.87243D-02\n",
      "\n",
      "At iterate    5    f=  8.99250D-01    |proj g|=  2.59781D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      6      9      1     0     0   1.790D-07   8.992D-01\n",
      "  F =  0.89924964565110366     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.02353D-01    |proj g|=  9.50682D-02\n",
      "\n",
      "At iterate    5    f=  8.94068D-01    |proj g|=  5.16324D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      7     10      1     0     0   9.342D-07   8.941D-01\n",
      "  F =  0.89406771742361224     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.73754D-01    |proj g|=  1.64833D-02\n",
      "\n",
      "At iterate    5    f=  8.72966D-01    |proj g|=  2.83495D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4      8     12      1     0     0   2.584D-06   8.730D-01\n",
      "  F =  0.87296212162896381     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.18394D-01    |proj g|=  7.94404D-03\n",
      "\n",
      "At iterate    5    f=  9.18386D-01    |proj g|=  2.33980D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      5      7      1     0     0   2.340D-06   9.184D-01\n",
      "  F =  0.91838641972844381     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/erdos_sp_2024/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/erdos_sp_2024/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.07142D-01    |proj g|=  4.11395D-02\n",
      "\n",
      "At iterate    5    f=  8.91796D-01    |proj g|=  1.64227D-01\n",
      "\n",
      "At iterate   10    f=  8.87882D-01    |proj g|=  1.63518D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     12     15      1     0     0   2.679D-06   8.879D-01\n",
      "  F =  0.88788094728102318     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.02029D-01    |proj g|=  7.98841D-02\n",
      "\n",
      "At iterate    5    f=  8.96070D-01    |proj g|=  8.91344D-03\n",
      "\n",
      "At iterate   10    f=  8.84518D-01    |proj g|=  1.31996D-01\n",
      "\n",
      "At iterate   15    f=  8.80727D-01    |proj g|=  8.82578D-03\n",
      "\n",
      "At iterate   20    f=  8.80304D-01    |proj g|=  7.82267D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4     21     26      1     0     0   1.265D-05   8.803D-01\n",
      "  F =  0.88030360277020225     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.73315D-01    |proj g|=  1.76285D-02\n",
      "\n",
      "At iterate    5    f=  8.72801D-01    |proj g|=  1.58063D-03\n",
      "\n",
      "At iterate   10    f=  8.72701D-01    |proj g|=  1.78453D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     14     18      1     0     0   6.867D-06   8.727D-01\n",
      "  F =  0.87270006518384291     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.14298D-01    |proj g|=  1.72048D-03\n",
      "\n",
      "At iterate    5    f=  9.14296D-01    |proj g|=  2.38488D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      6     14      1     0     0   2.324D-05   9.143D-01\n",
      "  F =  0.91429578381196708     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.00697D+00    |proj g|=  4.61397D-01\n",
      "\n",
      "At iterate    5    f=  9.09668D-01    |proj g|=  2.50453D-02\n",
      "\n",
      "At iterate   10    f=  8.97738D-01    |proj g|=  8.34037D-02\n",
      "\n",
      "At iterate   15    f=  8.77015D-01    |proj g|=  2.10012D-02\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4     18     20      1     0     0   8.333D-06   8.769D-01\n",
      "  F =  0.87693289752929415     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.80345D-01    |proj g|=  8.33879D-02\n",
      "\n",
      "At iterate    5    f=  8.76662D-01    |proj g|=  1.14978D-02\n",
      "\n",
      "At iterate   10    f=  8.75704D-01    |proj g|=  6.08590D-03\n",
      "\n",
      "At iterate   15    f=  8.75279D-01    |proj g|=  3.66670D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     18     22      1     0     0   9.797D-06   8.753D-01\n",
      "  F =  0.87527861386240713     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            6     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.77437D-01    |proj g|=  7.26773D-02\n",
      "\n",
      "At iterate    5    f=  8.75985D-01    |proj g|=  2.34487D-02\n",
      "\n",
      "At iterate   10    f=  8.74281D-01    |proj g|=  5.60905D-03\n",
      "\n",
      "At iterate   15    f=  8.73115D-01    |proj g|=  2.54002D-02\n",
      "\n",
      "At iterate   20    f=  8.72001D-01    |proj g|=  1.29777D-03\n",
      "\n",
      "At iterate   25    f=  8.72000D-01    |proj g|=  9.02624D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    6     26     30      1     0     0   1.206D-05   8.720D-01\n",
      "  F =  0.87199990166997920     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.01441D-01    |proj g|=  6.31231D-03\n",
      "\n",
      "At iterate    5    f=  9.01437D-01    |proj g|=  3.03293D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4      6      8      1     0     0   4.916D-06   9.014D-01\n",
      "  F =  0.90143661971855560     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.94810D-01    |proj g|=  3.95369D-02\n",
      "\n",
      "At iterate    5    f=  8.90749D-01    |proj g|=  4.14598D-02\n",
      "\n",
      "At iterate   10    f=  8.76088D-01    |proj g|=  1.38631D-02\n",
      "\n",
      "At iterate   15    f=  8.74843D-01    |proj g|=  1.60487D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     18     22      1     0     0   2.964D-06   8.748D-01\n",
      "  F =  0.87484192417877216     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            6     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.82086D-01    |proj g|=  7.18297D-02\n",
      "\n",
      "At iterate    5    f=  8.78681D-01    |proj g|=  1.86043D-02\n",
      "\n",
      "At iterate   10    f=  8.75243D-01    |proj g|=  1.19836D-03\n",
      "\n",
      "At iterate   15    f=  8.74946D-01    |proj g|=  6.77087D-03\n",
      "\n",
      "At iterate   20    f=  8.74815D-01    |proj g|=  1.58668D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    6     21     26      1     0     0   9.222D-06   8.748D-01\n",
      "  F =  0.87481541174377331     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            7     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.76489D-01    |proj g|=  2.02148D-01\n",
      "\n",
      "At iterate    5    f=  8.70800D-01    |proj g|=  4.07601D-02\n",
      "\n",
      "At iterate   10    f=  8.70450D-01    |proj g|=  1.03580D-02\n",
      "\n",
      "At iterate   15    f=  8.69767D-01    |proj g|=  4.88965D-03\n",
      "\n",
      "At iterate   20    f=  8.69753D-01    |proj g|=  4.37354D-03\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At iterate   25    f=  8.69260D-01    |proj g|=  3.36969D-02\n",
      "\n",
      "At iterate   30    f=  8.68309D-01    |proj g|=  1.52766D-02\n",
      "\n",
      "At iterate   35    f=  8.68148D-01    |proj g|=  1.47165D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    7     37     61      1     0     0   1.259D-05   8.681D-01\n",
      "  F =  0.86814835142746483     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.00067D+00    |proj g|=  7.19459D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      2      6      1     0     0   2.537D-05   1.001D+00\n",
      "  F =   1.0006609963964637     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.02562D-01    |proj g|=  4.84041D-02\n",
      "\n",
      "At iterate    5    f=  8.99178D-01    |proj g|=  2.65651D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      6      9      1     0     0   1.736D-07   8.992D-01\n",
      "  F =  0.89917805962022745     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.02644D-01    |proj g|=  9.48631D-02\n",
      "\n",
      "At iterate    5    f=  8.94330D-01    |proj g|=  5.80674D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      6      9      1     0     0   9.402D-06   8.943D-01\n",
      "  F =  0.89432953157277262     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.74644D-01    |proj g|=  1.69165D-02\n",
      "\n",
      "At iterate    5    f=  8.73806D-01    |proj g|=  2.72679D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4      8     12      1     0     0   2.623D-06   8.738D-01\n",
      "  F =  0.87380216606310612     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.18933D-01    |proj g|=  7.82754D-03\n",
      "\n",
      "At iterate    5    f=  9.18925D-01    |proj g|=  2.36358D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      5      7      1     0     0   2.364D-06   9.189D-01\n",
      "  F =  0.91892478556857082     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.07277D-01    |proj g|=  4.10871D-02\n",
      "\n",
      "At iterate    5    f=  8.91865D-01    |proj g|=  1.55067D-01\n",
      "\n",
      "At iterate   10    f=  8.88658D-01    |proj g|=  9.96231D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     13     16      1     0     0   2.184D-06   8.886D-01\n",
      "  F =  0.88864810608251532     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.02199D-01    |proj g|=  7.78601D-02\n",
      "\n",
      "At iterate    5    f=  8.96424D-01    |proj g|=  7.86639D-03\n",
      "\n",
      "At iterate   10    f=  8.86822D-01    |proj g|=  1.54418D-01\n",
      "\n",
      "At iterate   15    f=  8.81074D-01    |proj g|=  1.12131D-02\n",
      "\n",
      "At iterate   20    f=  8.80836D-01    |proj g|=  8.35620D-07\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4     20     26      1     0     0   8.356D-07   8.808D-01\n",
      "  F =  0.88083551522375536     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.74240D-01    |proj g|=  1.78556D-02\n",
      "\n",
      "At iterate    5    f=  8.73666D-01    |proj g|=  1.95707D-03\n",
      "\n",
      "At iterate   10    f=  8.73511D-01    |proj g|=  9.68778D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     14     18      1     0     0   1.302D-05   8.735D-01\n",
      "  F =  0.87350983927435988     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.14514D-01    |proj g|=  1.71923D-03\n",
      "\n",
      "At iterate    5    f=  9.14512D-01    |proj g|=  2.27069D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      5      7      1     0     0   2.271D-05   9.145D-01\n",
      "  F =  0.91451217306966304     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.01022D+00    |proj g|=  4.66768D-01\n",
      "\n",
      "At iterate    5    f=  9.09782D-01    |proj g|=  2.48874D-02\n",
      "\n",
      "At iterate   10    f=  9.00461D-01    |proj g|=  8.49656D-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " Warning:  more than 10 function and gradient\n",
      "   evaluations in the last line search.  Termination\n",
      "   may possibly be caused by a bad search direction.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/erdos_sp_2024/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/erdos_sp_2024/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   15    f=  8.77565D-01    |proj g|=  1.72670D-02\n",
      "\n",
      "At iterate   20    f=  8.77387D-01    |proj g|=  1.03987D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4     20     23      1     0     0   1.040D-05   8.774D-01\n",
      "  F =  0.87738685040766418     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.81395D-01    |proj g|=  8.20036D-02\n",
      "\n",
      "At iterate    5    f=  8.77586D-01    |proj g|=  1.13843D-02\n",
      "\n",
      "At iterate   10    f=  8.76603D-01    |proj g|=  6.41162D-03\n",
      "\n",
      "At iterate   15    f=  8.75996D-01    |proj g|=  1.53378D-03\n",
      "\n",
      "At iterate   20    f=  8.75991D-01    |proj g|=  5.09747D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     20     24      1     0     0   5.097D-06   8.760D-01\n",
      "  F =  0.87599088474664122     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            6     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.78779D-01    |proj g|=  8.89222D-02\n",
      "\n",
      "At iterate    5    f=  8.76870D-01    |proj g|=  3.17051D-02\n",
      "\n",
      "At iterate   10    f=  8.74987D-01    |proj g|=  7.24011D-03\n",
      "\n",
      "At iterate   15    f=  8.74308D-01    |proj g|=  1.89535D-02\n",
      "\n",
      "At iterate   20    f=  8.73000D-01    |proj g|=  7.24852D-03\n",
      "\n",
      "At iterate   25    f=  8.72683D-01    |proj g|=  3.16877D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    6     29     35      1     0     0   3.453D-05   8.727D-01\n",
      "  F =  0.87267744400335501     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.02574D-01    |proj g|=  6.27536D-03\n",
      "\n",
      "At iterate    5    f=  9.02570D-01    |proj g|=  2.84750D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4      6      8      1     0     0   5.661D-06   9.026D-01\n",
      "  F =  0.90256993444716616     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.95933D-01    |proj g|=  3.93216D-02\n",
      "\n",
      "At iterate    5    f=  8.91721D-01    |proj g|=  4.23556D-02\n",
      "\n",
      "At iterate   10    f=  8.77064D-01    |proj g|=  1.23240D-02\n",
      "\n",
      "At iterate   15    f=  8.75606D-01    |proj g|=  1.53628D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     18     22      1     0     0   4.478D-07   8.756D-01\n",
      "  F =  0.87560517597338616     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            6     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.83036D-01    |proj g|=  7.22780D-02\n",
      "\n",
      "At iterate    5    f=  8.79532D-01    |proj g|=  1.63176D-02\n",
      "\n",
      "At iterate   10    f=  8.76092D-01    |proj g|=  1.15823D-03\n",
      "\n",
      "At iterate   15    f=  8.75799D-01    |proj g|=  8.41675D-03\n",
      "\n",
      "At iterate   20    f=  8.75593D-01    |proj g|=  1.24710D-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    6     22     26      1     0     0   1.732D-05   8.756D-01\n",
      "  F =  0.87559322914831184     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            7     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.78599D-01    |proj g|=  1.94130D-01\n",
      "\n",
      "At iterate    5    f=  8.72725D-01    |proj g|=  4.41958D-02\n",
      "\n",
      "At iterate   10    f=  8.72311D-01    |proj g|=  2.75724D-02\n",
      "\n",
      "At iterate   15    f=  8.71602D-01    |proj g|=  4.56281D-03\n",
      "\n",
      "At iterate   20    f=  8.71304D-01    |proj g|=  7.68527D-03\n",
      "\n",
      "At iterate   25    f=  8.69422D-01    |proj g|=  1.73153D-02\n",
      "\n",
      "At iterate   30    f=  8.68965D-01    |proj g|=  4.04716D-03\n",
      "\n",
      "At iterate   35    f=  8.68955D-01    |proj g|=  9.91142D-04\n",
      "\n",
      "At iterate   40    f=  8.68953D-01    |proj g|=  2.89336D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    7     40     49      1     0     0   2.893D-05   8.690D-01\n",
      "  F =  0.86895346969503451     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            1     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.97816D-01    |proj g|=  7.11345D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    1      2      6      1     0     0   2.526D-05   9.978D-01\n",
      "  F =  0.99781033698336818     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.00509D-01    |proj g|=  4.88386D-02\n",
      "\n",
      "At iterate    5    f=  8.97082D-01    |proj g|=  2.74700D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      6      9      1     0     0   1.851D-07   8.971D-01\n",
      "  F =  0.89708229830835529     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.99496D-01    |proj g|=  9.01488D-02\n",
      "\n",
      "At iterate    5    f=  8.91673D-01    |proj g|=  6.01144D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      8     12      1     0     0   3.415D-05   8.917D-01\n",
      "  F =  0.89167217331584359     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.73965D-01    |proj g|=  1.86672D-02\n",
      "\n",
      "At iterate    5    f=  8.72941D-01    |proj g|=  2.55832D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4      8     12      1     0     0   2.611D-06   8.729D-01\n",
      "  F =  0.87293725670672029     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            2     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.18151D-01    |proj g|=  7.72442D-03\n",
      "\n",
      "At iterate    5    f=  9.18144D-01    |proj g|=  2.32162D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    2      5      7      1     0     0   2.322D-06   9.181D-01\n",
      "  F =  0.91814391091089287     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.04217D-01    |proj g|=  4.42505D-02\n",
      "\n",
      "At iterate    5    f=  8.87624D-01    |proj g|=  1.33106D-01\n",
      "\n",
      "At iterate   10    f=  8.85748D-01    |proj g|=  5.78255D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3     13     16      1     0     0   9.058D-06   8.857D-01\n",
      "  F =  0.88573698400285372     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.99401D-01    |proj g|=  8.18769D-02\n",
      "\n",
      "At iterate    5    f=  8.93080D-01    |proj g|=  9.09342D-03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/erdos_sp_2024/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:966: UserWarning: Non-stationary starting autoregressive parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-stationary starting autoregressive parameters'\n",
      "/opt/homebrew/Caskroom/miniforge/base/envs/erdos_sp_2024/lib/python3.12/site-packages/statsmodels/tsa/statespace/sarimax.py:978: UserWarning: Non-invertible starting MA parameters found. Using zeros as starting parameters.\n",
      "  warn('Non-invertible starting MA parameters found.'\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate   10    f=  8.79961D-01    |proj g|=  1.93382D-02\n",
      "\n",
      "At iterate   15    f=  8.78796D-01    |proj g|=  3.76358D-02\n",
      "\n",
      "At iterate   20    f=  8.78246D-01    |proj g|=  7.17510D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4     21     26      1     0     0   1.399D-05   8.782D-01\n",
      "  F =  0.87824644621895920     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.73461D-01    |proj g|=  1.85868D-02\n",
      "\n",
      "At iterate    5    f=  8.72747D-01    |proj g|=  2.64125D-03\n",
      "\n",
      "At iterate   10    f=  8.72398D-01    |proj g|=  1.05941D-03\n",
      "\n",
      "At iterate   15    f=  8.72397D-01    |proj g|=  2.51123D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     15     19      1     0     0   2.511D-05   8.724D-01\n",
      "  F =  0.87239657343043020     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            3     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.12758D-01    |proj g|=  1.67455D-03\n",
      "\n",
      "At iterate    5    f=  9.12756D-01    |proj g|=  2.21748D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    3      5      7      1     0     0   2.217D-05   9.128D-01\n",
      "  F =  0.91275625004255301     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  1.00699D+00    |proj g|=  4.61740D-01\n",
      "\n",
      "At iterate    5    f=  9.07876D-01    |proj g|=  2.56850D-02\n",
      "\n",
      "At iterate   10    f=  8.96869D-01    |proj g|=  8.21501D-02\n",
      "\n",
      "At iterate   15    f=  8.75329D-01    |proj g|=  3.47421D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4     19     21      1     0     0   2.091D-06   8.753D-01\n",
      "  F =  0.87529569934859286     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.79508D-01    |proj g|=  8.14331D-02\n",
      "\n",
      "At iterate    5    f=  8.75799D-01    |proj g|=  1.17080D-02\n",
      "\n",
      "At iterate   10    f=  8.74872D-01    |proj g|=  5.64257D-03\n",
      "\n",
      "At iterate   15    f=  8.74263D-01    |proj g|=  4.61881D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     19     22      1     0     0   2.568D-05   8.742D-01\n",
      "  F =  0.87424908295427650     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            6     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.77252D-01    |proj g|=  9.85565D-02\n",
      "\n",
      "At iterate    5    f=  8.75174D-01    |proj g|=  5.53683D-02\n",
      "\n",
      "At iterate   10    f=  8.73865D-01    |proj g|=  6.16861D-03\n",
      "\n",
      "At iterate   15    f=  8.73549D-01    |proj g|=  1.75976D-02\n",
      "\n",
      "At iterate   20    f=  8.72361D-01    |proj g|=  1.32212D-02\n",
      "\n",
      "At iterate   25    f=  8.71731D-01    |proj g|=  2.29616D-03\n",
      "\n",
      "At iterate   30    f=  8.71724D-01    |proj g|=  1.11778D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    6     30     33      1     0     0   1.118D-05   8.717D-01\n",
      "  F =  0.87172399468605599     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            4     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  9.01570D-01    |proj g|=  6.14879D-03\n",
      "\n",
      "At iterate    5    f=  9.01566D-01    |proj g|=  2.31485D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    4      6      8      1     0     0   4.955D-06   9.016D-01\n",
      "  F =  0.90156609395216303     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.95132D-01    |proj g|=  3.88814D-02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "At iterate    5    f=  8.90839D-01    |proj g|=  4.42159D-02\n",
      "\n",
      "At iterate   10    f=  8.75668D-01    |proj g|=  1.24748D-02\n",
      "\n",
      "At iterate   15    f=  8.73951D-01    |proj g|=  1.41039D-03\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     17     21      1     0     0   2.820D-06   8.739D-01\n",
      "  F =  0.87394945211045516     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            6     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.81023D-01    |proj g|=  7.38239D-02\n",
      "\n",
      "At iterate    5    f=  8.77608D-01    |proj g|=  1.25893D-02\n",
      "\n",
      "At iterate   10    f=  8.74451D-01    |proj g|=  2.19532D-03\n",
      "\n",
      "At iterate   15    f=  8.74386D-01    |proj g|=  4.01234D-03\n",
      "\n",
      "At iterate   20    f=  8.73953D-01    |proj g|=  1.73265D-03\n",
      "\n",
      "At iterate   25    f=  8.73946D-01    |proj g|=  4.21608D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    6     25     30      1     0     0   4.216D-05   8.739D-01\n",
      "  F =  0.87394614623020017     \n",
      "\n",
      "CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH             \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            7     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  8.88378D-01    |proj g|=  5.04010D-01\n",
      "\n",
      "At iterate    5    f=  8.79814D-01    |proj g|=  6.29369D-02\n",
      "\n",
      "At iterate   10    f=  8.73147D-01    |proj g|=  6.73655D-03\n",
      "\n",
      "At iterate   15    f=  8.72819D-01    |proj g|=  1.64069D-02\n",
      "\n",
      "At iterate   20    f=  8.72256D-01    |proj g|=  5.52226D-03\n",
      "\n",
      "At iterate   25    f=  8.72212D-01    |proj g|=  7.08459D-03\n",
      "\n",
      "At iterate   30    f=  8.70434D-01    |proj g|=  6.07127D-02\n",
      "\n",
      "At iterate   35    f=  8.68638D-01    |proj g|=  2.90626D-02\n",
      "\n",
      "At iterate   40    f=  8.67906D-01    |proj g|=  3.18913D-03\n",
      "\n",
      "At iterate   45    f=  8.67899D-01    |proj g|=  1.58678D-04\n",
      "\n",
      "At iterate   50    f=  8.67899D-01    |proj g|=  5.28716D-05\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    7     53     60      1     0     0   4.420D-06   8.679D-01\n",
      "  F =  0.86789902285287035     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n"
     ]
    }
   ],
   "source": [
    "arima_rmses = np.zeros((10, 4, 4))\n",
    "\n",
    "i = 0\n",
    "for train_index, test_index in cv.split(tv_train):\n",
    "    ### NOTE THE ORIGINAL COPY HAD A TYPO\n",
    "    ### should be iloc not loc\n",
    "    tv_tt = tv_train.iloc[train_index]\n",
    "    tv_ho = tv_train.iloc[test_index]\n",
    "    \n",
    "    j = 0\n",
    "    for p in range(4):\n",
    "        k = 0\n",
    "        for q in range(4):\n",
    "            arima = SARIMAX(tv_tt.imdb_rating.values,\n",
    "                               order=(p, 1, q)).fit(maxiter=500)\n",
    "            \n",
    "            arima_rmses[i,j,k] = np.sqrt(mean_squared_error(tv_ho.imdb_rating.values, \n",
    "                                                   arima.forecast(len(tv_ho))))\n",
    "            k = k +1\n",
    "        j = j + 1\n",
    "    i = i +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "051d7343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arima_ind = np.unravel_index(np.argmin(np.mean(arima_rmses, axis=0), axis=None), \n",
    "                             np.mean(arima_rmses, axis=0).shape)\n",
    "np.unravel_index(np.argmin(np.mean(arima_rmses, axis=0), axis=None), \n",
    "                 np.mean(arima_rmses, axis=0).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8aed555e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The p and q values that give an ARIMA model with lowest avg cv mse are p =  1 and q =  3\n",
      "This model had an avg cv mse of 0.529\n"
     ]
    }
   ],
   "source": [
    "print(\"The p and q values that give an ARIMA model\",\n",
    "         \"with lowest avg cv mse are\",\n",
    "         \"p = \", range(4)[arima_ind[0]],\n",
    "         \"and q = \", range(4)[arima_ind[1]])\n",
    "\n",
    "print(\"This model had an avg cv mse of\",\n",
    "         np.round(np.mean(arima_rmses, axis=0)[arima_ind],3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6081c1e",
   "metadata": {},
   "source": [
    "##### g.\n",
    "\n",
    "Compare the best RMSE you attained in this notebook to the best RMSE for the baseline models in the completed version of `Problem Session 6`.\n",
    "\n",
    "Plot the best forecast with the training and test data. What is the RMSE of the forecast on the test data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6ad3ca",
   "metadata": {},
   "source": [
    "##### Sample Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0859b807",
   "metadata": {},
   "outputs": [],
   "source": [
    "holt = Holt(tv_train.imdb_rating.values).fit(smoothing_level=.01, \n",
    "                                              smoothing_trend=.14,\n",
    "                                              optimized=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32456751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14,5))\n",
    "\n",
    "plt.scatter(tv_train.episode_number,\n",
    "               tv_train.imdb_rating,\n",
    "               alpha=.5,\n",
    "               label=\"Training Points\")\n",
    "\n",
    "plt.scatter(tv_test.episode_number,\n",
    "               tv_test.imdb_rating,\n",
    "               alpha=.5,\n",
    "               c = 'red',\n",
    "               marker = 'v',\n",
    "               label=\"Test Points\")\n",
    "\n",
    "plt.plot(tv_train.episode_number,\n",
    "            holt.fittedvalues,\n",
    "            'k-',\n",
    "            linewidth = 2,\n",
    "            label=\"Fitted Values\")\n",
    "\n",
    "plt.plot(tv_test.episode_number,\n",
    "            arima.forecast(len(tv_test)),\n",
    "            'r--',\n",
    "            linewidth=2,\n",
    "            label=\"Forecast\")\n",
    "\n",
    "plt.legend(fontsize=12, loc=4)\n",
    "\n",
    "test_mse = np.sqrt(mean_squared_error(tv_test.imdb_rating.values, \n",
    "                                       holt.forecast(len(tv_test))))\n",
    "\n",
    "plt.title(\"Test Set MSE = \" + str(np.round(test_mse,3)),\n",
    "             fontsize=14)\n",
    "\n",
    "plt.xlabel(\"Episode Number\", fontsize=12)\n",
    "plt.ylabel(\"IMDB Rating\", fontsize=12)\n",
    "\n",
    "\n",
    "plt.ylim(3,8.5)\n",
    "plt.xlim(180,220)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc55f33",
   "metadata": {},
   "source": [
    "#### 2. Pumpkin spice seasonal ARIMA\n",
    "\n",
    "In this problem you will be introduces to seasonal ARIMA models with the pumpkin spice Google trend data. This will be a surface level introduction, for a more in depth look check out the time series practice problems `jupyter notebook`.\n",
    "\n",
    "##### a.\n",
    "\n",
    "Load the data stored in `pumpkin_spice.csv` in the `Data` folder then look at the first five rows. Then make a train test split setting aside all observations on or after January 1, 2022 aside as the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56eec377",
   "metadata": {},
   "source": [
    "##### Sample Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "10d3bbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pumpkin = pd.read_csv(\"../../data/pumpkin_spice.csv\",\n",
    "                         parse_dates = [\"Month\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "150d93d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_train = pumpkin.loc[pumpkin.Month < datetime(2022, 1, 1)].copy()\n",
    "p_test = pumpkin.drop(p_train.index).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b0ac66",
   "metadata": {},
   "source": [
    "##### b.\n",
    "\n",
    "In lecture we talked about first differencing non-stationary time series exhibiting a trend to create a, seemingly, stationary time series.\n",
    "\n",
    "This can also be done for seasonal data. Suppose that we suspect a time series, $\\left\\lbrace y_t \\right\\rbrace$ exhibits seasonality where a season lasts $m$ time steps. Then the first seasonal differenced time series is:\n",
    "\n",
    "$$\n",
    "\\nabla_s y_t = y_t - y_{t-m}.\n",
    "$$\n",
    "\n",
    "Plot the autocorrelation of the training set, then perform first seasonal differencing on these data and plot the autocorrelation of the first seasonal differenced series.\n",
    "\n",
    "Does the differenced series appear less likely to violate stationarity?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97308cac",
   "metadata": {},
   "source": [
    "##### Sample Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f5cfcfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.tsa.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a928b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots(1,1, figsize=(12,5))\n",
    "\n",
    "sm.graphics.plot_acf(p_train.interest_level.values,\n",
    "                        alpha=None, \n",
    "                        lags = 36,\n",
    "                        ax = ax)\n",
    "\n",
    "plt.ylim([-1.1,1.1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e909831b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots(1,1, figsize=(12,5))\n",
    "\n",
    "sm.graphics.plot_acf(p_train.interest_level.diff(12)[12:],\n",
    "                        alpha=None, \n",
    "                        lags = 36,\n",
    "                        ax = ax)\n",
    "\n",
    "plt.ylim([-1.1,1.1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493b0de6",
   "metadata": {},
   "source": [
    "These data appear to less egregiously violate stationarity, but it may be reasonable to consider second differencing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d36f73b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots(1,1, figsize=(12,5))\n",
    "\n",
    "sm.graphics.plot_acf(p_train.interest_level.diff(12)[12:].diff(12)[12:],\n",
    "                        alpha=None, \n",
    "                        lags = 36,\n",
    "                        ax = ax)\n",
    "\n",
    "plt.ylim([-1.1,1.1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fad46e7",
   "metadata": {},
   "source": [
    "##### c.\n",
    "\n",
    "While traditional $\\text{ARIMA}$ models do not work well for seasonal data, there are seasonal ARIMA ($\\text{SARIMA}$) models as well. Recall for an $\\text{ARIMA}$ model you needed parameters $p$, $d$ and $q$. For a $\\text{SARIMA}$ model you need parameters $P$, $D$, $Q$ and $m$ here:\n",
    "\n",
    "- $P$ is the order of the seasonal autoregressive portion of the model,\n",
    "- $Q$ is the order of the seasonal moving average portion of the model,\n",
    "- $D$ is the order of the seasonal differencing and\n",
    "- $m$ is the number of time steps that take place in a single period.\n",
    "\n",
    "You should have an idea of a value for $D$ from <i>b.</i> and we know $m=12$. In this problem you will fit a $\\text{SARIMA}$ model on the pumpkin spice data using `statsmodels` `SARIMAX`. Choose whatever values you would like for $p$, $P$, $q$ and $Q$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0503b5ed",
   "metadata": {},
   "source": [
    "##### Sample Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b3a6e2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.59553D+00    |proj g|=  1.43902D-01\n",
      "\n",
      "At iterate    5    f=  2.56937D+00    |proj g|=  4.81223D-03\n",
      "\n",
      "At iterate   10    f=  2.56875D+00    |proj g|=  2.59023D-03\n",
      "\n",
      "At iterate   15    f=  2.56868D+00    |proj g|=  2.65344D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     18     20      1     0     0   2.662D-06   2.569D+00\n",
      "  F =   2.5686749114631962     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n"
     ]
    }
   ],
   "source": [
    "sarima = SARIMAX(p_train.interest_level.values,\n",
    "                    order = (1,0,1),\n",
    "                    seasonal_order = (1,1,1,12)).fit(maxiter=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7049e408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "\n",
    "plt.plot(p_train.Month,\n",
    "            p_train.interest_level,\n",
    "            'b-o',\n",
    "            label='Training Data')\n",
    "\n",
    "plt.plot(p_train.Month,\n",
    "            sarima.fittedvalues,\n",
    "            'r',\n",
    "            label='Fitted Values')\n",
    "\n",
    "plt.scatter(p_test.Month,\n",
    "               sarima.forecast(len(p_test)),\n",
    "               c='r',\n",
    "               marker='x',\n",
    "               s=100,\n",
    "               label=\"Forecast\")\n",
    "\n",
    "plt.legend(fontsize=14)\n",
    "plt.xlabel(\"Date\", fontsize=14)\n",
    "plt.ylabel(\"Interest Level\", fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f955b77",
   "metadata": {},
   "source": [
    "##### d. \n",
    "\n",
    "Get the average cross-validation MSE for the SARIMA model you fit above. Use 5-fold cross-validation with a test set size of 12.\n",
    "\n",
    "\n",
    "How does it compare to the baseline models from `Problem Session 6`? <i>Feel free to use the answer from the completed version `Problem Session 6` if you did not complete it</i>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9aa3ec",
   "metadata": {},
   "source": [
    "##### Sample Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a50ea813",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = TimeSeriesSplit(5, test_size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1eab0cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.37715D+00    |proj g|=  3.15535D-01\n",
      "\n",
      "At iterate    5    f=  2.25907D+00    |proj g|=  7.62395D-03\n",
      "\n",
      "At iterate   10    f=  2.25803D+00    |proj g|=  5.02396D-04\n",
      "\n",
      "At iterate   15    f=  2.25803D+00    |proj g|=  6.02354D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     15     17      1     0     0   6.024D-06   2.258D+00\n",
      "  F =   2.2580276655882581     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.38408D+00    |proj g|=  2.65775D-01\n",
      "\n",
      "At iterate    5    f=  2.30342D+00    |proj g|=  2.70889D-03\n",
      "\n",
      "At iterate   10    f=  2.30337D+00    |proj g|=  1.12657D-04\n",
      "\n",
      "At iterate   15    f=  2.30337D+00    |proj g|=  7.94858D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     15     18      1     0     0   7.949D-06   2.303D+00\n",
      "  F =   2.3033713214599025     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n",
      " This problem is unconstrained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.56966D+00    |proj g|=  2.06547D-01\n",
      "\n",
      "At iterate    5    f=  2.50087D+00    |proj g|=  1.73626D-02\n",
      "\n",
      "At iterate   10    f=  2.49823D+00    |proj g|=  4.11580D-03\n",
      "\n",
      "At iterate   15    f=  2.49436D+00    |proj g|=  1.30434D-02\n",
      "\n",
      "At iterate   20    f=  2.49334D+00    |proj g|=  2.53466D-03\n",
      "\n",
      "At iterate   25    f=  2.49318D+00    |proj g|=  1.69145D-06\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     25     30      1     0     0   1.691D-06   2.493D+00\n",
      "  F =   2.4931809737780624     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.55907D+00    |proj g|=  1.64579D-01\n",
      "\n",
      "At iterate    5    f=  2.50567D+00    |proj g|=  2.12426D-02\n",
      "\n",
      "At iterate   10    f=  2.50481D+00    |proj g|=  1.70464D-03\n",
      "\n",
      "At iterate   15    f=  2.50463D+00    |proj g|=  4.78727D-04\n",
      "\n",
      "At iterate   20    f=  2.50385D+00    |proj g|=  7.51706D-03\n",
      "\n",
      "At iterate   25    f=  2.50330D+00    |proj g|=  2.20896D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     28     38      1     0     0   2.879D-06   2.503D+00\n",
      "  F =   2.5033009977288234     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =            5     M =           10\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  2.56662D+00    |proj g|=  1.80726D-01\n",
      "\n",
      "At iterate    5    f=  2.51659D+00    |proj g|=  1.74424D-02\n",
      "\n",
      "At iterate   10    f=  2.51582D+00    |proj g|=  4.97844D-03\n",
      "\n",
      "At iterate   15    f=  2.51401D+00    |proj g|=  6.63722D-03\n",
      "\n",
      "At iterate   20    f=  2.51219D+00    |proj g|=  3.98601D-03\n",
      "\n",
      "At iterate   25    f=  2.51152D+00    |proj g|=  1.32648D-04\n",
      "\n",
      "           * * *\n",
      "\n",
      "Tit   = total number of iterations\n",
      "Tnf   = total number of function evaluations\n",
      "Tnint = total number of segments explored during Cauchy searches\n",
      "Skip  = number of BFGS updates skipped\n",
      "Nact  = number of active bounds at final generalized Cauchy point\n",
      "Projg = norm of the final projected gradient\n",
      "F     = final function value\n",
      "\n",
      "           * * *\n",
      "\n",
      "   N    Tit     Tnf  Tnint  Skip  Nact     Projg        F\n",
      "    5     26     36      1     0     0   7.936D-06   2.512D+00\n",
      "  F =   2.5115232863600818     \n",
      "\n",
      "CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL            \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " This problem is unconstrained.\n"
     ]
    }
   ],
   "source": [
    "rmses = np.zeros(5)\n",
    "\n",
    "i = 0\n",
    "for train_index, test_index in cv.split(p_train):\n",
    "    p_tt = p_train.iloc[train_index]\n",
    "    p_ho = p_train.iloc[test_index]\n",
    "    \n",
    "    sarima = SARIMAX(p_tt.interest_level.values,\n",
    "                    order = (1,0,1),\n",
    "                    seasonal_order = (1,1,1,12)).fit(maxiter=200)\n",
    "    \n",
    "    rmses[i] = np.sqrt(mean_squared_error(p_ho.interest_level.values,\n",
    "                                             sarima.forecast(12)))\n",
    "    \n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "14380bc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.9908503658794"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(rmses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641e1615",
   "metadata": {},
   "source": [
    "For me this was lower than the seasonal average baseline, but slightly higher than the seasonal naive baseline. That's not to say we would not be able to do better than the baseline, we have not done any hyperparameter tuning of the $p, q, P,$ or $Q$ values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168c713f",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "\n",
    "This notebook was written for the Erd&#337;s Institute C&#337;de Data Science Boot Camp by Matthew Osborne, Ph. D., 2023.\n",
    "\n",
    "Any potential redistributors must seek and receive permission from Matthew Tyler Osborne, Ph.D. prior to redistribution. Redistribution of the material contained in this repository is conditional on acknowledgement of Matthew Tyler Osborne, Ph.D.'s original authorship and sponsorship of the Erdős Institute as subject to the license (see License.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fac1662",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

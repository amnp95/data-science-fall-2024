{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f1769a6",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression\n",
    "\n",
    "Most variables of interest probably depend upon more than just a single feature. That is why statisticians invented multiple linear regression.\n",
    "\n",
    "## What we will accomplish\n",
    "\n",
    "In this notebook we will:\n",
    "- Introduce the multiple linear regression model,\n",
    "- Show how to fit the model using the <i>normal equation</i>,\n",
    "- Fit a sample model with `numpy` and\n",
    "- Fit the same model with `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f515b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from seaborn import set_style\n",
    "\n",
    "set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277995ad",
   "metadata": {},
   "source": [
    "## The multiple linear regression model\n",
    "\n",
    "Suppose there is a quantitative variable you want to predict/model called $y$ and a set of $m$ features $X_1, X_2, \\dots X_m$, then the multiple linear regression model regressing $y$ on $X_1, \\dots, X_m$ is:\n",
    "\n",
    "$$\n",
    "y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\dots + \\beta_m X_m + \\epsilon = X \\beta + \\epsilon,\n",
    "$$\n",
    "\n",
    "where $\\beta_0, \\dots, \\beta_m \\in \\mathbb{R}$ are constants, $\\beta$ is an $(m+1) \\times 1$ vector of the $\\beta_i$s in numerical order, \n",
    "\n",
    "$$\n",
    "X = \\left(1 | X_1 | X_2 | \\dots | X_m \\right),\n",
    "$$\n",
    "\n",
    "and $\\epsilon \\sim N(0,\\sigma)$ is an error term independent of $X$.\n",
    "\n",
    "### Fitting the model\n",
    "\n",
    "Suppose that we have $n$ observations $(X^{(i)}, y^{(i)})$. In order to fit a multiple linear regression model regressing $y$ on $X$ using this data we return to the mean square error.\n",
    "\n",
    "$$\n",
    "MSE = \\frac{1}{n} \\sum_{i=1}^n \\left(y^{(i)} - \\hat{y}^{(i)}\\right)^2 = \\frac{1}{n} \\sum_{i=1}^n \\left(y^{(i)} - X^{(i)} \\hat{\\beta}\\right)^2,\n",
    "$$\n",
    "\n",
    "we can rewrite this using some linear algebra as:\n",
    "\n",
    "$$\n",
    "MSE = \\frac{1}{n}\\left(y - X\\hat{\\beta} \\right)^T\\left(y-X\\hat{\\beta} \\right) = \\frac{1}{n}\\left( y^T y - \\hat{\\beta}^T X^T y - y^T X \\hat{\\beta} + \\hat{\\beta}^T X^T X \\hat{\\beta}\\right). \n",
    "$$\n",
    "\n",
    "When you take the derivative with respect to $\\hat{\\beta}$ and set it equal to $0$ gives the following:\n",
    "\n",
    "$$\n",
    "X^T X \\hat{\\beta} - X^T y = 0, \\text{ and so } \\hat{\\beta} = (X^T X)^{-1}X^T y.\n",
    "$$\n",
    "\n",
    "This is the <i>ordinary least squares</i> estimate of the coefficient vector $\\beta$. Note that this formula is also sometimes called the <i>normal equation</i>.\n",
    "\n",
    "### Back to baseball\n",
    "\n",
    "We will demonstrate how to fit this model in `numpy` and `sklearn` with the baseball example we looked at in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afcf800e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note this works on Mac and Linux,\n",
    "## you may need to change the slash directions if\n",
    "## you are running a Windows machine\n",
    "baseball = pd.read_csv(\"../../../data/baseball.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b08bd2c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teamID</th>\n",
       "      <th>yearID</th>\n",
       "      <th>lgID</th>\n",
       "      <th>G</th>\n",
       "      <th>W</th>\n",
       "      <th>L</th>\n",
       "      <th>R</th>\n",
       "      <th>RA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANA</td>\n",
       "      <td>2001</td>\n",
       "      <td>AL</td>\n",
       "      <td>162</td>\n",
       "      <td>75</td>\n",
       "      <td>87</td>\n",
       "      <td>691</td>\n",
       "      <td>730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ARI</td>\n",
       "      <td>2001</td>\n",
       "      <td>NL</td>\n",
       "      <td>162</td>\n",
       "      <td>92</td>\n",
       "      <td>70</td>\n",
       "      <td>818</td>\n",
       "      <td>677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  teamID  yearID lgID    G   W   L    R   RA\n",
       "0    ANA    2001   AL  162  75  87  691  730\n",
       "1    ARI    2001   NL  162  92  70  818  677"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseball.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9251fc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import train_test_split\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf2aeae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make the train test split here\n",
    "## Note a slight difference, we have to use .copy()\n",
    "## for pandas dataframes\n",
    "bb_train, bb_test = train_test_split(baseball.copy(),\n",
    "                                        shuffle = True,\n",
    "                                        random_state = 440,\n",
    "                                        test_size=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09500f6b",
   "metadata": {},
   "source": [
    "The multiple linear regression model that we will fit is:\n",
    "\n",
    "$$\n",
    "\\texttt{W} = \\beta_0 + \\beta_1 \\texttt{R} + \\beta_2 \\texttt{RA} + \\epsilon.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63e5ae3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## remember X needs a column of 1s\n",
    "X_train = np.ones((len(bb_train), 3))\n",
    "\n",
    "X_train[:,1:] = bb_train[['R', 'RA']].values\n",
    "y_train = bb_train.W.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08e195a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1., 667., 633.],\n",
       "       [  1., 770., 580.],\n",
       "       [  1., 718., 700.],\n",
       "       ...,\n",
       "       [  1., 657., 858.],\n",
       "       [  1., 678., 831.],\n",
       "       [  1., 513., 646.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3af2ae7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 86, 104,  83,  85, 100,  97, 105,  90,  95,  69,  91,  70,  91,\n",
       "        71,  83, 101,  75,  62,  69,  95,  85, 100,  93,  73,  56,  80,\n",
       "        88,  78,  76,  62,  78,  89,  93,  83,  77,  68,  76,  78,  76,\n",
       "        79,  97,  63,  82,  83,  81,  98,  96,  89,  83,  81,  86,  80,\n",
       "        74,  75,  91,  77,  97, 103,  85,  88,  90,  81,  64,  68,  66,\n",
       "        64,  63,  89,  71,  68,  92,  67,  86,  86,  83,  77,  84,  87,\n",
       "        86,  85,  76,  66,  82,  83,  80,  76,  81,  83,  88,  98,  92,\n",
       "        71,  75,  90,  78,  86,  75,  75,  84,  71,  92,  72,  96,  62,\n",
       "        78,  79,  71,  71,  90,  96,  51,  69,  68,  67,  75,  63,  96,\n",
       "        81,  93,  97,  83, 108,  88,  96,  73,  85,  90,  82,  88,  87,\n",
       "        92,  74,  67,  72,  91,  80,  75,  72,  89,  88,  87,  68,  66,\n",
       "        85,  70,  82,  92,  92,  75,  67,  77,  68,  75,  65,  85,  73,\n",
       "        86,  96,  73,  65,  62,  80,  67,  98,  95,  97,  71,  82,  79,\n",
       "        93,  75,  71,  80,  69,  93,  83,  85,  55,  81,  75,  88,  93,\n",
       "        73,  95,  66,  84,  82,  89,  85,  74,  86,  78,  73,  85,  84,\n",
       "        90,  72,  67,  66,  82,  69,  76,  83,  66,  58,  83,  97,  92,\n",
       "        95,  87,  77,  84,  71, 103,  78,  94,  72,  72,  74,  90,  81,\n",
       "        91,  89,  63,  79,  93,  89,  79,  86,  74,  88,  79,  75,  93,\n",
       "        80,  89,  85,  73,  79,  68,  69,  79,  67,  66,  72, 101,  85,\n",
       "        86,  97,  99,  68,  92,  96,  88,  71,  95,  95,  90,  59,  91,\n",
       "        63,  66,  43, 103,  75,  87,  67,  97,  80,  74,  65,  82,  89,\n",
       "        97,  55,  80,  86,  66, 102,  95,  86,  76,  90,  87,  72,  88,\n",
       "        57,  78,  70,  83,  83,  63,  64,  77,  88,  94,  73,  93,  88,\n",
       "        74,  90,  94,  58,  68,  94,  82,  61,  81,  47,  86,  69, 103,\n",
       "        96,  84,  86,  78,  74,  83,  83,  67,  67,  81,  89,  91, 100,\n",
       "        79,  64,  93,  81,  68,  83,  93,  93,  92,  67,  87,  55,  89,\n",
       "        94,  69,  71,  64,  79,  72,  74,  77,  80,  80,  83,  80,  92,\n",
       "        93,  76, 100,  66,  96,  72,  90,  78,  88,  90,  95,  96,  66,\n",
       "        91,  71,  69,  77, 116,  80,  96,  62,  65,  74,  67,  88,  73,\n",
       "        61,  69,  88,  94,  91,  90,  94,  88,  79,  88,  73,  86,  74,\n",
       "        86,  73,  71,  94,  97,  73,  91, 101,  97,  86,  81,  70,  84,\n",
       "        56,  87,  87,  91,  76,  74,  95,  94,  78,  82,  80,  67,  90,\n",
       "        69,  79,  80,  67, 102,  80,  71,  81,  59,  81,  92,  84,  80,\n",
       "        62,  64,  62])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60377673",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the normal equation\n",
    "## note we'll use the linalg subpackage of numpy a lot\n",
    "## here is a link to the documentation\n",
    "## https://numpy.org/doc/stable/reference/routines.linalg.html\n",
    "beta_hat = np.linalg.inv(X_train.transpose().dot(X_train)).dot(X_train.transpose()).dot(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d6ffc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beta_0_hat = 84.08213739723357\n",
      "beta_1_hat = 0.09718334537049489\n",
      "beta_2_hat = -0.10132296424142645\n"
     ]
    }
   ],
   "source": [
    "# looking at beta_hat\n",
    "print(\"beta_0_hat =\", beta_hat[0])\n",
    "print(\"beta_1_hat =\", beta_hat[1])\n",
    "print(\"beta_2_hat =\", beta_hat[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1218294",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make the predictions \n",
    "y_pred_numpy = beta_hat[0] + beta_hat[1] * X_train[:,1] + beta_hat[2] * X_train[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b527e4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the training mse is 16.945434114275745\n"
     ]
    }
   ],
   "source": [
    "## calculate the mse\n",
    "print(\"the training mse is\", np.sum(np.power(y_train-y_pred_numpy, 2))/len(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8823a31",
   "metadata": {},
   "source": [
    "### Using `sklearn`\n",
    "\n",
    "We will end this notebook by showing how simple it is to use `sklearn` to fit this model. In fact you already know how to do it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4fac5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import the LinearRegression object\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15145ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression(fit_intercept=False)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression(fit_intercept=False)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression(fit_intercept=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Make the model object\n",
    "## notice we have to us fit_intercept = False\n",
    "## because X_train has a column of 1s\n",
    "reg = LinearRegression(copy_X=True, fit_intercept=False)\n",
    "\n",
    "## Fit the model object\n",
    "## note I do NOT have to use reshape here\n",
    "## because X_train is a 2D np.array\n",
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72be0d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([84.0821374 ,  0.09718335, -0.10132296])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## look at coef\n",
    "reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33ac638d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make a prediction\n",
    "y_pred_sklearn = reg.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ab213dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the mse is 16.945434114275745\n"
     ]
    }
   ],
   "source": [
    "## calculate the mse\n",
    "print(\"the mse is\",np.sum(np.power(y_train-y_pred_sklearn, 2))/len(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e478ee19",
   "metadata": {},
   "source": [
    "That's it!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7d1ea9",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "\n",
    "This notebook was written for the Erd&#337;s Institute C&#337;de Data Science Boot Camp by Matthew Osborne, Ph. D., 2023.\n",
    "\n",
    "Any potential redistributors must seek and receive permission from Matthew Tyler Osborne, Ph.D. prior to redistribution. Redistribution of the material contained in this repository is conditional on acknowledgement of Matthew Tyler Osborne, Ph.D.'s original authorship and sponsorship of the Erdős Institute as subject to the license (see License.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb29a3a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

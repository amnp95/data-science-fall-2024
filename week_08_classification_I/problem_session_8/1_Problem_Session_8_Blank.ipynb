{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ef78ced",
   "metadata": {},
   "source": [
    "# Problem Session 8\n",
    "## Classifying Pumpkin Seeds I\n",
    "\n",
    "In the next few notebooks you will work to build models to classify types of pumpkin seeds using features engineered from photographs of the seeds. Here we will introduce the data set, perform some exploratory data analysis and build some simple models.\n",
    "\n",
    "The problems in this notebook will cover the content covered in our `Classification` notebooks including:\n",
    "- `Adjustments for Classification`,\n",
    "- `k Nearest Neighbors`,\n",
    "- `The Confusion Matrix` and\n",
    "- `Logistic Regression`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6282deb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07fd9e7",
   "metadata": {},
   "source": [
    "#### 1. Load the data\n",
    "\n",
    "##### a.\n",
    "\n",
    "First load the data stored in `Pumpkin_Seeds_Dataset.xlsx` in the `data` folder.\n",
    "\n",
    "Note you will want to use the `read_excel` function from `pandas`, <a href=\"https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html?highlight=read_excel\">https://pandas.pydata.org/docs/reference/api/pandas.read_excel.html?highlight=read_excel</a>. Print a random sample of five rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f682e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the data here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fc690a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## look at the sample here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff08a92a",
   "metadata": {},
   "source": [
    "##### b.\n",
    "\n",
    "Create a new column of the `DataFrame` called `y` where `y=1` if `Class=Ürgüp Sivrisi` and `y=0` if `Class=Çerçevelik`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f056d5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c517064b",
   "metadata": {},
   "source": [
    "#### 2. Learn about the data\n",
    "\n",
    "##### a.\n",
    "\n",
    "These data represent various measurements of pumpkin seeds that come from high quality photos of the seeds. The data was provided as supplementary material to <a href=\"https://link.springer.com/article/10.1007/s10722-021-01226-0\">The use of machine learning methods in classification of pumpkin seeds (Cucurbita pepo L.)</a> by Koklu, Sarigil and Ozbek (2021).\n",
    "\n",
    "In this work the researchers demonstrated how various algorithms could be used to predict whether a pumpkin seed was a Ürgüp Sivrisi seed or a Çerçevelik seed. These data were generated by engineering features from special photos of seeds like so:\n",
    "<br>\n",
    "<br>\n",
    "<img src=\"problem_session_8_assets/pumpkin_seeds.jpg\" width=\"55%\"></img>\n",
    "\n",
    "As you can see these two seeds can be quite difficult for the human eye to discern, hence the appeal to machine learning algorithms.\n",
    "\n",
    "A PDF of this paper is provided here, <a href=\"problem_session_8_assets/pumpkin_seed_paper.pdf\">pumpkin_seed_paper.pdf</a>. Scroll down to Figure 5 and Table 1 and read about the features of this data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e0d354",
   "metadata": {},
   "source": [
    "#### 3. Train test split\n",
    "\n",
    "##### a.\n",
    "\n",
    "Look at how the data is split between the two classes. Does this appear to be imbalanced data? <i>Recall that we say data is imbalanced if one of the classes has a very small presence in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1d540c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a20a86e",
   "metadata": {},
   "source": [
    "This data set seems pretty well balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce213013",
   "metadata": {},
   "source": [
    "##### b.\n",
    "\n",
    "Make a train test split, set aside $10\\%$ of the data as the test set (note that we are using $10\\%$ because this was the split they used in the paper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ff4c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238b9fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make your train test split here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cc9c08",
   "metadata": {},
   "source": [
    "#### 4. Exploratory data analysis (EDA)\n",
    "\n",
    "Before building any models you will do some EDA.\n",
    "\n",
    "##### a. \n",
    "\n",
    "One way to try and identify key features for classification algorithms is to plot histograms of the feature values for each of the classes.\n",
    "\n",
    "Below is an example of such a histogram for the `Area` column made using `plt.hist`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77598c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,5))\n",
    "\n",
    "\n",
    "plt.hist(seeds_train.loc[seeds_train.y==0].Area.values,\n",
    "            color='blue',\n",
    "            alpha=.8,\n",
    "            label=\"$y=0$\")\n",
    "\n",
    "plt.hist(seeds_train.loc[seeds_train.y==1].Area.values,\n",
    "            color='red',\n",
    "            alpha=.4,\n",
    "            hatch = '\\\\',\n",
    "            edgecolor='black',\n",
    "            label=\"$y=1$\")\n",
    "\n",
    "plt.xlabel(\"Area\", fontsize=12)\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d90fffe",
   "metadata": {},
   "source": [
    "In this plot we can see that the two histograms are right on top of one another, indicating that the two classes of pumpkin seeds tend to have similar areas. This suggests that `Area` may not be a useful variable for discerning the seed class.\n",
    "\n",
    "Use a `for` loop or some comparable method to produce similar histograms for each of the features. Write down the features that look like they may be useful for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa26d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7a4ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155ac496",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264970ca",
   "metadata": {},
   "source": [
    "##### Keep track of your selected variables here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59552475",
   "metadata": {},
   "source": [
    "##### b.\n",
    "\n",
    "Now try making a `seaborn` `pairplot` using the variables you identified in part <i>a.</i> as the arguments for `x_vars` and `y_vars`. Use `y` as the argument to `hue`. The main goal with this question is to see if you can identify any pairs of variables that seem to separate the two classes. You will use these plots later in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e6761f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fill in the missing code\n",
    "sns.pairplot(data = ,\n",
    "                x_vars = [],\n",
    "                y_vars = [],\n",
    "                hue = )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b563c4ce",
   "metadata": {},
   "source": [
    "#### 5. Metric selection\n",
    "\n",
    "In the remainder of this notebook you will make some initial models.\n",
    "\n",
    "##### a.\n",
    "\n",
    "Now that you have read about the data and looked at the split between the two classes what seems like a reasonable performance metric for this problem? Explain your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887c9cf1",
   "metadata": {},
   "source": [
    "##### Write here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cd093f",
   "metadata": {},
   "source": [
    "##### b.\n",
    "\n",
    "Recalling that `y=1` implies that the seed is of the Ürgüp Sivrisi class and `y=0` implies that the seed is of the Çerçevelik class, what do the following metrics measure in the context of this classification problem:\n",
    "- recall\n",
    "- precision\n",
    "- false positive rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c77821b",
   "metadata": {},
   "source": [
    "##### Write here\n",
    "\n",
    "- recall:\n",
    "- precision:\n",
    "- false positive rate:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38c27b5",
   "metadata": {},
   "source": [
    "#### 6. Initial modeling attempts\n",
    "\n",
    "In the remainder of this notebook you will make some initial models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1c24fc",
   "metadata": {},
   "source": [
    "##### a.\n",
    "\n",
    "Think of a baseline model for these data. Some common approaches are:\n",
    "- A random coin flip whose probability for heads is the same as the probability of drawing the more present class,\n",
    "- Classifying any observation as the majority class.\n",
    "\n",
    "For whichever baseline you choose project the generalization accuracy of the baseline using the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5997159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d80cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05ca9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48ba8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b0937b",
   "metadata": {},
   "source": [
    "##### b.\n",
    "\n",
    "Fill in the code below to perform 5-fold cross-validation in order to compare logistic regression models regressing `y` on each of the useful features you identified in your EDA above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faac99bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import what you will need\n",
    "from sklearn.linear_model import \n",
    "from sklearn.metrics import \n",
    "from sklearn.model_selection import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b070c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make your kfold object\n",
    "n_splits = \n",
    "\n",
    "kfold = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cb5eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fill in your list of features\n",
    "features = []\n",
    "\n",
    "## Make your array of zeros to hold the accuracies\n",
    "log_reg_accs = np.zeros()\n",
    "\n",
    "## Loop through the cv splits\n",
    "i = 0\n",
    "for train_index, test_index in kfold:\n",
    "    ## get the training and holdout sets\n",
    "    seeds_tt = seeds_train.iloc[train_index]\n",
    "    seeds_ho = seeds_train.iloc[test_index]\n",
    "    \n",
    "    ## loop through your features\n",
    "    j = 0\n",
    "    for feature in features:\n",
    "        ## Define the model\n",
    "        log_reg = \n",
    "        \n",
    "        ## fit the model\n",
    "        log_reg\n",
    "        \n",
    "        ## Make the prediction\n",
    "        pred = \n",
    "        \n",
    "        ## Record the accuracy on the holdout set\n",
    "        log_reg_accs[i,j] = \n",
    "        \n",
    "        j = j + 1\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca194a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print out the average cv accuracies here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd2a7a8",
   "metadata": {},
   "source": [
    "##### c.\n",
    "\n",
    "Compare these models to the logistic regression model that incorporates all of the features you identified with your histogram exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108bf81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## fill in the missing code below\n",
    "\n",
    "\n",
    "i = 0\n",
    "for train_index, test_index in :\n",
    "    seeds_tt = seeds_train.iloc[train_index]\n",
    "    seeds_ho = seeds_train.iloc[test_index]\n",
    "    \n",
    "    ## Define the model, fit the model, then record the accuracies\n",
    "    \n",
    "    \n",
    "    \n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8abd120",
   "metadata": {},
   "outputs": [],
   "source": [
    "## What is the avg. cv. accuracy?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce55492f",
   "metadata": {},
   "source": [
    "##### Make any notes you want here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c90b55",
   "metadata": {},
   "source": [
    "##### d.\n",
    "\n",
    "Fill in the code to find the optimal $k$ for a $k$ nearest neighbors model encorporating all of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4510cea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import the model class\n",
    "from sklearn.neighbors import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7447297",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fill in the range you want to try for k\n",
    "ks = range()\n",
    "\n",
    "## This will give you a list of all feature column names\n",
    "all_features = seeds_train.columns[:-2]\n",
    "\n",
    "## Make an array to hold the accuracies\n",
    "k_all_accs = np.zeros()\n",
    "\n",
    "i = 0\n",
    "for train_index, test_index in :\n",
    "    ## Get the train and holdout sets\n",
    "    seeds_tt = seeds_train.iloc[train_index]\n",
    "    seeds_ho = seeds_train.iloc[test_index]\n",
    "    \n",
    "    ## Loop through the different ks\n",
    "    j = 0\n",
    "    for k in ks:\n",
    "        ## Make the model object\n",
    "        knn = \n",
    "        \n",
    "        ## Fit the model\n",
    "        \n",
    "        \n",
    "        ## Make your prediction\n",
    "        pred = \n",
    "        \n",
    "        ## Record the accuracy on the holdout set\n",
    "        k_all_accs[i,j] = accuracy_score(seeds_ho.y.values, pred)\n",
    "        \n",
    "        j = j + 1\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9885bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plots the accuracies as a function of k\n",
    "plt.figure(figsize=(7,5))\n",
    "\n",
    "\n",
    "plt.plot(ks, \n",
    "         np.mean(k_all_accs, axis=0),\n",
    "         '-o')\n",
    "\n",
    "\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.xlabel(\"$k$\", fontsize=12)\n",
    "plt.ylabel(\"Avg. CV Accuracy\", fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05b1de8",
   "metadata": {},
   "source": [
    "##### e. \n",
    "\n",
    "Now see if you can improve the accuracy by using just the features you chose as a result of your histogram explorations. Did the best accuracy change? Did the optimal value of $k$ change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001b2f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_select_accs = np.zeros((n_splits, len(ks)))\n",
    "\n",
    "i = 0\n",
    "for train_index, test_index in kfold.split(seeds_train, seeds_train.y):\n",
    "    seeds_tt = seeds_train.iloc[train_index]\n",
    "    seeds_ho = seeds_train.iloc[test_index]\n",
    "    \n",
    "    j = 0\n",
    "    for k in ks:\n",
    "        ## Make your model object\n",
    "        knn = \n",
    "        \n",
    "        ## Fit your model object\n",
    "        knn\n",
    "        \n",
    "        ## Make your prediction on the holdout set\n",
    "        pred = \n",
    "        \n",
    "        ## Record the accuracies\n",
    "        k_select_accs[i,j] = accuracy_score(seeds_ho.y.values, pred)\n",
    "        \n",
    "        j = j + 1\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31532103",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This will plot the avg cv accuracies as a function of k\n",
    "plt.figure(figsize=(7,5))\n",
    "\n",
    "\n",
    "plt.plot(ks, \n",
    "         np.mean(k_select_accs, axis=0),\n",
    "         '-o')\n",
    "\n",
    "\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.xlabel(\"$k$\", fontsize=12)\n",
    "plt.ylabel(\"Avg. CV Accuracy\", fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bbc56c",
   "metadata": {},
   "source": [
    "##### f.\n",
    "\n",
    "As a final check see if you can improve the cross-validation accuracy further by only considering a pair of features from your `pairplot` exploration earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55c38b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_final_accs = np.zeros((n_splits, len(ks)))\n",
    "\n",
    "i = 0\n",
    "for train_index, test_index in kfold.split(seeds_train, seeds_train.y):\n",
    "    seeds_tt = seeds_train.iloc[train_index]\n",
    "    seeds_ho = seeds_train.iloc[test_index]\n",
    "    \n",
    "    j = 0\n",
    "    for k in ks:\n",
    "        ## Make the model\n",
    "        knn = \n",
    "\n",
    "        \n",
    "        ## Fit the model\n",
    "        knn.fit()\n",
    "        \n",
    "        ## Make the prediction on the holdout set\n",
    "        pred = \n",
    "        \n",
    "        ## record the accuracy on the holdout set\n",
    "        k_final_accs[i,j] = accuracy_score(seeds_ho.y.values, pred)\n",
    "        \n",
    "        j = j + 1\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5581f224",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This plots the accuracies as a function of k\n",
    "plt.figure(figsize=(7,5))\n",
    "\n",
    "\n",
    "plt.plot(ks, \n",
    "         np.mean(k_final_accs, axis=0),\n",
    "         '-o')\n",
    "\n",
    "\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.xlabel(\"$k$\", fontsize=12)\n",
    "plt.ylabel(\"Avg. CV Accuracy\", fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d894fb59",
   "metadata": {},
   "source": [
    "##### 7. Summarizing the current results\n",
    "\n",
    "Consider the best average CV accuracies of all of the models you built. Which one performed the best?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38089b56",
   "metadata": {},
   "source": [
    "##### Write your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa698eee",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "\n",
    "This notebook was written for the Erd&#337;s Institute C&#337;de Data Science Boot Camp by Matthew Osborne, Ph. D., 2023.\n",
    "\n",
    "Any potential redistributors must seek and receive permission from Matthew Tyler Osborne, Ph.D. prior to redistribution. Redistribution of the material contained in this repository is conditional on acknowledgement of Matthew Tyler Osborne, Ph.D.'s original authorship and sponsorship of the Erdős Institute as subject to the license (see License.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

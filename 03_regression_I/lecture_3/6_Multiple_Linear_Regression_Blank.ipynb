{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f1769a6",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression\n",
    "\n",
    "## What we will accomplish\n",
    "\n",
    "In this notebook we will:\n",
    "- Introduce the multiple linear regression model,\n",
    "- Show how to fit the model using the <i>normal equation</i>,\n",
    "- Fit a model with `sklearn`.\n",
    "- Show how to use the normal equations to make a custom class which mimics the sklearn model object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f515b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from seaborn import set_style\n",
    "\n",
    "set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2838277",
   "metadata": {},
   "source": [
    "## The multiple linear regression model\n",
    "\n",
    "Suppose there is a quantitative variable you want to predict/model called $y$ and a set of $p$ features $x_1, x_2, \\dots x_p$, then the multiple linear regression model regressing $y$ on $x_1, \\dots, x_p$ is:\n",
    "\n",
    "$$\n",
    "y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_m x_p + \\epsilon = \\vec{x} \\cdot \\vec{\\beta} + \\epsilon,\n",
    "$$\n",
    "\n",
    "where $\\beta_0, \\dots, \\beta_p \\in \\mathbb{R}$ are constants, $\\vec{\\beta}$ is the $(p+1)$-vector of the $\\beta_i$ in numerical order, \n",
    "\n",
    "$$\n",
    "\\vec{x} = \\left(1, x_1, x_2, \\dots, x_p \\right)^\\top,\n",
    "$$\n",
    "\n",
    "and $\\epsilon \\sim N(0,\\sigma)$ is an error term independent of $\\vec{x}$.  Note that we have \"padded\" $\\vec{x}$ with an initial one to capture the constant term.\n",
    "\n",
    "### Fitting the model\n",
    "\n",
    "Suppose that we have $n$ observations $(\\vec{x}_i, y_i)$.   We can package these into an $n \\times (p+1)$ matrix $X$ and a $n$-vector $\\vec{y}$\n",
    "\n",
    "$$\n",
    "X = \\begin{bmatrix}\n",
    "1 & x_{11} & x_{12} & ... & x_{1p}\\\\\n",
    "1 & x_{21} & x_{22} & ... & x_{2p}\\\\\n",
    "  &        &        & \\vdots &    \\\\\n",
    "1 & x_{n1} & x_{n2} & ... & x_{np}\\\\  \n",
    "\\end{bmatrix}\n",
    "\n",
    "\\hphantom{fdsfds}\n",
    "\n",
    "\\vec{y} = \n",
    "\\begin{bmatrix}\n",
    "y_1\\\\y_2\\\\ \\vdots \\\\ y_n\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "In order to fit a multiple linear regression model regressing $y$ on $\\vec{x}$ using this data we return to the mean square error.\n",
    "\n",
    "$$\n",
    "\\operatorname{MSE}(\\vec{\\beta}) = \\frac{1}{n} \\sum_{i=1}^n \\left(y_i - f_{\\vec{\\beta}}(\\vec{x}_i)\\right)^2 = \\frac{1}{n} \\sum_{i=1}^n \\left(y_i - \\vec{x}_i^\\top \\vec{\\beta}\\right)^2,\n",
    "$$\n",
    "\n",
    "we can rewrite this using some linear algebra as:\n",
    "\n",
    "$$\n",
    "\\operatorname{MSE}(\\vec{\\beta})  = \\frac{1}{n} \\left\\vert \\vec{y} - X \\vec{\\beta}\\right\\vert^2\n",
    "$$\n",
    "\n",
    "We want to find the value of the parameter $\\vec{\\beta}$ which minimizes the MSE.\n",
    "\n",
    "As seen in Math Hour,  we can minimize it in two ways:\n",
    "\n",
    "* Using multivariable differential calculus:  find gradient of the MSE with respect of $\\beta$ and set it equal to zero.\n",
    "* Using linear algebra:  view this geometrically as projecting $\\vec{y}$ into the subspace spanned by the columns of $X$.\n",
    "\n",
    "Either way we obtain\n",
    "\n",
    "$$\n",
    "\\hat{\\beta} = (X^T X)^{-1}X^T \\vec{y}.\n",
    "$$\n",
    "\n",
    "This is the <i>ordinary least squares</i> estimate of the coefficient vector $\\hat{\\beta}$. Note that this formula is also sometimes called the <i>normal equation</i>.\n",
    "\n",
    "### Back to baseball\n",
    "\n",
    "We will demonstrate how to fit this model using `sklearn` with the baseball example we looked at in the previous notebook.\n",
    "\n",
    "We will then write a naive custom class which functions similarly to the sklearn module to get a feel for what is going on \"under the hood\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcf800e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note this works on Mac and Linux,\n",
    "## you may need to change the slash directions if\n",
    "## you are running a Windows machine\n",
    "baseball = pd.read_csv(\"../../data/baseball.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9251fc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import train_test_split\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2aeae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make the train test split here\n",
    "bb_train, bb_test = train_test_split(baseball,\n",
    "                                        shuffle = True,\n",
    "                                        random_state = 216,\n",
    "                                        test_size=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09500f6b",
   "metadata": {},
   "source": [
    "The multiple linear regression model that we will fit is:\n",
    "\n",
    "$$\n",
    "\\texttt{W} = \\beta_0 + \\beta_1 \\texttt{R} + \\beta_2 \\texttt{RA} + \\epsilon.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e5ae3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = \n",
    "y_train = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8823a31",
   "metadata": {},
   "source": [
    "### Using `sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fac5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import the LinearRegression object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15145ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make the model object\n",
    "\n",
    "reg = \n",
    "\n",
    "## Fit the model object\n",
    "## note I do NOT have to use reshape here\n",
    "## because X_train is a 2D np.array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72be0d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## look at coef and intercept\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ac638d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make a prediction\n",
    "sklearn_y_pred = \n",
    "sklearn_mse = np.sum(np.power(y_train-sklearn_y_pred, 2))/len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab213dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculate the mse\n",
    "print(f\"the mse is {sklearn_mse:0.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e478ee19",
   "metadata": {},
   "source": [
    "### Implementing a custom linear regression class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265e170d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLinearRegression():\n",
    "    '''A minimal custom linear regression model object'''\n",
    "    def __init__(self):\n",
    "        self.beta = None\n",
    "    def fit(self,X,y):\n",
    "        '''Finds self.beta using the normal equation.  \n",
    "            X and y must be numpy arrays.\n",
    "            X must have shape (num_samples, num_features)\n",
    "            y must have shape (num_samples,)'''\n",
    "        X = np.hstack([np.ones(X.shape[0]).reshape(-1,1), X]) # adds column of ones to X\n",
    "        XtX =  \n",
    "        XtXinv = \n",
    "        Xty = \n",
    "        self.beta = \n",
    "    def predict(self,X):\n",
    "        X = np.hstack([np.ones(X.shape[0]).reshape(-1,1), X]) # adds column of ones to X\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917d5b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_reg = CustomLinearRegression()\n",
    "custom_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a40e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_reg.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24d4745",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_y_pred = custom_reg.predict(X_train)\n",
    "custom_mse = np.sum(np.power(y_train-custom_y_pred, 2))/len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768f0031",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_mse, sklearn_mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7d1ea9",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "\n",
    "This notebook was written for the Erd&#337;s Institute C&#337;de Data Science Boot Camp by Matthew Osborne, Ph. D., 2023.  Modified by Steven Gubkin 2024.\n",
    "\n",
    "Any potential redistributors must seek and receive permission from Matthew Tyler Osborne, Ph.D. prior to redistribution. Redistribution of the material contained in this repository is conditional on acknowledgement of Matthew Tyler Osborne, Ph.D.'s original authorship and sponsorship of the Erd≈ës Institute as subject to the license (see License.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
